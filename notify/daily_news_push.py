#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥è´¢ç»æ–°é—»æ¨é€è„šæœ¬

åŠŸèƒ½ï¼š
1. çˆ¬å–åŒèŠ±é¡ºã€ä¸œæ–¹è´¢å¯Œç­‰è´¢ç»æ–°é—»
2. ä½¿ç”¨AIå¤§æ¨¡å‹è¿›è¡Œæ–°é—»æ€»ç»“
3. é€šè¿‡ä¼ä¸šå¾®ä¿¡æ¨é€æ¯æ—¥æ–°é—»æ‘˜è¦
4. æ”¯æŒå¤šç§æ€»ç»“é£æ ¼å’Œæ¨é€æ ¼å¼

ä½¿ç”¨æ–¹æ³•ï¼š
python3 daily_news_push.py [é€‰é¡¹]

é€‰é¡¹ï¼š
--summary-type     æ€»ç»“ç±»å‹ (brief/detailed/investmentï¼Œé»˜è®¤brief)
--ai-provider      AIæä¾›å•† (openai/qianwen/ollamaï¼Œé»˜è®¤qianwen)
--api-key          AI APIå¯†é’¥
--limit            æ¯ä¸ªæ¥æºçš„æ–°é—»æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤15ï¼‰
--test-mode        æµ‹è¯•æ¨¡å¼ï¼ˆä¸æ¨é€æ¶ˆæ¯ï¼Œä»…æ˜¾ç¤ºç»“æœï¼‰

ç¤ºä¾‹ï¼š
python3 daily_news_push.py                                    # é»˜è®¤ç®€æ´æ€»ç»“å¹¶æ¨é€
python3 daily_news_push.py --summary-type detailed            # è¯¦ç»†åˆ†ææ€»ç»“
python3 daily_news_push.py --test-mode                        # æµ‹è¯•æ¨¡å¼
python3 daily_news_push.py --ai-provider ollama --test-mode   # ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹æµ‹è¯•
"""
import os
# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥databaseå’Œfetcheræ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import argparse
import logging
import sys
from datetime import datetime
from news_crawler import FinanceNewsCrawler
from ai_summarizer import AISummarizer
from send_msg import send_markdown_message, send_robot_message

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('daily_news_push.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


def format_news_for_wechat(report: dict, include_raw_news: bool = False) -> str:
    """
    æ ¼å¼åŒ–æ–°é—»æ‘˜è¦ç”¨äºä¼ä¸šå¾®ä¿¡æ¨é€
    
    Args:
        report: æ–°é—»æ‘˜è¦æŠ¥å‘Š
        include_raw_news: æ˜¯å¦åŒ…å«åŸå§‹æ–°é—»åˆ—è¡¨
        
    Returns:
        str: æ ¼å¼åŒ–çš„markdownæ–‡æœ¬
    """
    markdown_text = f"""# {report['title']}

{report['ai_summary']}

## ğŸ“Š æ•°æ®ç»Ÿè®¡
- **æ–°é—»æ€»æ•°**: {report['news_count']} æ¡
- **çˆ¬å–æ—¶é—´**: {report['crawl_time']}
- **æ€»ç»“æ—¶é—´**: {report['summary_time']}

## ğŸ“ˆ æ–°é—»æ¥æº
"""
    
    for source, count in report['source_distribution'].items():
        markdown_text += f"- **{source}**: {count} æ¡\n"
    
    if include_raw_news and report['raw_news']:
        markdown_text += "\n## ğŸ“° æ–°é—»è¯¦æƒ…\n"
        for i, news in enumerate(report['raw_news'][:10], 1):  # æœ€å¤šæ˜¾ç¤º10æ¡
            title = news.get('title', '')
            source = news.get('source', '')
            pub_time = news.get('pub_time', '')
            markdown_text += f"{i}. **[{source}]** {title}\n"
            if pub_time:
                markdown_text += f"   *æ—¶é—´: {pub_time}*\n"
            markdown_text += "\n"
        
        if len(report['raw_news']) > 10:
            markdown_text += f"... è¿˜æœ‰ {len(report['raw_news']) - 10} æ¡æ–°é—»\n"
    
    markdown_text += f"\n---\nğŸ’¡ *æ•°æ®æ¥æºï¼šåŒèŠ±é¡ºã€ä¸œæ–¹è´¢å¯Œç­‰è´¢ç»ç½‘ç«™*\n"
    markdown_text += f"ğŸ¤– *AIæ€»ç»“ï¼šæ™ºèƒ½åˆ†ææ¯æ—¥è´¢ç»åŠ¨æ€*"
    
    return markdown_text


def run_daily_news_push(ai_provider: str = "qianwen", api_key: str = None,
                       summary_type: str = "brief", limit_per_source: int = 15,
                       test_mode: bool = False) -> dict:
    """
    æ‰§è¡Œæ¯æ—¥æ–°é—»æ¨é€
    
    Args:
        ai_provider: AIæä¾›å•†
        api_key: APIå¯†é’¥
        summary_type: æ€»ç»“ç±»å‹
        limit_per_source: æ¯ä¸ªæ¥æºçš„æ–°é—»æ•°é‡
        test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼
        
    Returns:
        dict: æ‰§è¡Œç»“æœç»Ÿè®¡
    """
    stats = {
        'start_time': datetime.now(),
        'end_time': None,
        'duration': None,
        'crawl_success': False,
        'summary_success': False,
        'push_success': False,
        'news_count': 0,
        'error_message': None
    }
    
    try:
        logger.info("ğŸš€ å¼€å§‹æ¯æ—¥è´¢ç»æ–°é—»æ¨é€ä»»åŠ¡...")
        logger.info("=" * 70)
        
        # 1. çˆ¬å–æ–°é—»
        logger.info("ğŸ“° ç¬¬ä¸€æ­¥ï¼šçˆ¬å–è´¢ç»æ–°é—»...")
        crawler = FinanceNewsCrawler()
        news_data = crawler.get_daily_finance_news(limit_per_source=limit_per_source)
        
        if news_data['total_count'] > 0:
            stats['crawl_success'] = True
            stats['news_count'] = news_data['total_count']
            logger.info(f"âœ… æ–°é—»çˆ¬å–æˆåŠŸï¼Œè·å¾— {stats['news_count']} æ¡æ–°é—»")
        else:
            logger.error("âŒ æ–°é—»çˆ¬å–å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°æ–°é—»æ•°æ®")
            stats['error_message'] = "æ–°é—»çˆ¬å–å¤±è´¥"
            return stats
        
        # 2. AIæ€»ç»“
        logger.info("ğŸ¤– ç¬¬äºŒæ­¥ï¼šAIæ–°é—»æ€»ç»“...")
        summarizer = AISummarizer(api_provider=ai_provider, api_key=api_key)
        report = summarizer.create_news_digest(news_data, summary_type)
        
        if report and report.get('ai_summary'):
            stats['summary_success'] = True
            logger.info("âœ… AIæ–°é—»æ€»ç»“æˆåŠŸ")
        else:
            logger.warning("âš ï¸ AIæ€»ç»“å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ€»ç»“")
            stats['summary_success'] = False
        
        # 3. æ ¼å¼åŒ–å’Œæ¨é€
        logger.info("ğŸ“± ç¬¬ä¸‰æ­¥ï¼šæ ¼å¼åŒ–å’Œæ¨é€æ¶ˆæ¯...")
        
        if test_mode:
            # æµ‹è¯•æ¨¡å¼ï¼šä»…æ‰“å°ç»“æœï¼Œä¸å®é™…æ¨é€
            logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šæ˜¾ç¤ºæ¨é€å†…å®¹é¢„è§ˆ...")
            markdown_content = format_news_for_wechat(report, include_raw_news=True)
            
            print("\n" + "="*70)
            print("ğŸ“± ä¼ä¸šå¾®ä¿¡æ¨é€å†…å®¹é¢„è§ˆï¼š")
            print("="*70)
            print(markdown_content)
            print("="*70)
            
            stats['push_success'] = True
            logger.info("âœ… æµ‹è¯•æ¨¡å¼æ‰§è¡Œå®Œæˆ")
            
        else:
            # æ­£å¼æ¨é€
            try:
                markdown_content = format_news_for_wechat(report, include_raw_news=False)
                
                # æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡
                result = send_markdown_message(markdown_content)
                
                if result:
                    stats['push_success'] = True
                    logger.info("âœ… ä¼ä¸šå¾®ä¿¡æ¨é€æˆåŠŸ")
                else:
                    logger.error("âŒ ä¼ä¸šå¾®ä¿¡æ¨é€å¤±è´¥")
                    
            except Exception as e:
                logger.error(f"âŒ æ¶ˆæ¯æ¨é€å¤±è´¥: {e}")
                stats['error_message'] = f"æ¨é€å¤±è´¥: {e}"
        
    except Exception as e:
        logger.error(f"âŒ æ¯æ—¥æ–°é—»æ¨é€ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        stats['error_message'] = str(e)
    
    finally:
        stats['end_time'] = datetime.now()
        stats['duration'] = stats['end_time'] - stats['start_time']
    
    return stats


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¯æ—¥è´¢ç»æ–°é—»æ¨é€')
    parser.add_argument('--summary-type', choices=['brief', 'detailed', 'investment'], 
                       default='brief', help='æ€»ç»“ç±»å‹ï¼ˆé»˜è®¤ç®€æ´ï¼‰')
    parser.add_argument('--ai-provider', choices=['openai', 'qianwen', 'ollama'], 
                       default='qianwen', help='AIæä¾›å•†ï¼ˆé»˜è®¤é€šä¹‰åƒé—®ï¼‰')
    parser.add_argument('--api-key', help='AI APIå¯†é’¥')
    parser.add_argument('--limit', type=int, default=15, help='æ¯ä¸ªæ¥æºçš„æ–°é—»æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤15ï¼‰')
    parser.add_argument('--test-mode', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼ˆä¸å®é™…æ¨é€ï¼‰')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ æ¯æ—¥è´¢ç»æ–°é—»æ¨é€ç³»ç»Ÿ")
    logger.info("=" * 70)
    
    logger.info(f"âš™ï¸ é…ç½®å‚æ•°ï¼š")
    logger.info(f"   æ€»ç»“ç±»å‹: {args.summary_type}")
    logger.info(f"   AIæä¾›å•†: {args.ai_provider}")
    logger.info(f"   æ–°é—»æ•°é‡: æ¯æº{args.limit}æ¡")
    logger.info(f"   æµ‹è¯•æ¨¡å¼: {'æ˜¯' if args.test_mode else 'å¦'}")
    
    if args.ai_provider != 'ollama' and not args.api_key:
        logger.warning("âš ï¸ æœªæä¾›APIå¯†é’¥ï¼Œå¯èƒ½å½±å“AIæ€»ç»“åŠŸèƒ½")
    
    start_time = datetime.now()
    
    try:
        # æ‰§è¡Œæ¯æ—¥æ–°é—»æ¨é€ä»»åŠ¡
        stats = run_daily_news_push(
            ai_provider=args.ai_provider,
            api_key=args.api_key,
            summary_type=args.summary_type,
            limit_per_source=args.limit,
            test_mode=args.test_mode
        )
        
        # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
        logger.info("\n" + "ğŸ“Š ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡".center(70, "="))
        logger.info(f"   ğŸ“° æ–°é—»çˆ¬å–: {'æˆåŠŸ' if stats['crawl_success'] else 'å¤±è´¥'}")
        logger.info(f"   ğŸ¤– AIæ€»ç»“: {'æˆåŠŸ' if stats['summary_success'] else 'å¤±è´¥'}")
        logger.info(f"   ğŸ“± æ¶ˆæ¯æ¨é€: {'æˆåŠŸ' if stats['push_success'] else 'å¤±è´¥'}")
        logger.info(f"   ğŸ“Š æ–°é—»æ•°é‡: {stats['news_count']} æ¡")
        logger.info(f"   â±ï¸ æ€»è€—æ—¶: {stats['duration']}")
        
        if stats['error_message']:
            logger.error(f"   âŒ é”™è¯¯ä¿¡æ¯: {stats['error_message']}")
        
        # åˆ¤æ–­æ•´ä½“æ˜¯å¦æˆåŠŸ
        overall_success = stats['crawl_success'] and (stats['summary_success'] or test_mode) and stats['push_success']
        
        if overall_success:
            logger.info("ğŸ‰ æ¯æ—¥è´¢ç»æ–°é—»æ¨é€ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼")
            return True
        else:
            logger.error("âŒ æ¯æ—¥è´¢ç»æ–°é—»æ¨é€ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
            return False
        
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        return False
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}")
        return False
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° ç¨‹åºæ€»æ‰§è¡Œæ—¶é—´: {total_duration}")


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
