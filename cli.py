# -*- coding: utf-8 -*-
"""
å‘½ä»¤è¡Œæ¥å£æ¨¡å—
å¤„ç†å‘½ä»¤è¡Œå‚æ•°è§£æå’Œæ‰§è¡Œé€»è¾‘
"""

import argparse
import logging
import sys
import time
import pandas as pd
from typing import Optional

from config import DEFAULT_CONFIG_MODE, ARGS_CONFIG
from utils import (
    format_date, load_config_defaults, merge_config_and_args, 
    print_current_config, estimate_execution_time, validate_stock_codes
)
from fetcher import StockDataFetcher
from database import StockDatabase

logger = logging.getLogger(__name__)


class StockDataCLI:
    """è‚¡ç¥¨æ•°æ®å‘½ä»¤è¡Œæ¥å£"""
    
    def __init__(self):
        """åˆå§‹åŒ–CLI"""
        self.db = StockDatabase()
        self.fetcher = None
    
    def create_parser(self) -> argparse.ArgumentParser:
        """
        åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
        
        Returns:
            argparse.ArgumentParser: é…ç½®å¥½çš„å‚æ•°è§£æå™¨
        """
        parser = argparse.ArgumentParser(description='è‚¡ç¥¨æ•°æ®è·å–å’Œå­˜å‚¨å·¥å…·')
        
        # åŸºç¡€å‚æ•°
        parser.add_argument('--codes', nargs='*', help='è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ï¼š000001.SZ 000002.SZ')
        parser.add_argument('--start-date', help='å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDæˆ–YYYYMMDDæ ¼å¼ï¼‰')
        parser.add_argument('--end-date', help='ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDæˆ–YYYYMMDDæ ¼å¼ï¼‰')
        
        # åŠŸèƒ½é€‰é¡¹
        parser.add_argument('--create-db', action='store_true', help='åˆ›å»ºæ•°æ®åº“å’Œæ•°æ®è¡¨')
        parser.add_argument('--query', action='store_true', help='æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æ•°æ®')
        parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯')
        parser.add_argument('--trade-date', help='è·å–æŒ‡å®šäº¤æ˜“æ—¥çš„æ•°æ®ï¼ˆYYYY-MM-DDæˆ–YYYYMMDDæ ¼å¼ï¼‰')
        parser.add_argument('--latest', action='store_true', help='è·å–æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®')
        
        # æ¨¡å¼å’Œé…ç½®
        parser.add_argument('--mode', choices=['ts_code', 'trade_date'], default='ts_code', 
                           help='æ•°æ®è·å–æ¨¡å¼ï¼šts_codeæŒ‰è‚¡ç¥¨è·å–å†å²æ•°æ®ï¼Œtrade_dateæŒ‰æ—¥æœŸè·å–å½“æ—¥æ•°æ®')
        parser.add_argument('--main-board', action='store_true', 
                           help='è·å–Aè‚¡ä¸»æ¿æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼ˆå½“ä¸æŒ‡å®š--codesæ—¶é»˜è®¤å¼€å¯ï¼‰')
        
        # æ‰¹é‡å¤„ç†å‚æ•°
        parser.add_argument('--batch-size', type=int, default=50, 
                           help='æ‰¹é‡è·å–çš„æ‰¹æ¬¡å¤§å°ï¼Œé˜²æ­¢APIè°ƒç”¨è¿‡äºé¢‘ç¹ï¼ˆé»˜è®¤50ï¼‰')
        parser.add_argument('--delay', type=float, default=0.1, 
                           help='æ¯æ¬¡APIè°ƒç”¨çš„å»¶è¿Ÿæ—¶é—´ï¼Œå•ä½ç§’ï¼ˆé»˜è®¤0.1ï¼‰')
        parser.add_argument('--limit', type=int, 
                           help='é™åˆ¶è·å–çš„è‚¡ç¥¨æ•°é‡ï¼Œç”¨äºæµ‹è¯•ï¼ˆé»˜è®¤æ— é™åˆ¶ï¼‰')
        
        # é«˜æ•ˆè·å–æ¨¡å¼
        parser.add_argument('--market-mode', action='store_true',
                           help='ä½¿ç”¨å…¨å¸‚åœºæ¨¡å¼ï¼šé€šè¿‡äº¤æ˜“æ—¥å¾ªç¯è·å–ï¼ˆæ¨èç”¨äºå¤§æ‰¹é‡å†å²æ•°æ®ï¼‰')
        parser.add_argument('--exchange', choices=['SSE', 'SZSE'], default='SSE',
                           help='äº¤æ˜“æ‰€é€‰æ‹©ï¼Œç”¨äºäº¤æ˜“æ—¥å†ï¼ˆSSEä¸Šäº¤æ‰€ï¼ŒSZSEæ·±äº¤æ‰€ï¼Œé»˜è®¤SSEï¼‰')
        parser.add_argument('--batch-days', type=int, default=10,
                           help='å…¨å¸‚åœºæ¨¡å¼ä¸‹æ¯æ‰¹æ’å…¥çš„äº¤æ˜“æ—¥æ•°é‡ï¼ˆé»˜è®¤10å¤©ï¼‰')
        parser.add_argument('--use-batch-insert', action='store_true', default=True,
                           help='ä½¿ç”¨åˆ†æ‰¹æ’å…¥ä¼˜åŒ–æ€§èƒ½ï¼ˆé»˜è®¤å¼€å¯ï¼Œæ¨èå¤§æ•°æ®é‡ä½¿ç”¨ï¼‰')
        
        # é…ç½®æ–‡ä»¶ç›¸å…³
        parser.add_argument('--config', default=DEFAULT_CONFIG_MODE,
                           choices=list(ARGS_CONFIG.keys()),
                           help=f'ä½¿ç”¨é¢„è®¾çš„é…ç½®æ¨¡å¼ï¼ˆé»˜è®¤: {DEFAULT_CONFIG_MODE}ï¼‰ã€‚'
                                f'å¯é€‰: {", ".join(ARGS_CONFIG.keys())}')
        parser.add_argument('--show-config', action='store_true',
                           help='æ˜¾ç¤ºå½“å‰é…ç½®å¹¶é€€å‡º')
        
        # å®šæ—¶åŒæ­¥ç›¸å…³
        parser.add_argument('--sync-today', action='store_true',
                           help='åŒæ­¥ä»Šå¤©çš„ä¸»æ¿æ•°æ®åˆ°æ•°æ®åº“')
        parser.add_argument('--install-cron', action='store_true',
                           help='æ˜¾ç¤ºcronä»»åŠ¡å®‰è£…é…ç½®ï¼ˆæ¯å¤©è‡ªåŠ¨åŒæ­¥ï¼‰')
        
        return parser
    
    def parse_and_merge_args(self, args=None) -> argparse.Namespace:
        """
        è§£æå¹¶åˆå¹¶å‘½ä»¤è¡Œå‚æ•°å’Œé…ç½®æ–‡ä»¶
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            
        Returns:
            argparse.Namespace: åˆå¹¶åçš„å‚æ•°
        """
        parser = self.create_parser()
        parsed_args = parser.parse_args(args)
        
        # åŠ è½½é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        config_defaults = load_config_defaults(parsed_args.config)
        
        # åˆå¹¶é…ç½®æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°
        merged_args = merge_config_and_args(config_defaults, parsed_args)
        
        return merged_args
    
    def handle_show_config(self, args: argparse.Namespace) -> bool:
        """
        å¤„ç†æ˜¾ç¤ºé…ç½®çš„è¯·æ±‚
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥é€€å‡ºç¨‹åº
        """
        if args.show_config:
            print_current_config(args)
            return True
        return False
    
    def handle_database_operations(self, args: argparse.Namespace) -> Optional[bool]:
        """
        å¤„ç†æ•°æ®åº“ç›¸å…³æ“ä½œ
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            Optional[bool]: Noneè¡¨ç¤ºç»§ç»­æ‰§è¡Œï¼ŒTrueè¡¨ç¤ºæˆåŠŸé€€å‡ºï¼ŒFalseè¡¨ç¤ºå¤±è´¥é€€å‡º
        """
        # åˆ›å»ºæ•°æ®åº“å’Œæ•°æ®è¡¨
        if getattr(args, 'create_db', False) or not (getattr(args, 'query', False) or getattr(args, 'stats', False)):
            logger.info("æ­£åœ¨åˆ›å»ºæ•°æ®åº“å’Œæ•°æ®è¡¨...")
            self.db.create_database()
            with self.db:
                self.db.create_daily_table()
        
        # æŸ¥è¯¢æ•°æ®åº“
        if getattr(args, 'query', False):
            with self.db:
                query_limit = getattr(args, 'limit', 100) or 100
                df = self.db.query_data(limit=query_limit)
                if df is not None and not df.empty:
                    print(f"\\næœ€æ–°çš„è‚¡ç¥¨æ•°æ®ï¼ˆå‰{min(query_limit, 20)}æ¡ï¼‰ï¼š")
                    print(df.head(20))
                else:
                    print("æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®")
            return True
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if getattr(args, 'stats', False):
            with self.db:
                stats = self.db.get_stats()
                print("\\næ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯ï¼š")
                print(f"æ€»è®°å½•æ•°: {stats.get('total_records', 0):,}")
                print(f"è‚¡ç¥¨æ•°é‡: {stats.get('stock_count', 0)}")
                if stats.get('date_range'):
                    print(f"æ—¥æœŸèŒƒå›´: {stats['date_range']['min_date']} åˆ° {stats['date_range']['max_date']}")
                print(f"æœ€åæ›´æ–°: {stats.get('last_update', 'N/A')}")
            return True
        
        return None
    
    def initialize_fetcher(self) -> None:
        """åˆå§‹åŒ–æ•°æ®è·å–å™¨"""
        if self.fetcher is None:
            self.fetcher = StockDataFetcher()
    
    def get_stock_codes(self, args: argparse.Namespace) -> list:
        """
        è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        if args.codes:
            # éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
            if not validate_stock_codes(args.codes):
                logger.warning("å­˜åœ¨æ— æ•ˆçš„è‚¡ç¥¨ä»£ç æ ¼å¼")
            
            logger.info(f"ä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨ä»£ç : {len(args.codes)}åª")
            return args.codes
        else:
            # è·å–Aè‚¡ä¸»æ¿è‚¡ç¥¨
            logger.info("æœªæŒ‡å®šè‚¡ç¥¨ä»£ç ï¼Œå°†è·å–æ‰€æœ‰Aè‚¡ä¸»æ¿è‚¡ç¥¨æ•°æ®...")
            self.initialize_fetcher()
            
            stock_codes = self.fetcher.get_main_board_stocks()
            
            if not stock_codes:
                from config import DEFAULT_STOCK_CODES
                logger.error("æ— æ³•è·å–ä¸»æ¿è‚¡ç¥¨åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤è‚¡ç¥¨ä»£ç ")
                stock_codes = DEFAULT_STOCK_CODES
            elif args.limit and args.limit > 0:
                stock_codes = stock_codes[:args.limit]
                logger.info(f"é™åˆ¶è·å–è‚¡ç¥¨æ•°é‡: {len(stock_codes)}åªï¼ˆç”¨äºæµ‹è¯•ï¼‰")
            
            return stock_codes
    
    def handle_trade_date_mode(self, args: argparse.Namespace) -> Optional[bool]:
        """
        å¤„ç†æŒ‡å®šäº¤æ˜“æ—¥æœŸæ¨¡å¼
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            Optional[bool]: Noneè¡¨ç¤ºç»§ç»­æ‰§è¡Œï¼ŒTrueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        if not getattr(args, 'trade_date', None):
            return None
        
        self.initialize_fetcher()
        trade_date_formatted = format_date(args.trade_date)
        stock_codes = self.get_stock_codes(args)
        
        logger.info(f"è·å– {trade_date_formatted} äº¤æ˜“æ—¥æ•°æ®...")
        logger.info(f"è‚¡ç¥¨æ•°é‡: {len(stock_codes)}åª")
        
        if len(stock_codes) > 100:
            logger.warning(f"å³å°†è·å– {len(stock_codes)} åªè‚¡ç¥¨çš„äº¤æ˜“æ—¥æ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
        
        # è·å–æŒ‡å®šäº¤æ˜“æ—¥çš„æ•°æ®
        all_data = []
        for ts_code in stock_codes:
            df = self.fetcher.get_daily_by_date(trade_date_formatted, ts_code)
            if df is not None and not df.empty:
                all_data.append(df)
            time.sleep(0.1)  # é¿å…APIé¢‘ç‡é™åˆ¶
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            logger.info(f"æˆåŠŸè·å– {len(combined_df)} æ¡äº¤æ˜“æ—¥æ•°æ®")
            
            # å­˜å‚¨åˆ°æ•°æ®åº“
            with self.db:
                success = self.db.insert_daily_data(combined_df)
                if success:
                    logger.info("äº¤æ˜“æ—¥æ•°æ®å­˜å‚¨æˆåŠŸï¼")
                    return True
                else:
                    logger.error("äº¤æ˜“æ—¥æ•°æ®å­˜å‚¨å¤±è´¥")
                    return False
        else:
            logger.warning(f"æœªè·å–åˆ° {trade_date_formatted} çš„æ•°æ®")
            return False
    
    def handle_latest_mode(self, args: argparse.Namespace) -> Optional[bool]:
        """
        å¤„ç†æœ€æ–°äº¤æ˜“æ—¥æ¨¡å¼
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            Optional[bool]: Noneè¡¨ç¤ºç»§ç»­æ‰§è¡Œï¼ŒTrueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        if not getattr(args, 'latest', False):
            return None
        
        self.initialize_fetcher()
        stock_codes = self.get_stock_codes(args)
        
        logger.info(f"è·å–æœ€æ–°äº¤æ˜“æ—¥æ•°æ®...")
        logger.info(f"è‚¡ç¥¨æ•°é‡: {len(stock_codes)}åª")
        
        if len(stock_codes) > 100:
            logger.warning(f"å³å°†è·å– {len(stock_codes)} åªè‚¡ç¥¨çš„æœ€æ–°äº¤æ˜“æ—¥æ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
        
        df = self.fetcher.get_latest_trading_day_data(stock_codes)
        if df is not None and not df.empty:
            logger.info(f"æˆåŠŸè·å–æœ€æ–°äº¤æ˜“æ—¥ {len(df)} æ¡æ•°æ®")
            
            # å­˜å‚¨åˆ°æ•°æ®åº“
            with self.db:
                success = self.db.insert_daily_data(df)
                if success:
                    logger.info("æœ€æ–°äº¤æ˜“æ—¥æ•°æ®å­˜å‚¨æˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºè·å–çš„æ•°æ®
                    print("\\næœ€æ–°äº¤æ˜“æ—¥æ•°æ®ï¼š")
                    print(df[['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pct_chg', 'vol']].to_string(index=False))
                    return True
                else:
                    logger.error("æœ€æ–°äº¤æ˜“æ—¥æ•°æ®å­˜å‚¨å¤±è´¥")
                    return False
        else:
            logger.warning("æœªè·å–åˆ°æœ€æ–°äº¤æ˜“æ—¥æ•°æ®")
            return False
    
    def handle_historical_data(self, args: argparse.Namespace) -> bool:
        """
        å¤„ç†å†å²æ•°æ®è·å–
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        self.initialize_fetcher()
        
        # å¤„ç†æ—¥æœŸå‚æ•°
        start_date = format_date(args.start_date) if args.start_date else None
        end_date = format_date(args.end_date) if args.end_date else None
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å…¨å¸‚åœºæ¨¡å¼
        if getattr(args, 'market_mode', False):
            return self.handle_market_mode_data(args, start_date, end_date)
        else:
            return self.handle_stock_mode_data(args, start_date, end_date)
    
    def handle_market_mode_data(self, args: argparse.Namespace, start_date: str, end_date: str) -> bool:
        """
        å¤„ç†å…¨å¸‚åœºæ¨¡å¼çš„æ•°æ®è·å–ï¼ˆé€šè¿‡äº¤æ˜“æ—¥å¾ªç¯ï¼‰
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not start_date or not end_date:
            logger.error("å…¨å¸‚åœºæ¨¡å¼éœ€è¦æŒ‡å®šå¼€å§‹å’Œç»“æŸæ—¥æœŸ")
            return False
        
        logger.info(f"ğŸš€ ä½¿ç”¨å…¨å¸‚åœºæ¨¡å¼è·å–æ•°æ®")
        logger.info(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
        logger.info(f"ğŸ¢ äº¤æ˜“æ‰€: {args.exchange}")
        logger.info(f"â±ï¸ APIå»¶è¿Ÿ: {args.delay}ç§’")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨åˆ†æ‰¹æ’å…¥
        use_batch_insert = getattr(args, 'use_batch_insert', True)
        batch_days = getattr(args, 'batch_days', 10)
        
        if use_batch_insert:
            logger.info(f"ğŸ’¾ ä½¿ç”¨åˆ†æ‰¹æ’å…¥æ¨¡å¼ï¼Œæ¯ {batch_days} ä¸ªäº¤æ˜“æ—¥æ’å…¥ä¸€æ¬¡")
            return self.handle_batch_insert_mode(args, start_date, end_date, batch_days)
        else:
            logger.info(f"ğŸ’¾ ä½¿ç”¨ä¸€æ¬¡æ€§æ’å…¥æ¨¡å¼ï¼ˆä¸æ¨èå¤§æ•°æ®é‡ä½¿ç”¨ï¼‰")
            return self.handle_single_insert_mode(args, start_date, end_date)
    
    def handle_batch_insert_mode(self, args: argparse.Namespace, start_date: str, end_date: str, batch_days: int) -> bool:
        """
        å¤„ç†åˆ†æ‰¹æ’å…¥æ¨¡å¼ï¼ˆæ¨èç”¨äºå¤§æ•°æ®é‡ï¼‰
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            batch_days: æ¯æ‰¹å¤„ç†çš„äº¤æ˜“æ—¥æ•°é‡
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # é¢„ä¼°æ—¶é—´
        estimated_time = self.fetcher.estimate_market_data_time(start_date, end_date, args.delay)
        logger.info(f"â° é¢„ä¼°æ€»è€—æ—¶: {estimated_time}")
        
        # ä½¿ç”¨åˆ†æ‰¹æ’å…¥æ–¹æ³•
        with self.db:
            stats = self.fetcher.get_all_market_data_by_dates_with_batch_insert(
                start_date=start_date,
                end_date=end_date,
                delay=args.delay,
                exchange=args.exchange,
                db_instance=self.db,
                batch_days=batch_days
            )
        
        if not stats or stats.get('total_records', 0) == 0:
            logger.error("âŒ å…¨å¸‚åœºæ•°æ®è·å–å’Œæ’å…¥å¤±è´¥")
            return False
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        logger.info("âœ… å…¨å¸‚åœºæ•°æ®è·å–å’Œæ’å…¥å®Œæˆï¼")
        
        # è·å–æ•°æ®åº“æœ€æ–°ç»Ÿè®¡
        with self.db:
            db_stats = self.db.get_stats()
            logger.info(f"ğŸ“Š æ•°æ®åº“å½“å‰çŠ¶æ€:")
            logger.info(f"   æ€»è®°å½•æ•°: {db_stats.get('total_records', 0):,}")
            logger.info(f"   è‚¡ç¥¨æ•°é‡: {db_stats.get('stock_count', 0)}")
            if db_stats.get('date_range'):
                logger.info(f"   æ•°æ®èŒƒå›´: {db_stats['date_range']['min_date']} åˆ° {db_stats['date_range']['max_date']}")
        
        # åˆ¤æ–­æˆåŠŸç‡
        success_rate = stats.get('batch_insert_success', 0) / max(stats.get('total_batches', 1), 1)
        return success_rate >= 0.8  # 80%ä»¥ä¸ŠæˆåŠŸç‡è®¤ä¸ºæ˜¯æˆåŠŸçš„
    
    def handle_single_insert_mode(self, args: argparse.Namespace, start_date: str, end_date: str) -> bool:
        """
        å¤„ç†ä¸€æ¬¡æ€§æ’å…¥æ¨¡å¼ï¼ˆä¸æ¨èå¤§æ•°æ®é‡ä½¿ç”¨ï¼‰
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        logger.warning("âš ï¸ ä½¿ç”¨ä¸€æ¬¡æ€§æ’å…¥æ¨¡å¼ï¼Œå¤§æ•°æ®é‡å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜")
        
        # é¢„ä¼°æ—¶é—´
        estimated_time = self.fetcher.estimate_market_data_time(start_date, end_date, args.delay)
        logger.info(f"â° é¢„ä¼°è€—æ—¶: {estimated_time}")
        
        # è·å–å…¨å¸‚åœºæ•°æ®
        df = self.fetcher.get_all_market_data_by_dates(
            start_date=start_date,
            end_date=end_date, 
            delay=args.delay,
            exchange=args.exchange
        )
        
        if df.empty:
            logger.error("æœªè·å–åˆ°ä»»ä½•å…¨å¸‚åœºæ•°æ®")
            return False
        
        logger.info(f"ğŸ“Š å‡†å¤‡æ’å…¥ {len(df):,} æ¡è®°å½•åˆ°æ•°æ®åº“...")
        
        # å­˜å‚¨åˆ°æ•°æ®åº“
        logger.info("ğŸ’¾ å¼€å§‹ä¸€æ¬¡æ€§æ’å…¥å…¨å¸‚åœºæ•°æ®åˆ°MySQLæ•°æ®åº“...")
        with self.db:
            success = self.db.insert_daily_data(df)
            if success:
                logger.info("âœ… å…¨å¸‚åœºæ•°æ®å­˜å‚¨æˆåŠŸï¼")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats = self.db.get_stats()
                logger.info(f"ğŸ“Š æ•°æ®åº“æ€»è®°å½•æ•°: {stats.get('total_records', 0):,}")
                logger.info(f"ğŸ“ˆ æ¶‰åŠè‚¡ç¥¨æ•°é‡: {stats.get('stock_count', 0)}")
                return True
            else:
                logger.error("âŒ å…¨å¸‚åœºæ•°æ®å­˜å‚¨å¤±è´¥")
                return False
    
    def handle_stock_mode_data(self, args: argparse.Namespace, start_date: str, end_date: str) -> bool:
        """
        å¤„ç†è‚¡ç¥¨æ¨¡å¼çš„æ•°æ®è·å–ï¼ˆé€šè¿‡è‚¡ç¥¨ä»£ç å¾ªç¯ï¼‰
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        stock_codes = self.get_stock_codes(args)
        
        logger.info(f"ğŸ“Š ä½¿ç”¨è‚¡ç¥¨æ¨¡å¼è·å–æ•°æ®")
        logger.info(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {len(stock_codes)}åª")
        logger.info(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date or 'N/A'} åˆ° {end_date or 'ä»Šå¤©'}")
        logger.info(f"ğŸ”§ æ•°æ®è·å–æ¨¡å¼: {args.mode}")
        logger.info(f"âš™ï¸ æ‰¹æ¬¡å¤§å°: {args.batch_size}, å»¶è¿Ÿ: {args.delay}ç§’")
        
        # å¦‚æœè‚¡ç¥¨æ•°é‡å¾ˆå¤šï¼Œç»™å‡ºæç¤ºå’Œå»ºè®®
        if len(stock_codes) > 100:
            estimated_time = estimate_execution_time(len(stock_codes), args.delay, args.batch_size)
            logger.warning(f"âš ï¸  å³å°†è·å– {len(stock_codes)} åªè‚¡ç¥¨æ•°æ®ï¼Œé¢„è®¡éœ€è¦ {estimated_time}")
            logger.warning("ğŸ’¡ å»ºè®®ï¼šå¯¹äºå¤§æ‰¹é‡å†å²æ•°æ®ï¼Œæ¨èä½¿ç”¨ --market-mode å‚æ•°ï¼Œæ•ˆç‡æ›´é«˜")
            logger.info("   å¦‚éœ€æµ‹è¯•ï¼Œå¯ä½¿ç”¨ --limit å‚æ•°é™åˆ¶è‚¡ç¥¨æ•°é‡")
        
        # è·å–è‚¡ç¥¨æ•°æ®
        df = self.fetcher.get_multiple_stocks_data(
            stock_codes, start_date, end_date, 
            batch_size=args.batch_size, delay=args.delay
        )
        
        if df.empty:
            logger.warning("æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
            return False
        
        # å­˜å‚¨åˆ°æ•°æ®åº“
        logger.info("æ­£åœ¨å°†æ•°æ®å­˜å‚¨åˆ°MySQLæ•°æ®åº“...")
        with self.db:
            success = self.db.insert_daily_data(df)
            if success:
                logger.info("âœ… æ•°æ®å­˜å‚¨æˆåŠŸï¼")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats = self.db.get_stats()
                logger.info(f"ğŸ“Š æ•°æ®åº“æ€»è®°å½•æ•°: {stats.get('total_records', 0):,}")
                logger.info(f"ğŸ“ˆ æ¶‰åŠè‚¡ç¥¨æ•°é‡: {stats.get('stock_count', 0)}")
                return True
            else:
                logger.error("âŒ æ•°æ®å­˜å‚¨å¤±è´¥")
                return False
    
    def handle_sync_today(self, args: argparse.Namespace) -> Optional[bool]:
        """
        å¤„ç†åŒæ­¥ä»Šå¤©æ•°æ®çš„è¯·æ±‚
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            Optional[bool]: Noneè¡¨ç¤ºç»§ç»­æ‰§è¡Œï¼ŒTrueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        if not getattr(args, 'sync_today', False):
            return None
        
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥ä»Šå¤©çš„ä¸»æ¿æ•°æ®...")
        
        self.initialize_fetcher()
        
        # è·å–ä»Šå¤©çš„æ—¥æœŸ
        from datetime import datetime
        today = datetime.now().strftime('%Y%m%d')
        logger.info(f"ğŸ“… åŒæ­¥æ—¥æœŸ: {today}")
        
        # å°è¯•è·å–ä»Šæ—¥æ•°æ®ï¼Œå¦‚æœä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–æœ€æ–°äº¤æ˜“æ—¥æ•°æ®
        df = self.fetcher.get_daily_by_date(today)
        
        if df is None or df.empty:
            logger.info(f"ä»Šå¤©({today})å¯èƒ½ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œå°è¯•è·å–æœ€æ–°äº¤æ˜“æ—¥æ•°æ®...")
            
            # è·å–ä¸»æ¿è‚¡ç¥¨åˆ—è¡¨
            stock_codes = self.fetcher.get_main_board_stocks()
            if not stock_codes:
                logger.error("æ— æ³•è·å–ä¸»æ¿è‚¡ç¥¨åˆ—è¡¨")
                return False
            
            df = self.fetcher.get_latest_trading_day_data(stock_codes)
        
        if df is None or df.empty:
            logger.error("âŒ æ— æ³•è·å–ä»Šæ—¥æˆ–æœ€æ–°äº¤æ˜“æ—¥æ•°æ®")
            return False
        
        # è·å–äº¤æ˜“æ—¥æœŸ
        if 'trade_date' in df.columns and not df.empty:
            actual_date = df['trade_date'].iloc[0].strftime('%Y-%m-%d')
            logger.info(f"ğŸ“ˆ å®é™…æ•°æ®æ—¥æœŸ: {actual_date}")
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡ä¸»æ¿æ•°æ®")
        
        # æ’å…¥æ•°æ®åº“
        with self.db:
            success = self.db.insert_daily_data(df)
            if success:
                logger.info("âœ… ä»Šæ—¥ä¸»æ¿æ•°æ®åŒæ­¥æˆåŠŸï¼")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats = self.db.get_stats()
                logger.info(f"ğŸ“Š æ•°æ®åº“æ€»è®°å½•æ•°: {stats.get('total_records', 0):,}")
                logger.info(f"ğŸ“ˆ æ¶‰åŠè‚¡ç¥¨æ•°é‡: {stats.get('stock_count', 0)}")
                return True
            else:
                logger.error("âŒ ä»Šæ—¥æ•°æ®æ’å…¥æ•°æ®åº“å¤±è´¥")
                return False
    
    def handle_install_cron(self, args: argparse.Namespace) -> Optional[bool]:
        """
        å¤„ç†å®‰è£…cronä»»åŠ¡çš„è¯·æ±‚
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            Optional[bool]: Noneè¡¨ç¤ºç»§ç»­æ‰§è¡Œï¼ŒTrueè¡¨ç¤ºæ˜¾ç¤ºå®Œæˆ
        """
        if not getattr(args, 'install_cron', False):
            return None
        
        import os
        import sys
        
        # è·å–è„šæœ¬è·¯å¾„
        script_path = os.path.abspath(sys.argv[0])
        script_dir = os.path.dirname(script_path)
        python_path = sys.executable
        log_file = os.path.join(script_dir, "daily_sync.log")
        
        print("ğŸ”§ Linux Cron å®šæ—¶ä»»åŠ¡é…ç½®")
        print("=" * 80)
        print("æ¯å¤©18:00è‡ªåŠ¨åŒæ­¥å½“å¤©çš„Aè‚¡ä¸»æ¿æ•°æ®åˆ°MySQL")
        print()
        
        # cronä»»åŠ¡é…ç½®ï¼ˆæ¯å¤©18:00æ‰§è¡Œï¼Œåªåœ¨å·¥ä½œæ—¥ï¼‰
        cron_config = f"0 18 * * 1-5 cd {script_dir} && {python_path} {script_path} --sync-today >> {log_file} 2>&1"
        
        print("ğŸ“‹ Cronä»»åŠ¡é…ç½®ï¼š")
        print("-" * 80)
        print(cron_config)
        print("-" * 80)
        
        print("\\nğŸ“ å®‰è£…æ­¥éª¤ï¼š")
        steps = [
            "1. å¤åˆ¶ä¸Šé¢çš„croné…ç½®",
            "2. è¿è¡Œå‘½ä»¤: crontab -e", 
            "3. å°†é…ç½®ç²˜è´´åˆ°æ–‡ä»¶æœ«å°¾",
            "4. ä¿å­˜å¹¶é€€å‡ºç¼–è¾‘å™¨ï¼ˆé€šå¸¸æ˜¯Ctrl+X, Y, Enterï¼‰",
            "5. è¿è¡Œå‘½ä»¤: crontab -l ï¼ˆéªŒè¯ä»»åŠ¡å·²æ·»åŠ ï¼‰"
        ]
        
        for step in steps:
            print(f"   {step}")
        
        print("\\nğŸ’¡ é…ç½®è¯´æ˜ï¼š")
        print(f"   â° æ‰§è¡Œæ—¶é—´: æ¯å¤© 18:00ï¼ˆäº¤æ˜“ç»“æŸåï¼‰")
        print(f"   ğŸ“… æ‰§è¡Œæ—¥æœŸ: å‘¨ä¸€åˆ°å‘¨äº”ï¼ˆå·¥ä½œæ—¥ï¼‰")
        print(f"   ğŸ“ å·¥ä½œç›®å½•: {script_dir}")
        print(f"   ğŸ“œ æ—¥å¿—æ–‡ä»¶: {log_file}")
        print(f"   ğŸ Pythonè·¯å¾„: {python_path}")
        print(f"   ğŸ“Š æ•°æ®èŒƒå›´: Aè‚¡ä¸»æ¿æ‰€æœ‰è‚¡ç¥¨")
        
        print("\\nğŸ” ç›‘æ§å‘½ä»¤ï¼š")
        monitoring_commands = [
            ("æŸ¥çœ‹cronä»»åŠ¡", "crontab -l"),
            ("æŸ¥çœ‹åŒæ­¥æ—¥å¿—", f"tail -f {log_file}"),
            ("æ‰‹åŠ¨æµ‹è¯•åŒæ­¥", f"cd {script_dir} && python {script_path} --sync-today"),
            ("æŸ¥çœ‹æ•°æ®åº“çŠ¶æ€", f"cd {script_dir} && python {script_path} --stats"),
            ("åˆ é™¤cronä»»åŠ¡", "crontab -e ï¼ˆç„¶ååˆ é™¤å¯¹åº”è¡Œï¼‰")
        ]
        
        for desc, cmd in monitoring_commands:
            print(f"   {desc:<15}: {cmd}")
        
        print("\\nâœ… è®¾ç½®å®Œæˆåï¼Œç³»ç»Ÿå°†æ¯å¤©18:00è‡ªåŠ¨åŒæ­¥å½“å¤©çš„Aè‚¡ä¸»æ¿æ•°æ®ï¼")
        print("ğŸ”„ æ•°æ®ä¼šè‡ªåŠ¨å»é‡ï¼Œé‡å¤è¿è¡Œä¸ä¼šäº§ç”Ÿé‡å¤æ•°æ®")
        
        return True
    
    def run(self, args=None) -> int:
        """
        è¿è¡ŒCLIç¨‹åº
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            
        Returns:
            int: é€€å‡ºä»£ç ï¼Œ0è¡¨ç¤ºæˆåŠŸï¼Œ1è¡¨ç¤ºå¤±è´¥
        """
        try:
            # è§£æå‚æ•°
            parsed_args = self.parse_and_merge_args(args)
            
            # å¦‚æœåªæ˜¯æ˜¾ç¤ºé…ç½®ï¼Œåˆ™æ‰“å°å¹¶é€€å‡º
            if self.handle_show_config(parsed_args):
                return 0
            
            # å¤„ç†cronå®‰è£…è¯·æ±‚
            cron_result = self.handle_install_cron(parsed_args)
            if cron_result is not None:
                return 0 if cron_result else 1
            
            # å¤„ç†ä»Šæ—¥åŒæ­¥è¯·æ±‚
            sync_result = self.handle_sync_today(parsed_args)
            if sync_result is not None:
                return 0 if sync_result else 1
            
            # æ˜¾ç¤ºå½“å‰é…ç½®
            print_current_config(parsed_args)
            
            # å¤„ç†æ•°æ®åº“æ“ä½œ
            db_result = self.handle_database_operations(parsed_args)
            if db_result is not None:
                return 0 if db_result else 1
            
            # å¤„ç†ç‰¹å®šäº¤æ˜“æ—¥æ•°æ®è·å–
            trade_date_result = self.handle_trade_date_mode(parsed_args)
            if trade_date_result is not None:
                return 0 if trade_date_result else 1
            
            # å¤„ç†è·å–æœ€æ–°äº¤æ˜“æ—¥æ•°æ®
            latest_result = self.handle_latest_mode(parsed_args)
            if latest_result is not None:
                return 0 if latest_result else 1
            
            # å¤„ç†å†å²æ•°æ®è·å–
            if self.handle_historical_data(parsed_args):
                return 0
            else:
                return 1
                
        except Exception as e:
            logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            return 1
