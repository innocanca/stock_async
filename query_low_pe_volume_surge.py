#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸ¥è¯¢ä½ä¼°å€¼ä¸”å‘¨çº¿æ”¾é‡çš„ä¸»æ¿å¤§å¸‚å€¼è‚¡ç¥¨

ç­›é€‰æ¡ä»¶ï¼š
1. å¸‚åœºæ¿å—ï¼šä¸»æ¿ï¼ˆ60xxxx.SH / 00xxxx.SZï¼‰
2. æ€»å¸‚å€¼ï¼š> 500äº¿ï¼ˆtotal_mv >= 5,000,000 ä¸‡å…ƒï¼‰
3. ä¼°å€¼æŒ‡æ ‡ï¼šPE(TTM) <= 30
4. æˆäº¤é‡ï¼šæœ€è¿‘ä¸€å‘¨å‘¨çº¿æˆäº¤é‡ > è¿‡å»3å‘¨æ‰€æœ‰å‘¨æœ€å¤§æˆäº¤é‡ Ã— 1.3

ä½¿ç”¨æ–¹æ³•ï¼š
    python query_low_pe_volume_surge.py
"""

import sys
import os
from datetime import datetime, timedelta
from typing import List, Dict

import pandas as pd

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from database import StockDatabase
from fetcher import StockDataFetcher
from log_config import get_logger

logger = get_logger(__name__)


class LowPEVolumeSurgeAnalyzer:
    """ä½PE + å‘¨çº¿æ”¾é‡ ç­›é€‰å™¨"""

    def __init__(self):
        self.db = StockDatabase()
        self.fetcher = StockDataFetcher()

    def get_market_valuations(self, min_mv: float = 5000000, max_pe: float = 30) -> pd.DataFrame:
        """
        è·å–å¸‚åœºä¼°å€¼æ•°æ® (å¸‚å€¼ã€PE)ï¼Œå¹¶ç­›é€‰ä¸»æ¿ + å¤§å¸‚å€¼ + ä½PE

        Args:
            min_mv: æœ€å°æ€»å¸‚å€¼ï¼ˆä¸‡å…ƒï¼‰ï¼Œ500äº¿ = 5000000 ä¸‡å…ƒ
            max_pe: æœ€å¤§å¸‚ç›ˆç‡ï¼ˆTTMï¼‰
        """
        logger.info("ğŸ“Š è·å–å…¨å¸‚åœºä¼°å€¼æ•°æ®(daily_basic)...")

        try:
            df = None
            # å¾€å‰æœ€å¤šå›æº¯ 5 å¤©ï¼Œæ‰¾åˆ°æœ€è¿‘ä¸€ä¸ªæœ‰ daily_basic æ•°æ®çš„äº¤æ˜“æ—¥
            for i in range(5):
                trade_date = (datetime.now() - timedelta(days=i)).strftime('%Y%m%d')
                logger.info(f"   å°è¯•è·å– {trade_date} çš„ä¼°å€¼æ•°æ®...")
                try:
                    df = self.fetcher.pro.daily_basic(
                        trade_date=trade_date,
                        fields="ts_code,trade_date,close,pe_ttm,pb,total_mv"
                    )
                    if df is not None and not df.empty:
                        logger.info(f"   âœ… æˆåŠŸè·å– {len(df)} æ¡ä¼°å€¼æ•°æ®")
                        break
                except Exception as e:
                    logger.warning(f"   âš ï¸ è·å– {trade_date} æ•°æ®å¤±è´¥: {e}")

            if df is None or df.empty:
                logger.error("âŒ æ— æ³•è·å–ä¼°å€¼æ•°æ®ï¼Œå¯èƒ½æ˜¯æƒé™ä¸è¶³æˆ–è¿ç»­éäº¤æ˜“æ—¥")
                return pd.DataFrame()

            # ä¸»æ¿è¿‡æ»¤ï¼š60xxxx.SH / 00xxxx.SZ
            df = df[df["ts_code"].str.match(r"^(60|00)\d{4}\.(SH|SZ)$")]
            logger.info(f"   ä¸»æ¿è‚¡ç¥¨æ•°é‡: {len(df)}")

            # å¸‚å€¼è¿‡æ»¤ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼‰
            df = df[df["total_mv"] >= min_mv]
            logger.info(f"   å¸‚å€¼>{min_mv/10000:.0f}äº¿çš„è‚¡ç¥¨æ•°é‡: {len(df)}")

            # PE è¿‡æ»¤ï¼š0 < PE <= max_pe
            df = df[(df["pe_ttm"] > 0) & (df["pe_ttm"] <= max_pe)]
            logger.info(f"   PE(TTM)<={max_pe} çš„è‚¡ç¥¨æ•°é‡: {len(df)}")

            return df

        except Exception as e:
            logger.error(f"è·å–ä¼°å€¼æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_weekly_volume_surge(
        self,
        stock_codes: List[str],
        min_ratio: float = 1.3,
        lookback_weeks: int = 3,
    ) -> pd.DataFrame:
        """
        è®¡ç®—å‘¨çº¿æ”¾é‡æƒ…å†µ + åˆ¤æ–­æ˜¯å¦â€œåˆšå¯åŠ¨â€ï¼š
        - æ”¾é‡ï¼šæœ€è¿‘ä¸€å‘¨æˆäº¤é‡ / è¿‡å» N å‘¨ã€Œæœ€å¤§æˆäº¤é‡ã€
        - åˆšå¯åŠ¨ï¼ˆå¯åŠ¨è½¦é€»è¾‘ï¼‰ç²—ç•¥å®šä¹‰ï¼š
            * å‰ 3 å‘¨ç´¯è®¡æ¶¨è·Œå¹… < 10%ï¼ˆä¹‹å‰ä»¥éœ‡è¡/æ•´ç†ä¸ºä¸»ï¼‰
            * è¿‡å»ä¸€å¹´ä»·æ ¼ä½ç½®ä»åœ¨åŒºé—´ä¸‹åŠéƒ¨ï¼ˆæœªå¤§å¹…æ‹‰å‡ï¼Œposition_1y <= 0.5ï¼‰

        Args:
            stock_codes: å¾…æ£€æµ‹è‚¡ç¥¨åˆ—è¡¨
            min_ratio: æœ€å°æ”¾é‡å€æ•°ï¼Œä¾‹å¦‚ 1.3 è¡¨ç¤ºæœ€è¿‘ä¸€å‘¨ > è¿‡å»Nå‘¨æœ€å¤§æˆäº¤é‡çš„1.3å€
            lookback_weeks: å›çœ‹å‘¨æ•°ï¼Œç”¨äºè®¡ç®—å†å²æœ€å¤§æˆäº¤é‡
        """
        logger.info(
            f"ğŸ“ˆ è®¡ç®—å‘¨çº¿æ”¾é‡ï¼šæœ€è¿‘ä¸€å‘¨ vs è¿‡å»{lookback_weeks}å‘¨æœ€å¤§æˆäº¤é‡ï¼Œé˜ˆå€¼ {min_ratio} å€..."
        )

        if not stock_codes:
            return pd.DataFrame()

        try:
            # è·å–æœ€è¿‘ä¸€å‘¨çš„ trade_date
            cursor = self.db.connection.cursor()
            cursor.execute("SELECT MAX(trade_date) FROM weekly_data")
            result = cursor.fetchone()
            latest_week = result[0]

            if not latest_week:
                logger.error("âŒ weekly_data è¡¨ä¸­æ²¡æœ‰ä»»ä½•å‘¨çº¿æ•°æ®")
                return pd.DataFrame()

            logger.info(f"   æœ€è¿‘å‘¨çº¿æ—¥æœŸ: {latest_week}")

            # ä»æœ€è¿‘å‘¨çº¿å¾€å‰æŠ“ä¸€æ®µçª—å£ï¼ˆçº¦1å¹´ï¼‰ï¼Œç”¨äºæ”¾é‡å’Œâ€œåˆšå¯åŠ¨â€åˆ¤æ–­
            placeholders = ",".join(["%s"] * len(stock_codes))
            query_sql = f"""
            SELECT ts_code, trade_date, vol, close, pct_chg, high, low
            FROM weekly_data
            WHERE trade_date <= %s
              AND trade_date >= DATE_SUB(%s, INTERVAL 365 DAY)
              AND ts_code IN ({placeholders})
            ORDER BY ts_code, trade_date
            """

            params = [latest_week, latest_week] + stock_codes
            df = pd.read_sql(query_sql, self.db.connection, params=params)

            if df.empty:
                logger.warning("âš ï¸ æœªæŸ¥è¯¢åˆ°ä»»ä½•å‘¨çº¿æ•°æ®")
                return pd.DataFrame()

            results = []
            for ts_code, g in df.groupby("ts_code"):
                g = g.sort_values("trade_date")
                if len(g) < lookback_weeks + 1:
                    continue

                last_rows = g.tail(lookback_weeks + 1)
                if len(last_rows) < lookback_weeks + 1:
                    continue

                last_week_row = last_rows.iloc[-1]
                prev_weeks = last_rows.iloc[:-1]

                # ä½¿ç”¨è¿‡å» N å‘¨ä¸­çš„ã€Œæœ€å¤§æˆäº¤é‡ã€ä½œä¸ºå¯¹æ¯”åŸºå‡†
                prev_max_vol = prev_weeks["vol"].max()
                last_vol = last_week_row["vol"]
                if prev_max_vol is None or prev_max_vol <= 0:
                    continue

                ratio = last_vol / prev_max_vol

                # ===== â€œåˆšå¯åŠ¨â€åˆ¤æ–­é€»è¾‘ =====
                last_pct = float(last_week_row.get("pct_chg") or 0)
                prev3_sum_pct = float(prev_weeks["pct_chg"].sum() if "pct_chg" in prev_weeks.columns else 0)

                # è¿‡å»ä¸€å¹´ä»·æ ¼åŒºé—´ä½ç½®ï¼ˆåŸºäºå½“å‰æŸ¥è¯¢çª—å£å†…çš„å‘¨çº¿æ•°æ®ï¼‰
                window_1y = g  # å·²ç»æŒ‰SQLé™åˆ¶åœ¨ä¸€å¹´å†…
                high_1y = window_1y["high"].max()
                low_1y = window_1y["low"].min()
                pos_1y = None
                if (
                    high_1y is not None
                    and low_1y is not None
                    and pd.notna(high_1y)
                    and pd.notna(low_1y)
                    and high_1y > low_1y
                ):
                    pos_1y = (float(last_week_row["close"]) - float(low_1y)) / (float(high_1y) - float(low_1y))

                is_startup = (
                    ratio >= min_ratio
                    and prev3_sum_pct < 10.0
                    and pos_1y is not None
                    and pos_1y <= 0.5
                )

                if ratio >= min_ratio:
                    results.append(
                        {
                            "ts_code": ts_code,
                            "latest_week": last_week_row["trade_date"],
                            "last_week_vol": float(last_vol),
                            "max_prev_vol": float(prev_max_vol),
                            "volume_ratio": float(ratio),
                            "last_week_pct_chg": last_pct,
                            "prev3_sum_pct_chg": prev3_sum_pct,
                            "position_1y": float(pos_1y) if pos_1y is not None else None,
                            "is_startup": bool(is_startup),
                        }
                    )

            surge_df = pd.DataFrame(results)
            logger.info(f"   å‘¨çº¿æ”¾é‡>= {min_ratio} å€çš„è‚¡ç¥¨æ•°é‡: {len(surge_df)}")
            return surge_df

        except Exception as e:
            logger.error(f"è®¡ç®—å‘¨çº¿æ”¾é‡å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_stock_names(self, stock_codes: List[str]) -> Dict[str, str]:
        """ä»æœ¬åœ° stock_basic è¡¨è·å–è‚¡ç¥¨åç§°"""
        names: Dict[str, str] = {}
        if not stock_codes:
            return names
        
        try:
            # å•ç‹¬å¼€å¯ä¸€ä¸ªæ•°æ®åº“è¿æ¥ï¼Œé¿å…ä¾èµ–å¤–éƒ¨ä¸Šä¸‹æ–‡çš„è¿æ¥çŠ¶æ€
            from database import StockDatabase as _DB  # é¿å…ç±»å‹æ£€æŸ¥å¹²æ‰°
            with _DB() as db:
                cursor = db.connection.cursor()
                placeholders = ",".join(["%s"] * len(stock_codes))
                sql = f"SELECT ts_code, name FROM stock_basic WHERE ts_code IN ({placeholders})"
                cursor.execute(sql, stock_codes)
                for ts_code, name in cursor.fetchall():
                    names[ts_code] = name
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")

        return names

    def run_analysis(self):
        """æ‰§è¡Œç»¼åˆç­›é€‰ï¼šPE + å¸‚å€¼ + å‘¨çº¿æ”¾é‡"""
        logger.info(
            "ğŸš€ å¼€å§‹ç­›é€‰ï¼šä¸»æ¿ã€å¸‚å€¼>500äº¿ã€PE<=30 ä¸”æœ€è¿‘ä¸€å‘¨å‘¨çº¿æ”¾é‡>=2å€ çš„è‚¡ç¥¨..."
        )

        # 1. å…ˆä»ä¼°å€¼ç»´åº¦ç­›é€‰å‡ºä¸»æ¿+å¤§å¸‚å€¼+ä½PE
        df_valuation = self.get_market_valuations(min_mv=5000000, max_pe=30)
        if df_valuation.empty:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆä¼°å€¼æ¡ä»¶çš„è‚¡ç¥¨")
            return

        target_codes = df_valuation["ts_code"].tolist()

        with self.db:
            # 2. åœ¨ä¼°å€¼åˆæ ¼çš„è‚¡ç¥¨é‡Œï¼Œå†ç­›é€‰å‘¨çº¿æ”¾é‡
            surge_df = self.get_weekly_volume_surge(
                stock_codes=target_codes, min_ratio=1.3, lookback_weeks=3
            )
            if surge_df.empty:
                logger.warning("åœ¨ç¬¦åˆä¼°å€¼æ¡ä»¶çš„è‚¡ç¥¨ä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°æ»¡è¶³ã€Œæœ€è¿‘ä¸€å‘¨ > è¿‡å»3å‘¨æœ€å¤§æˆäº¤é‡Ã—1.3ã€çš„æ ‡çš„")
                return

        # 3. åˆå¹¶ä¼°å€¼ + å‘¨çº¿æ”¾é‡ä¿¡æ¯
        merged = pd.merge(df_valuation, surge_df, on="ts_code", how="inner")
        if merged.empty:
            logger.warning("ä¼°å€¼æ•°æ®ä¸å‘¨çº¿æ”¾é‡æ•°æ®åˆå¹¶åä¸ºç©º")
            return

        # 3.1 åªä¿ç•™â€œä¸€å¹´å†…åŒºé—´ä½ç½®åœ¨ä¸‹åŠéƒ¨â€çš„æ ‡çš„
        if "position_1y" in merged.columns:
            before_cnt = len(merged)
            merged = merged[merged["position_1y"].notna() & (merged["position_1y"] <= 0.5)].copy()
            logger.info(f"   æŒ‰ä¸€å¹´åŒºé—´ä¸‹åŠéƒ¨è¿‡æ»¤: {before_cnt} -> {len(merged)} åª")
            if merged.empty:
                logger.warning("å½“å‰æ²¡æœ‰æ»¡è¶³â€œä¸€å¹´å†…åŒºé—´ä½ç½®åœ¨ä¸‹åŠéƒ¨â€çš„æ ‡çš„")
                return

        # 4. è·å–è‚¡ç¥¨åç§°
        stock_names = self.get_stock_names(merged["ts_code"].tolist())

        # 5. ç»„ç»‡æœ€ç»ˆç»“æœ
        final_rows = []
        for _, row in merged.iterrows():
            ts_code = row["ts_code"]
            final_rows.append(
                {
                    "ä»£ç ": ts_code,
                    "åç§°": stock_names.get(ts_code, ts_code),
                    "å¸‚å€¼(äº¿)": row["total_mv"] / 10000,
                    "PE(TTM)": row["pe_ttm"],
                    "PB": row["pb"],
                    "ç°ä»·": row["close"],
                    "æœ€è¿‘å‘¨çº¿æ—¥æœŸ": row["latest_week"],
                    "æœ€è¿‘ä¸€å‘¨æˆäº¤é‡": row["last_week_vol"],
                    "è¿‡å»3å‘¨æœ€å¤§æˆäº¤é‡": row["max_prev_vol"],
                    "å‘¨æ”¾é‡å€æ•°": row["volume_ratio"],
                    "æ˜¯å¦åˆšå¯åŠ¨": bool(row.get("is_startup", False)),
                    "æœ€è¿‘å‘¨æ¶¨è·Œå¹…%": row.get("last_week_pct_chg"),
                    "å‰ä¸‰å‘¨ç´¯è®¡æ¶¨è·Œå¹…%": row.get("prev3_sum_pct_chg"),
                    "ä¸€å¹´åŒºé—´ä½ç½®": row.get("position_1y"),
                }
            )

        if not final_rows:
            logger.warning("æ²¡æœ‰æœ€ç»ˆç»“æœ")
            return

        final_df = pd.DataFrame(final_rows)
        # ä¼˜å…ˆæŒ‰â€œåˆšå¯åŠ¨â€æ ‡è®°æ’åºï¼Œå…¶æ¬¡æŒ‰æ”¾é‡å€æ•° + æœ€è¿‘å‘¨æ¶¨å¹…ï¼Œå†æŒ‰å¸‚å€¼ä»å¤§åˆ°å°
        final_df = final_df.sort_values(
            by=["æ˜¯å¦åˆšå¯åŠ¨", "å‘¨æ”¾é‡å€æ•°", "æœ€è¿‘å‘¨æ¶¨è·Œå¹…%", "å¸‚å€¼(äº¿)"],
            ascending=[False, False, False, False],
        )

        logger.info(
            f"\nğŸ‰ ç­›é€‰ç»“æœ (ä¸»æ¿, å¸‚å€¼>500äº¿, PE<=20, æœ€è¿‘ä¸€å‘¨ > è¿‡å»3å‘¨æœ€å¤§æˆäº¤é‡Ã—1.3): å…± {len(final_df)} åª"
        )
        logger.info("=" * 140)
        logger.info(
            f"{'ä»£ç ':<10} {'åç§°':<10} {'å¸‚å€¼(äº¿)':<10} {'PE(TTM)':<10} {'PB':<8} "
            f"{'ç°ä»·':<8} {'å‘¨æ”¾é‡å€æ•°':<12} {'åˆšå¯åŠ¨':<8} {'æœ€è¿‘å‘¨æ¶¨å¹…%':<12} {'æœ€è¿‘å‘¨çº¿':<12}"
        )
        logger.info("-" * 140)

        for _, r in final_df.iterrows():
            startup_flag = "æ˜¯" if r.get("æ˜¯å¦åˆšå¯åŠ¨") else "å¦"
            logger.info(
                f"{r['ä»£ç ']:<10} {r['åç§°']:<10} "
                f"{r['å¸‚å€¼(äº¿)']:<10.1f} {r['PE(TTM)']:<10.2f} {r['PB']:<8.2f} "
                f"{r['ç°ä»·']:<8.2f} {r['å‘¨æ”¾é‡å€æ•°']:<12.2f} "
                f"{startup_flag:<8} {(r['æœ€è¿‘å‘¨æ¶¨è·Œå¹…%'] or 0):<12.2f} {str(r['æœ€è¿‘å‘¨çº¿æ—¥æœŸ'])[:10]:<12}"
            )

        logger.info("=" * 140)

        # 6. ä¿å­˜åˆ° CSV
        output_file = (
            f"low_pe_volume_surge_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        )
        final_df.to_csv(output_file, index=False, encoding="utf-8-sig")
        logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_file}")


if __name__ == "__main__":
    analyzer = LowPEVolumeSurgeAnalyzer()
    analyzer.run_analysis()


