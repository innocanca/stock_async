#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸ¥è¯¢å‘¨çº¿ä¸‰è¿å°é˜³åŠä»¥ä¸Šçš„åƒäº¿å¸‚å€¼ä¸»æ¿è‚¡ç¥¨

åŠŸèƒ½ï¼š
1. åˆ†ææœ€è¿‘çš„å‘¨çº¿èµ°åŠ¿
2. è¯†åˆ«è¿ç»­é˜³çº¿ï¼ˆæ”¶ç›˜ä»·>å¼€ç›˜ä»·ï¼‰
3. ç­›é€‰1000äº¿ä»¥ä¸Šå¸‚å€¼è‚¡ç¥¨
4. æŒ‰è¿ç»­é˜³çº¿å‘¨æ•°æ’åº

ä½¿ç”¨æ–¹æ³•ï¼š
python query_consecutive_yang_lines.py
"""

import logging
import sys
import os
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥æ ¹ç›®å½•ä¸‹çš„ database / fetcher / log_config
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from database import StockDatabase
from fetcher import StockDataFetcher

# é…ç½®æ—¥å¿—
from log_config import get_logger
logger = get_logger(__name__)


class ConsecutiveYangLinesAnalyzer:
    """è¿ç»­é˜³çº¿åˆ†æå™¨"""
    
    def __init__(self):
        self.db = StockDatabase()
        self.fetcher = StockDataFetcher()
        
        # 1000äº¿ä»¥ä¸Šå¸‚å€¼çš„çŸ¥åä¸»æ¿è‚¡ç¥¨åˆ—è¡¨ï¼ˆæŒ‰2024å¹´å¸‚å€¼æ’åºï¼‰
        self.mega_cap_stocks = {
            # ä¸‡äº¿çº§å¸‚å€¼è‚¡ç¥¨
            '600519.SH': {'name': 'è´µå·èŒ…å°', 'market_cap': '20000+', 'industry': 'ç™½é…’'},
            '601318.SH': {'name': 'ä¸­å›½å¹³å®‰', 'market_cap': '15000+', 'industry': 'ä¿é™©'},
            '601398.SH': {'name': 'å·¥å•†é“¶è¡Œ', 'market_cap': '15000+', 'industry': 'é“¶è¡Œ'},
            '601939.SH': {'name': 'å»ºè®¾é“¶è¡Œ', 'market_cap': '12000+', 'industry': 'é“¶è¡Œ'},
            '000858.SZ': {'name': 'äº”ç²®æ¶²', 'market_cap': '8000+', 'industry': 'ç™½é…’'},
            '000333.SZ': {'name': 'ç¾çš„é›†å›¢', 'market_cap': '7000+', 'industry': 'å®¶ç”µ'},
            '002594.SZ': {'name': 'æ¯”äºšè¿ª', 'market_cap': '7000+', 'industry': 'æ–°èƒ½æºæ±½è½¦'},
            '600036.SH': {'name': 'æ‹›å•†é“¶è¡Œ', 'market_cap': '6000+', 'industry': 'é“¶è¡Œ'},
            
            # 5000-10000äº¿å¸‚å€¼è‚¡ç¥¨
            '601988.SH': {'name': 'ä¸­å›½é“¶è¡Œ', 'market_cap': '5000+', 'industry': 'é“¶è¡Œ'},
            '600887.SH': {'name': 'ä¼Šåˆ©è‚¡ä»½', 'market_cap': '4000+', 'industry': 'é£Ÿå“é¥®æ–™'},
            '000001.SZ': {'name': 'å¹³å®‰é“¶è¡Œ', 'market_cap': '3500+', 'industry': 'é“¶è¡Œ'},
            '002415.SZ': {'name': 'æµ·åº·å¨è§†', 'market_cap': '3500+', 'industry': 'å®‰é˜²'},
            '000002.SZ': {'name': 'ä¸‡ç§‘A', 'market_cap': '3000+', 'industry': 'æˆ¿åœ°äº§'},
            '600900.SH': {'name': 'é•¿æ±Ÿç”µåŠ›', 'market_cap': '3000+', 'industry': 'ç”µåŠ›'},
            '600276.SH': {'name': 'æ’ç‘åŒ»è¯', 'market_cap': '3000+', 'industry': 'åŒ»è¯'},
            '002475.SZ': {'name': 'ç«‹è®¯ç²¾å¯†', 'market_cap': '2800+', 'industry': 'æ¶ˆè´¹ç”µå­'},
            '601166.SH': {'name': 'å…´ä¸šé“¶è¡Œ', 'market_cap': '2500+', 'industry': 'é“¶è¡Œ'},
            '000063.SZ': {'name': 'ä¸­å…´é€šè®¯', 'market_cap': '2500+', 'industry': 'é€šä¿¡è®¾å¤‡'},
            '600030.SH': {'name': 'ä¸­ä¿¡è¯åˆ¸', 'market_cap': '2500+', 'industry': 'åˆ¸å•†'},
            '002714.SZ': {'name': 'ç‰§åŸè‚¡ä»½', 'market_cap': '2500+', 'industry': 'å†œä¸š'},
            
            # 2000-3000äº¿å¸‚å€¼è‚¡ç¥¨
            '601328.SH': {'name': 'äº¤é€šé“¶è¡Œ', 'market_cap': '2000+', 'industry': 'é“¶è¡Œ'},
            '600585.SH': {'name': 'æµ·èºæ°´æ³¥', 'market_cap': '2000+', 'industry': 'å»ºæ'},
            '000876.SZ': {'name': 'æ–°å¸Œæœ›', 'market_cap': '2000+', 'industry': 'å†œä¸š'},
            '600660.SH': {'name': 'ç¦è€€ç»ç’ƒ', 'market_cap': '2000+', 'industry': 'æ±½è½¦é›¶éƒ¨ä»¶'},
            '002304.SZ': {'name': 'æ´‹æ²³è‚¡ä»½', 'market_cap': '2000+', 'industry': 'ç™½é…’'},
            '000895.SZ': {'name': 'åŒæ±‡å‘å±•', 'market_cap': '1800+', 'industry': 'é£Ÿå“é¥®æ–™'},
            '600809.SH': {'name': 'å±±è¥¿æ±¾é…’', 'market_cap': '1800+', 'industry': 'ç™½é…’'},
            '002032.SZ': {'name': 'è‹æ³Šå°”', 'market_cap': '1800+', 'industry': 'å®¶ç”µ'},
            '002241.SZ': {'name': 'æ­Œå°”è‚¡ä»½', 'market_cap': '1800+', 'industry': 'æ¶ˆè´¹ç”µå­'},
            '002230.SZ': {'name': 'ç§‘å¤§è®¯é£', 'market_cap': '1800+', 'industry': 'äººå·¥æ™ºèƒ½'},
            
            # 1000-2000äº¿å¸‚å€¼è‚¡ç¥¨
            '600048.SH': {'name': 'ä¿åˆ©å‘å±•', 'market_cap': '1500+', 'industry': 'æˆ¿åœ°äº§'},
            '000338.SZ': {'name': 'æ½æŸ´åŠ¨åŠ›', 'market_cap': '1500+', 'industry': 'æœºæ¢°è®¾å¤‡'},
            '601601.SH': {'name': 'ä¸­å›½å¤ªä¿', 'market_cap': '1500+', 'industry': 'ä¿é™©'},
            '601628.SH': {'name': 'ä¸­å›½äººå¯¿', 'market_cap': '1500+', 'industry': 'ä¿é™©'},
            '600028.SH': {'name': 'ä¸­å›½çŸ³åŒ–', 'market_cap': '1500+', 'industry': 'çŸ³æ²¹åŒ–å·¥'},
            '601857.SH': {'name': 'ä¸­å›½çŸ³æ²¹', 'market_cap': '1500+', 'industry': 'çŸ³æ²¹åŒ–å·¥'},
            '600031.SH': {'name': 'ä¸‰ä¸€é‡å·¥', 'market_cap': '1400+', 'industry': 'æœºæ¢°è®¾å¤‡'},
            '002352.SZ': {'name': 'é¡ºä¸°æ§è‚¡', 'market_cap': '1400+', 'industry': 'ç‰©æµ'},
            '000100.SZ': {'name': 'TCLç§‘æŠ€', 'market_cap': '1300+', 'industry': 'æ¶ˆè´¹ç”µå­'},
            '600570.SH': {'name': 'æ’ç”Ÿç”µå­', 'market_cap': '1300+', 'industry': 'è½¯ä»¶'},
            '002027.SZ': {'name': 'åˆ†ä¼—ä¼ åª’', 'market_cap': '1200+', 'industry': 'ä¼ åª’'},
            '002142.SZ': {'name': 'å®æ³¢é“¶è¡Œ', 'market_cap': '1200+', 'industry': 'é“¶è¡Œ'},
            '000157.SZ': {'name': 'ä¸­è”é‡ç§‘', 'market_cap': '1200+', 'industry': 'æœºæ¢°è®¾å¤‡'},
            '002202.SZ': {'name': 'é‡‘é£ç§‘æŠ€', 'market_cap': '1200+', 'industry': 'é£ç”µ'},
            '601012.SH': {'name': 'éš†åŸºç»¿èƒ½', 'market_cap': '1200+', 'industry': 'å…‰ä¼'},
            '600104.SH': {'name': 'ä¸Šæ±½é›†å›¢', 'market_cap': '1200+', 'industry': 'æ±½è½¦'},
            '000166.SZ': {'name': 'ç”³ä¸‡å®æº', 'market_cap': '1100+', 'industry': 'åˆ¸å•†'},
            '002236.SZ': {'name': 'å¤§åè‚¡ä»½', 'market_cap': '1100+', 'industry': 'å®‰é˜²'},
            '601668.SH': {'name': 'ä¸­å›½å»ºç­‘', 'market_cap': '1100+', 'industry': 'å»ºç­‘'},
            '600690.SH': {'name': 'æµ·å°”æ™ºå®¶', 'market_cap': '1000+', 'industry': 'å®¶ç”µ'},
        }
    
    def get_mega_cap_weekly_data(self, weeks_back: int = 12) -> Optional[pd.DataFrame]:
        """
        è·å–åƒäº¿å¸‚å€¼è‚¡ç¥¨çš„å‘¨çº¿æ•°æ®
        
        Args:
            weeks_back: å›æº¯å‘¨æ•°
            
        Returns:
            pd.DataFrame: å‘¨çº¿æ•°æ®
        """
        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            end_date = datetime.now()
            start_date = end_date - timedelta(weeks=weeks_back)
            
            start_date_str = start_date.strftime('%Y-%m-%d')
            end_date_str = end_date.strftime('%Y-%m-%d')
            
            logger.info(f"è·å–åƒäº¿å¸‚å€¼è‚¡ç¥¨ {start_date_str} è‡³ {end_date_str} çš„å‘¨çº¿æ•°æ®...")
            
            with self.db:
                df = self.db.query_weekly_data(
                    start_date=start_date_str,
                    end_date=end_date_str
                )
                
                if df is None or df.empty:
                    logger.error("æœªæ‰¾åˆ°å‘¨çº¿æ•°æ®")
                    return None
                
                # åªä¿ç•™åƒäº¿å¸‚å€¼è‚¡ç¥¨
                mega_cap_df = df[df['ts_code'].isin(self.mega_cap_stocks.keys())].copy()
                
                if mega_cap_df.empty:
                    logger.error("æœªæ‰¾åˆ°åƒäº¿å¸‚å€¼è‚¡ç¥¨çš„å‘¨çº¿æ•°æ®")
                    return None
                
                logger.info(f"è·å–åˆ° {len(mega_cap_df)} æ¡åƒäº¿å¸‚å€¼è‚¡ç¥¨å‘¨çº¿è®°å½•ï¼Œæ¶µç›– {mega_cap_df['ts_code'].nunique()} åªè‚¡ç¥¨")
                return mega_cap_df
                
        except Exception as e:
            logger.error(f"è·å–å‘¨çº¿æ•°æ®å¤±è´¥: {e}")
            return None
    
    def analyze_consecutive_yang_lines(self, df: pd.DataFrame, min_consecutive: int = 3) -> pd.DataFrame:
        """
        åˆ†æè¿ç»­é˜³çº¿
        
        Args:
            df: å‘¨çº¿æ•°æ®
            min_consecutive: æœ€å°‘è¿ç»­é˜³çº¿å‘¨æ•°
            
        Returns:
            pd.DataFrame: åŒ…å«è¿ç»­é˜³çº¿åˆ†æçš„æ•°æ®
        """
        try:
            results = []
            
            for ts_code in df['ts_code'].unique():
                stock_data = df[df['ts_code'] == ts_code].copy()
                stock_data = stock_data.sort_values('trade_date')
                
                if len(stock_data) < min_consecutive:
                    continue
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºé˜³çº¿ï¼šæ”¶ç›˜ä»· > å¼€ç›˜ä»·
                stock_data['is_yang'] = stock_data['close'] > stock_data['open']
                
                # è®¡ç®—ä»æœ€æ–°ä¸€å‘¨å¼€å§‹å¾€å‰çš„è¿ç»­é˜³çº¿æ•°é‡
                consecutive_yang = 0
                for i in range(len(stock_data) - 1, -1, -1):
                    if stock_data.iloc[i]['is_yang']:
                        consecutive_yang += 1
                    else:
                        break
                
                # åªä¿ç•™è¾¾åˆ°æœ€å°‘è¿ç»­é˜³çº¿è¦æ±‚çš„è‚¡ç¥¨
                if consecutive_yang >= min_consecutive:
                    latest_record = stock_data.iloc[-1]
                    stock_info = self.mega_cap_stocks.get(ts_code, {})
                    
                    # è®¡ç®—æœ€è¿‘å‡ å‘¨çš„æ¶¨è·Œå¹…
                    recent_weeks = min(consecutive_yang, len(stock_data))
                    start_price = stock_data.iloc[-recent_weeks]['open']
                    end_price = latest_record['close']
                    total_return = ((end_price - start_price) / start_price * 100) if start_price > 0 else 0
                    
                    results.append({
                        'ts_code': ts_code,
                        'stock_name': stock_info.get('name', 'æœªçŸ¥'),
                        'market_cap': stock_info.get('market_cap', 'æœªçŸ¥'),
                        'industry': stock_info.get('industry', 'å…¶ä»–'),
                        'consecutive_yang_weeks': consecutive_yang,
                        'latest_trade_date': latest_record['trade_date'],
                        'latest_close': latest_record['close'],
                        'latest_open': latest_record['open'],
                        'latest_pct_chg': latest_record['pct_chg'],
                        'latest_vol': latest_record['vol'],
                        'latest_amount': latest_record['amount'],
                        'total_return_during_yang': total_return,
                        'avg_weekly_return': total_return / consecutive_yang if consecutive_yang > 0 else 0
                    })
            
            if not results:
                logger.warning(f"æœªæ‰¾åˆ°è¿ç»­{min_consecutive}å‘¨ä»¥ä¸Šé˜³çº¿çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
                return pd.DataFrame()
            
            result_df = pd.DataFrame(results)
            # æŒ‰è¿ç»­é˜³çº¿å‘¨æ•°æ’åºï¼Œç„¶åæŒ‰å¸‚å€¼æ’åº
            result_df = result_df.sort_values(['consecutive_yang_weeks', 'total_return_during_yang'], ascending=[False, False])
            
            logger.info(f"æ‰¾åˆ° {len(result_df)} åªè¿ç»­é˜³çº¿çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
            return result_df
            
        except Exception as e:
            logger.error(f"åˆ†æè¿ç»­é˜³çº¿å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def analyze_mega_cap_yang_lines(self) -> Optional[pd.DataFrame]:
        """
        ä¸»åˆ†æå‡½æ•°ï¼šæ‰¾åˆ°å‘¨çº¿ä¸‰è¿é˜³åŠä»¥ä¸Šçš„åƒäº¿å¸‚å€¼ä¸»æ¿è‚¡ç¥¨
        
        Returns:
            pd.DataFrame: åˆ†æç»“æœ
        """
        results = self.get_analysis_results(min_consecutive=3)
        if not results:
            return pd.DataFrame()
        return pd.DataFrame(results)

    def get_analysis_results(self, min_consecutive: int = 3) -> List[Dict]:
        """
        è·å–åˆ†æç»“æœåˆ—è¡¨ï¼Œä¾› API è°ƒç”¨ã€‚
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹åˆ†æå‘¨çº¿è¿ç»­é˜³çº¿ï¼šæœ€å°‘ {min_consecutive} å‘¨...")
            logger.info(f"ğŸ“Š åˆ†æèŒƒå›´ï¼š{len(self.mega_cap_stocks)} åªåƒäº¿å¸‚å€¼è‚¡ç¥¨")
            
            # 1. è·å–åƒäº¿å¸‚å€¼è‚¡ç¥¨çš„å‘¨çº¿æ•°æ®
            weekly_df = self.get_mega_cap_weekly_data(weeks_back=12)
            if weekly_df is None or weekly_df.empty:
                return []
            
            # 2. åˆ†æè¿ç»­é˜³çº¿
            result_df = self.analyze_consecutive_yang_lines(weekly_df, min_consecutive=min_consecutive)
            
            # å¦‚æœ 3 å‘¨æ²¡æœ‰ç»“æœï¼Œè‡ªåŠ¨å°è¯• 2 å‘¨
            if result_df.empty and min_consecutive >= 3:
                logger.info(f"æœªæ‰¾åˆ°è¿ç»­ {min_consecutive} å‘¨é˜³çº¿ï¼Œå°è¯•é™ä½åˆ° 2 å‘¨...")
                result_df = self.analyze_consecutive_yang_lines(weekly_df, min_consecutive=2)
            
            if result_df.empty:
                return []
            
            # 3. è½¬æ¢æ•°å€¼ç±»å‹ä¸ºæ ‡å‡† Python ç±»å‹ï¼Œé¿å… JSON åºåˆ—åŒ–é”™è¯¯
            records = result_df.to_dict(orient="records")
            for r in records:
                for k, v in r.items():
                    if pd.isna(v):
                        r[k] = None
                    elif hasattr(v, 'item'): # numpy types
                        r[k] = v.item()
            
            return records
            
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return []


def display_yang_lines_results(df: pd.DataFrame):
    """
    æ˜¾ç¤ºè¿ç»­é˜³çº¿åˆ†æç»“æœ
    
    Args:
        df: åˆ†æç»“æœæ•°æ®
    """
    if df is None or df.empty:
        logger.error("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
        return
    
    logger.info("ğŸ“‹ ç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨åˆ—è¡¨ï¼ˆå‘¨çº¿è¿ç»­é˜³çº¿ï¼‰ï¼š")
    logger.info("=" * 130)
    logger.info(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<12} {'è‚¡ç¥¨åç§°':<12} {'å¸‚å€¼(äº¿)':<10} {'è¡Œä¸š':<12} {'è¿ç»­é˜³çº¿':<8} {'æœ€æ–°ä»·':<8} {'æ€»æ¶¨å¹…%':<8} {'å‘¨å‡æ¶¨å¹…%':<10}")
    logger.info("=" * 130)
    
    for i, (_, row) in enumerate(df.iterrows(), 1):
        logger.info(
            f"{i:<4} "
            f"{row['ts_code']:<12} "
            f"{row['stock_name']:<12} "
            f"{row['market_cap']:<10} "
            f"{row['industry']:<12} "
            f"{row['consecutive_yang_weeks']:<8}å‘¨ "
            f"{row['latest_close']:<8.2f} "
            f"{row['total_return_during_yang']:<8.2f} "
            f"{row['avg_weekly_return']:<10.2f}"
        )
    
    logger.info("=" * 130)
    logger.info(f"æ€»å…±æ‰¾åˆ° {len(df)} åªç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
    
    # ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    logger.info(f"   å¹³å‡è¿ç»­é˜³çº¿å‘¨æ•°: {df['consecutive_yang_weeks'].mean():.1f}å‘¨")
    logger.info(f"   æœ€å¤šè¿ç»­é˜³çº¿å‘¨æ•°: {df['consecutive_yang_weeks'].max()}å‘¨")
    logger.info(f"   å¹³å‡è¿ç»­é˜³çº¿æœŸé—´æ¶¨å¹…: {df['total_return_during_yang'].mean():.2f}%")
    logger.info(f"   å¹³å‡å‘¨æ¶¨å¹…: {df['avg_weekly_return'].mean():.2f}%")
    
    # è¡Œä¸šåˆ†å¸ƒ
    if 'industry' in df.columns:
        industry_counts = df['industry'].value_counts()
        logger.info(f"\nğŸ“ˆ è¡Œä¸šåˆ†å¸ƒï¼š")
        for industry, count in industry_counts.items():
            logger.info(f"   {industry}: {count} åª")
    
    # å¸‚å€¼åˆ†å¸ƒ
    mega_cap_count = len(df[df['market_cap'].str.contains('5000\\+|8000\\+|15000\\+|20000\\+', na=False)])
    large_cap_count = len(df) - mega_cap_count
    logger.info(f"\nğŸ’° å¸‚å€¼åˆ†å¸ƒï¼š")
    logger.info(f"   è¶…å¤§å¸‚å€¼(5000äº¿+): {mega_cap_count} åª")
    logger.info(f"   å¤§å¸‚å€¼(1000-5000äº¿): {large_cap_count} åª")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æŸ¥è¯¢å‘¨çº¿ä¸‰è¿é˜³åŠä»¥ä¸Šçš„åƒäº¿å¸‚å€¼ä¸»æ¿è‚¡ç¥¨...")
    logger.info("=" * 60)
    
    start_time = datetime.now()
    
    try:
        analyzer = ConsecutiveYangLinesAnalyzer()
        result_df = analyzer.analyze_mega_cap_yang_lines()
        
        if result_df is not None and not result_df.empty:
            display_yang_lines_results(result_df)
            
            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            output_file = f"consecutive_yang_lines_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")
            
            logger.info("\nğŸ’¡ æŠ•èµ„ç­–ç•¥è§£è¯»ï¼š")
            logger.info("   âœ… è¿ç»­é˜³çº¿è¡¨æ˜è‚¡ä»·å¤„äºä¸Šå‡è¶‹åŠ¿")
            logger.info("   âœ… åƒäº¿å¸‚å€¼ç¡®ä¿äº†è¶³å¤Ÿçš„æµåŠ¨æ€§å’Œç¨³å®šæ€§")
            logger.info("   âœ… ä¸»æ¿è‚¡ç¥¨é€šå¸¸åŸºæœ¬é¢è¾ƒä¸ºæ‰å®")
            logger.info("   âš ï¸  æ³¨æ„è§‚å¯Ÿæ˜¯å¦åˆ°è¾¾é˜»åŠ›ä½")
            logger.info("   âš ï¸  å»ºè®®ç»“åˆæˆäº¤é‡å˜åŒ–è¿›è¡Œåˆ†æ")
            logger.info("   âš ï¸  å…³æ³¨å¸‚åœºæ•´ä½“èµ°åŠ¿å’Œæ¿å—è½®åŠ¨")
            
        else:
            logger.error("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨ï¼Œå¯èƒ½åŸå› ï¼š")
            logger.error("   1. è¿‘æœŸå¸‚åœºæ•´ä½“è°ƒæ•´ï¼Œè¿ç»­é˜³çº¿è‚¡ç¥¨è¾ƒå°‘")
            logger.error("   2. å¤§å¸‚å€¼è‚¡ç¥¨èµ°åŠ¿ç›¸å¯¹ç¨³å¥ï¼Œå¾ˆå°‘å‡ºç°è¿ç»­å¼ºåŠ¿ä¸Šæ¶¨")
            logger.error("   3. å¯ä»¥è€ƒè™‘é™ä½è¿ç»­é˜³çº¿å‘¨æ•°è¦æ±‚ï¼ˆå¦‚2å‘¨ï¼‰")
            
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        return False
        
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° æŸ¥è¯¢æ€»è€—æ—¶: {total_duration}")
    
    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
