#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸ¥è¯¢å‘¨çº¿æ˜æ˜¾æ”¾é‡çš„ETFåˆ—è¡¨

å®šä¹‰ï¼š
1. ä½¿ç”¨ `etf_daily` è¡¨çš„æ—¥çº¿æ•°æ®ï¼ŒæŒ‰å‘¨èšåˆæˆäº¤é‡ï¼ˆè‡ªç„¶å‘¨ï¼ŒYEARWEEK(trade_date, 3)ï¼‰
2. å¯¹æ¯åªETFè®¡ç®—ï¼š
   - æœ€è¿‘ä¸€å‘¨çš„å‘¨æˆäº¤é‡ last_week_vol
   - è¿‡å» N å‘¨ï¼ˆé»˜è®¤3å‘¨ï¼‰ä¸­çš„æœ€å¤§å‘¨æˆäº¤é‡ max_prev_vol
   - æ”¾é‡å€æ•° volume_ratio = last_week_vol / max_prev_vol
3. â€œæ˜æ˜¾æ”¾é‡â€é»˜è®¤å®šä¹‰ä¸ºï¼švolume_ratio >= 1.5

ä½¿ç”¨æ–¹æ³•ï¼š
    python query_etf_weekly_volume_surge.py

ä¾èµ–ï¼š
    - å·²åˆå§‹åŒ– etf_dailyï¼ˆæ—¥çº¿è¡Œæƒ…ï¼‰å’Œ etf_basicï¼ˆETFåŸºç¡€ä¿¡æ¯ï¼‰
"""

import sys
import os
from datetime import datetime, timedelta
from typing import Dict, List

import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from database import StockDatabase
from log_config import get_logger

logger = get_logger(__name__)


class ETFWeeklyVolumeSurgeAnalyzer:
    """ETF å‘¨çº¿æ”¾é‡ç­›é€‰å™¨"""

    def __init__(self):
        self.db = StockDatabase()

    def _get_latest_trade_date(self) -> datetime:
        """è·å– etf_daily ä¸­æœ€è¿‘çš„äº¤æ˜“æ—¥æœŸ"""
        cursor = self.db.connection.cursor()
        cursor.execute("SELECT MAX(trade_date) FROM etf_daily")
        result = cursor.fetchone()
        if not result or not result[0]:
            return None
        return result[0]

    def get_weekly_aggregated_volumes(
        self,
        lookback_days: int = 80,
    ) -> pd.DataFrame:
        """
        ä» etf_daily èšåˆå¾—åˆ°æŒ‰å‘¨ç»Ÿè®¡çš„æˆäº¤é‡

        Args:
            lookback_days: å›æº¯çš„è‡ªç„¶æ—¥èŒƒå›´ï¼Œç”¨äºæˆªå–ä¸€å®šçª—å£å†…çš„å‘¨çº¿æ•°æ®
        """
        logger.info("ğŸ“Š ä» etf_daily èšåˆå‘¨æˆäº¤é‡ ...")

        latest_trade_date = self._get_latest_trade_date()
        if latest_trade_date is None:
            logger.error("âŒ etf_daily è¡¨ä¸­æ²¡æœ‰ä»»ä½•æ•°æ®")
            return pd.DataFrame()

        logger.info(f"   æœ€è¿‘äº¤æ˜“æ—¥: {latest_trade_date}")

        cursor = self.db.connection.cursor()
        query_sql = """
        SELECT
            ts_code,
            YEARWEEK(trade_date, 3) AS year_week,
            MAX(trade_date) AS week_end_date,
            SUM(vol) AS week_vol,
            SUM(amount) AS week_amount
        FROM etf_daily
        WHERE trade_date >= DATE_SUB(%s, INTERVAL %s DAY)
        GROUP BY ts_code, YEARWEEK(trade_date, 3)
        ORDER BY ts_code, week_end_date;
        """

        params = [latest_trade_date, lookback_days]
        df = pd.read_sql(query_sql, self.db.connection, params=params)

        if df.empty:
            logger.warning("âš ï¸ æœªèšåˆå‡ºä»»ä½•å‘¨çº¿ETFæˆäº¤é‡æ•°æ®")
            return pd.DataFrame()

        # ç¡®ä¿æ—¥æœŸåˆ—ä¸º datetime
        df["week_end_date"] = pd.to_datetime(df["week_end_date"])
        logger.info(f"   èšåˆå¾—åˆ° {len(df)} æ¡ ETF å‘¨çº¿æˆäº¤é‡è®°å½•")
        return df

    def get_etf_names(self, ts_codes: List[str]) -> Dict[str, str]:
        """ä» etf_basic è·å– ETF åç§°ï¼ˆextnameï¼‰"""
        names: Dict[str, str] = {}
        if not ts_codes:
            return names

        try:
            with StockDatabase() as db:
                cursor = db.connection.cursor()
                placeholders = ",".join(["%s"] * len(ts_codes))
                sql = f"""
                SELECT ts_code, COALESCE(extname, ts_code) AS name
                FROM etf_basic
                WHERE ts_code IN ({placeholders})
                """
                cursor.execute(sql, ts_codes)
                for ts_code, name in cursor.fetchall():
                    names[ts_code] = name
        except Exception as e:
            logger.error(f"è·å–ETFåç§°å¤±è´¥: {e}")

        return names

    def find_weekly_volume_surge_etfs(
        self,
        min_ratio: float = 1.5,
        lookback_weeks: int = 3,
        min_last_week_amount_yi: float = 1.0,
    ) -> pd.DataFrame:
        """
        æŸ¥æ‰¾æœ€è¿‘ä¸€å‘¨å‘¨çº¿æ˜æ˜¾æ”¾é‡çš„ETF

        Args:
            min_ratio: æœ€å°æ”¾é‡å€æ•°ï¼ˆä¾‹å¦‚ 1.5ï¼‰
            lookback_weeks: å›çœ‹å‘¨æ•°ï¼Œç”¨äºè®¡ç®—å†å²æœ€å¤§å‘¨æˆäº¤é‡
        """
        logger.info(
            f"ğŸ“ˆ ç­›é€‰ETFå‘¨çº¿æ”¾é‡ï¼šæœ€è¿‘1å‘¨å‘¨æˆäº¤é‡ > è¿‡å»{lookback_weeks}å‘¨æœ€å¤§å‘¨æˆäº¤é‡ Ã— {min_ratio} "
            f"ä¸”æœ€è¿‘ä¸€å‘¨æˆäº¤é¢ â‰¥ {min_last_week_amount_yi} äº¿å…ƒ..."
        )

        weekly_df = self.get_weekly_aggregated_volumes(lookback_days=80)
        if weekly_df.empty:
            return pd.DataFrame()

        results = []
        # é‡‘é¢å•ä½æ¢ç®—ï¼šetf_daily.amount ä¸ºâ€œåƒå…ƒâ€ï¼Œ1äº¿å…ƒ = 100000 åƒå…ƒ
        min_last_week_amount_qianyuan = min_last_week_amount_yi * 100000
        for ts_code, g in weekly_df.groupby("ts_code"):
            g = g.sort_values("week_end_date")
            if len(g) < lookback_weeks + 1:
                continue

            last_rows = g.tail(lookback_weeks + 1)
            if len(last_rows) < lookback_weeks + 1:
                continue

            last_week_row = last_rows.iloc[-1]
            prev_weeks = last_rows.iloc[:-1]

            prev_max_vol = prev_weeks["week_vol"].max()
            last_vol = last_week_row["week_vol"]
            last_amount = last_week_row.get("week_amount", 0.0)
            if prev_max_vol is None or prev_max_vol <= 0:
                continue

            ratio = last_vol / prev_max_vol
            if ratio < min_ratio:
                continue

            # æœ€è¿‘ä¸€å‘¨æˆäº¤é¢ä¸è¶³é˜ˆå€¼ï¼ˆé»˜è®¤ < 1 äº¿å…ƒï¼‰çš„è·³è¿‡
            if pd.isna(last_amount) or float(last_amount) < min_last_week_amount_qianyuan:
                continue

            results.append(
                {
                    "ts_code": ts_code,
                    "latest_week_end": last_week_row["week_end_date"],
                    "last_week_vol": float(last_vol),
                    "max_prev_vol": float(prev_max_vol),
                        "last_week_amount": float(last_amount),
                        "volume_ratio": float(ratio),
                }
            )

        surge_df = pd.DataFrame(results)
        logger.info(
            f"   æ»¡è¶³å‘¨çº¿æ”¾é‡>= {min_ratio} å€ä¸”æœ€è¿‘ä¸€å‘¨æˆäº¤é¢â‰¥ {min_last_week_amount_yi} äº¿å…ƒçš„ETFæ•°é‡: {len(surge_df)}"
        )
        return surge_df

    def get_analysis_results(
        self,
        min_ratio: float = 1.5,
        lookback_weeks: int = 3,
        min_last_week_amount_yi: float = 1.0,
    ) -> List[Dict]:
        """
        è·å–åˆ†æç»“æœåˆ—è¡¨ï¼Œä¾› API è°ƒç”¨ã€‚
        """
        try:
            with self.db:
                surge_df = self.find_weekly_volume_surge_etfs(
                    min_ratio=min_ratio,
                    lookback_weeks=lookback_weeks,
                    min_last_week_amount_yi=min_last_week_amount_yi,
                )

            if surge_df.empty:
                return []

            # è¡¥å……ETFåç§°
            etf_names = self.get_etf_names(surge_df["ts_code"].tolist())

            final_rows = []
            for _, row in surge_df.iterrows():
                ts_code = row["ts_code"]
                final_rows.append(
                    {
                        "ts_code": ts_code,
                        "ä»£ç ": ts_code,
                        "åç§°": etf_names.get(ts_code, ts_code),
                        "æœ€è¿‘å‘¨çº¿æˆªæ­¢æ—¥": str(row["latest_week_end"])[:10],
                        "æœ€è¿‘ä¸€å‘¨æˆäº¤é‡(æ‰‹)": float(row["last_week_vol"]),
                        "æœ€è¿‘ä¸€å‘¨æˆäº¤é¢(äº¿å…ƒ)": float(row["last_week_amount"] / 100000.0),
                        "è¿‡å»3å‘¨æœ€å¤§å‘¨æˆäº¤é‡(æ‰‹)": float(row["max_prev_vol"]),
                        "å‘¨æ”¾é‡å€æ•°": float(row["volume_ratio"]),
                    }
                )

            # æ’åº
            final_rows.sort(
                key=lambda x: (x["å‘¨æ”¾é‡å€æ•°"], x["æœ€è¿‘ä¸€å‘¨æˆäº¤é¢(äº¿å…ƒ)"]),
                reverse=True
            )
            
            return final_rows
        except Exception as e:
            logger.error(f"è·å–åˆ†æç»“æœå¤±è´¥: {e}")
            return []

    def run(self):
        """æ‰§è¡ŒETFå‘¨çº¿æ”¾é‡æŸ¥è¯¢å¹¶æ‰“å°ç»“æœ"""
        results = self.get_analysis_results()
        
        if not results:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°å‘¨çº¿æ˜æ˜¾æ”¾é‡çš„ETF")
            return

        logger.info(
            f"\nğŸ‰ å‘¨çº¿æ˜æ˜¾æ”¾é‡çš„ETFåˆ—è¡¨ (æœ€è¿‘1å‘¨ > è¿‡å»3å‘¨æœ€å¤§å‘¨æˆäº¤é‡ Ã— 1.5 ä¸” æœ€è¿‘ä¸€å‘¨æˆäº¤é¢â‰¥1äº¿å…ƒ): å…± {len(results)} åª"
        )
        logger.info("=" * 120)
        logger.info(
            f"{'ä»£ç ':<12} {'åç§°':<20} {'æœ€è¿‘å‘¨çº¿æˆªæ­¢æ—¥':<12} "
            f"{'æœ€è¿‘ä¸€å‘¨æˆäº¤é‡(æ‰‹)':<18} {'æœ€è¿‘ä¸€å‘¨æˆäº¤é¢(äº¿å…ƒ)':<18} "
            f"{'è¿‡å»3å‘¨æœ€å¤§å‘¨æˆäº¤é‡(æ‰‹)':<22} {'å‘¨æ”¾é‡å€æ•°':<10}"
        )
        logger.info("-" * 120)

        for r in results:
            logger.info(
                f"{r['ä»£ç ']:<12} {r['åç§°']:<20} "
                f"{r['æœ€è¿‘å‘¨çº¿æˆªæ­¢æ—¥']:<12} "
                f"{r['æœ€è¿‘ä¸€å‘¨æˆäº¤é‡(æ‰‹)']:<18.0f} "
                f"{r['æœ€è¿‘ä¸€å‘¨æˆäº¤é¢(äº¿å…ƒ)']:<18.2f} "
                f"{r['è¿‡å»3å‘¨æœ€å¤§å‘¨æˆäº¤é‡(æ‰‹)']:<22.0f} "
                f"{r['å‘¨æ”¾é‡å€æ•°']:<10.2f}"
            )

        logger.info("=" * 120)

        


if __name__ == "__main__":
    analyzer = ETFWeeklyVolumeSurgeAnalyzer()
    analyzer.run()


