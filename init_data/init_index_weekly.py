#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. è·å–TushareæŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ•°æ®(index_weeklyæ¥å£)
2. åˆ›å»ºæŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ•°æ®åº“è¡¨ç»“æ„
3. å°†æ•°æ®åˆå§‹åŒ–åˆ°æ•°æ®åº“ä¸­

ä½¿ç”¨æ–¹æ³•ï¼š
    # é»˜è®¤ï¼šæœ€è¿‘1å¹´çš„ä¸»è¦æŒ‡æ•°å‘¨çº¿è¡Œæƒ…
    python init_data/init_index_weekly.py

    # æŒ‡å®šæ—¶é—´èŒƒå›´
    python init_data/init_index_weekly.py --start-date 20220101 --end-date 20251231

å¯¹åº”Tushareæ–‡æ¡£ï¼š
    - æŒ‡æ•°å‘¨çº¿è¡Œæƒ…: https://tushare.pro/document/2?doc_id=171
"""

import sys
import os
from datetime import datetime, timedelta
import argparse

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import StockDatabase
from fetcher import StockDataFetcher
from log_config import get_logger

logger = get_logger(__name__)


def create_database_tables(db: StockDatabase) -> bool:
    """
    åˆ›å»ºå¿…è¦çš„æ•°æ®åº“è¡¨
    """
    logger.info("ğŸ”§ å¼€å§‹åˆ›å»ºæŒ‡æ•°å‘¨çº¿æ•°æ®åº“è¡¨...")

    try:
        if not db.create_database():
            logger.error("âŒ åˆ›å»ºæ•°æ®åº“å¤±è´¥")
            return False

        if not db.connect():
            logger.error("âŒ è¿æ¥æ•°æ®åº“å¤±è´¥")
            return False

        if not db.create_index_weekly_table():
            logger.error("âŒ åˆ›å»ºæŒ‡æ•°å‘¨çº¿è¡Œæƒ…è¡¨å¤±è´¥")
            return False

        logger.info("âœ… æŒ‡æ•°å‘¨çº¿è¡Œæƒ…è¡¨åˆ›å»ºæˆåŠŸ")
        return True

    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæŒ‡æ•°å‘¨çº¿æ•°æ®åº“è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def fetch_and_store_index_weekly_data(
    fetcher: StockDataFetcher,
    db: StockDatabase,
    start_date: str,
    end_date: str,
) -> dict:
    """
    è·å–å¹¶å­˜å‚¨â€œå…¨éƒ¨æŒ‡æ•°â€çš„å‘¨çº¿è¡Œæƒ…æ•°æ®ï¼ˆæŒ‰å‘¨çº¿æ—¥æœŸå…¨å¸‚åœºæŠ“å–ï¼‰
    """
    stats = {
        "total_records": 0,
        "total_indexes": 0,
        "successful_insert": False,
        "date_range": {},
        "start_time": datetime.now(),
        "end_time": None,
        "duration": None,
    }

    logger.info(f"ğŸ“Š å¼€å§‹è·å–ã€å…¨éƒ¨æŒ‡æ•°ã€‘å‘¨çº¿è¡Œæƒ…æ•°æ® ({start_date} åˆ° {end_date})...")

    try:
        week_stats = fetcher.get_all_index_weekly_by_dates_with_batch_insert(
            start_date=start_date,
            end_date=end_date,
            delay=0.5,
            exchange="SSE",
            db_instance=db,
            batch_weeks=10,
        )

        if not week_stats:
            logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•æŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ•°æ®")
            return stats

        stats["total_records"] = week_stats.get("total_records", 0)
        stats["successful_insert"] = stats["total_records"] > 0

    except Exception as e:
        logger.error(f"âŒ è·å–å’Œå­˜å‚¨æŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    finally:
        stats["end_time"] = datetime.now()
        stats["duration"] = stats["end_time"] - stats["start_time"]

    return stats


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="æŒ‡æ•°å‘¨çº¿è¡Œæƒ…åˆå§‹åŒ–è„šæœ¬")
    parser.add_argument("--start-date", type=str, help="å¼€å§‹æ—¥æœŸ (YYYYMMDDæ ¼å¼)")
    parser.add_argument("--end-date", type=str, help="ç»“æŸæ—¥æœŸ (YYYYMMDDæ ¼å¼)")
    parser.add_argument(
        "--years-back",
        type=int,
        default=1,
        help="æœªæŒ‡å®šèµ·æ­¢æ—¥æœŸæ—¶çš„é»˜è®¤å›æº¯å¹´æ•°ï¼Œé»˜è®¤1å¹´",
    )
    return parser.parse_args()


def main() -> bool:
    logger.info("ğŸš€ æŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–å¼€å§‹...")
    logger.info("=" * 60)

    args = parse_arguments()
    start_time = datetime.now()

    if args.start_date and args.end_date:
        start_date = args.start_date
        end_date = args.end_date
    else:
        end_dt = datetime.now()
        start_dt = end_dt - timedelta(days=365 * args.years_back)
        start_date = start_dt.strftime("%Y%m%d")
        end_date = end_dt.strftime("%Y%m%d")

    logger.info(f"ğŸ“Š æŒ‡æ•°å‘¨çº¿åˆå§‹åŒ–åŒºé—´: {start_date} ~ {end_date}")

    try:
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®è·å–å™¨...")
        fetcher = StockDataFetcher()
        logger.info("âœ… æ•°æ®è·å–å™¨åˆå§‹åŒ–æˆåŠŸ")

        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        with StockDatabase() as db:
            if not create_database_tables(db):
                logger.error("âŒ æ•°æ®åº“è¡¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
                return False

            stats = fetch_and_store_index_weekly_data(fetcher, db, start_date, end_date)

            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“Š æŒ‡æ•°å‘¨çº¿åˆå§‹åŒ–ç»Ÿè®¡ï¼š")
            logger.info(f"   ğŸ“ˆ è®°å½•æ€»æ•°: {stats.get('total_records', 0)} æ¡")
            logger.info(f"   ğŸ“Š æ¶‰åŠæŒ‡æ•°: {stats.get('total_indexes', 0)} ä¸ª")
            logger.info(
                f"   ğŸ’¾ æ•°æ®æ’å…¥çŠ¶æ€: {'æˆåŠŸ' if stats.get('successful_insert') else 'å¤±è´¥'}"
            )
            logger.info(f"   â±ï¸  æ€»è€—æ—¶: {stats.get('duration')}")

            if stats.get("successful_insert"):
                logger.info("ğŸ‰ æŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–æˆåŠŸï¼")
                logger.info("\nğŸ’¡ ä½¿ç”¨æç¤ºï¼š")
                logger.info("   - è¡¨å: index_weekly")
                logger.info("   - æŸ¥è¯¢å¯å‚è€ƒ: index_daily çš„æŸ¥è¯¢æ–¹å¼ï¼Œè‡ªè¡Œå†™ SQL æˆ–å°è£…æ¥å£")
                return True
            else:
                logger.error("âŒ æŒ‡æ•°å‘¨çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–å¤±è´¥")
                return False

    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        return False
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}")
        return False
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° ç¨‹åºæ€»æ‰§è¡Œæ—¶é—´: {total_duration}")


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)


