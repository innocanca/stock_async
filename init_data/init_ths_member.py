#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®åˆå§‹åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. è·å–æ‰€æœ‰æ¦‚å¿µæŒ‡æ•°çš„æˆåˆ†è‚¡æ•°æ®
2. åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„
3. å°†æˆåˆ†è‚¡æ•°æ®åˆå§‹åŒ–åˆ°æ•°æ®åº“ä¸­
4. æä¾›æ•°æ®æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
python3 init_ths_member.py [é€‰é¡¹]

é€‰é¡¹ï¼š
--limit N      ä»…å¤„ç†å‰Nä¸ªæ¦‚å¿µæŒ‡æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
--batch-size N æ¯æ‰¹æ’å…¥çš„æŒ‡æ•°æ•°é‡ï¼ˆé»˜è®¤20ï¼‰
--delay N      APIè°ƒç”¨å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤0.3ï¼‰

ç¤ºä¾‹ï¼š
python3 init_ths_member.py --limit 10  # ä»…æµ‹è¯•å‰10ä¸ªæ¦‚å¿µæŒ‡æ•°
python3 init_ths_member.py              # è·å–æ‰€æœ‰æ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡
"""

import argparse
import logging
import sys
import os
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥databaseå’Œfetcheræ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import StockDatabase
from fetcher import StockDataFetcher

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('init_ths_member.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


def create_database_tables(db: StockDatabase) -> bool:
    """
    åˆ›å»ºå¿…è¦çš„æ•°æ®åº“è¡¨
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
        
    Returns:
        bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
    """
    logger.info("ğŸ”§ å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
    
    try:
        # åˆ›å»ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not db.create_database():
            logger.error("âŒ åˆ›å»ºæ•°æ®åº“å¤±è´¥")
            return False
        
        # è¿æ¥æ•°æ®åº“
        if not db.connect():
            logger.error("âŒ è¿æ¥æ•°æ®åº“å¤±è´¥")
            return False
        
        # åˆ›å»ºåŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not db.create_ths_index_table():
            logger.error("âŒ åˆ›å»ºåŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°è¡¨å¤±è´¥")
            return False
            
        # åˆ›å»ºåŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡è¡¨
        if not db.create_ths_member_table():
            logger.error("âŒ åˆ›å»ºåŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡è¡¨å¤±è´¥")
            return False
            
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def fetch_and_store_concept_members(fetcher: StockDataFetcher, db: StockDatabase, 
                                  limit: int = None, batch_size: int = 20,
                                  batch_delay: float = 0.3) -> dict:
    """
    è·å–å¹¶å­˜å‚¨æ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®
    
    Args:
        fetcher: æ•°æ®è·å–å™¨å®ä¾‹
        db: æ•°æ®åº“å®ä¾‹
        limit: é™åˆ¶å¤„ç†çš„æ¦‚å¿µæŒ‡æ•°æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        batch_size: æ¯æ‰¹æ’å…¥çš„æŒ‡æ•°æ•°é‡
        batch_delay: APIè°ƒç”¨å»¶è¿Ÿ
        
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'start_time': datetime.now(),
        'end_time': None,
        'duration': None,
        'total_indexes': 0,
        'processed_indexes': 0,
        'successful_indexes': 0,
        'total_members': 0,
        'successful_insert': False
    }
    
    logger.info("ğŸ“Š å¼€å§‹è·å–æ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®...")
    
    try:
        # è·å–æ¦‚å¿µæŒ‡æ•°åˆ—è¡¨
        concept_df = db.query_ths_index(index_type='N')
        
        if concept_df is None or concept_df.empty:
            logger.error("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ¦‚å¿µæŒ‡æ•°æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ init_ths_index.py")
            return stats
        
        concept_indexes = concept_df['ts_code'].tolist()
        stats['total_indexes'] = len(concept_indexes)
        
        # å¦‚æœè®¾ç½®äº†é™åˆ¶ï¼Œåªå¤„ç†å‰Nä¸ª
        if limit and limit < len(concept_indexes):
            concept_indexes = concept_indexes[:limit]
            stats['processed_indexes'] = limit
            logger.info(f"âš ï¸ æµ‹è¯•æ¨¡å¼ï¼šä»…å¤„ç†å‰ {limit} ä¸ªæ¦‚å¿µæŒ‡æ•°")
        else:
            stats['processed_indexes'] = len(concept_indexes)
        
        logger.info(f"ğŸ“ˆ å‡†å¤‡å¤„ç† {stats['processed_indexes']} ä¸ªæ¦‚å¿µæŒ‡æ•°çš„æˆåˆ†è‚¡")
        
        # ä½¿ç”¨æ‰¹é‡è·å–å’Œæ’å…¥æ–¹æ³•
        batch_stats = fetcher.get_concept_members_batch_with_db_insert(
            db_instance=db,
            concept_indexes=concept_indexes,
            batch_delay=batch_delay,
            batch_size=batch_size
        )
        
        if batch_stats:
            stats['successful_indexes'] = batch_stats.get('successful_indexes', 0)
            stats['total_members'] = batch_stats.get('total_members', 0)
            stats['successful_insert'] = batch_stats.get('successful_batches', 0) > 0
            
            logger.info("âœ… æ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®è·å–å’Œæ’å…¥å®Œæˆï¼")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            logger.info("ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š")
            logger.info(f"   å¤„ç†æ¦‚å¿µæŒ‡æ•°: {stats['processed_indexes']} ä¸ª")
            logger.info(f"   æˆåŠŸè·å–æŒ‡æ•°: {stats['successful_indexes']} ä¸ª")
            logger.info(f"   æ€»æˆåˆ†è‚¡è®°å½•: {stats['total_members']:,} æ¡")
        else:
            logger.error("âŒ æ‰¹é‡è·å–æˆåˆ†è‚¡æ•°æ®å¤±è´¥")
            
    except Exception as e:
        logger.error(f"âŒ è·å–å’Œå­˜å‚¨æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æƒé™é—®é¢˜
        if "æƒé™" in str(e) or "ç§¯åˆ†" in str(e) or "permission" in str(e).lower():
            logger.error("ğŸ’¡ æç¤ºï¼šåŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ¥å£éœ€è¦5000ç§¯åˆ†æƒé™")
            logger.error("   è¯·æ£€æŸ¥æ‚¨çš„Tushareè´¦æˆ·ç§¯åˆ†æˆ–å‡çº§è´¦æˆ·æƒé™")
            logger.error("   è®¿é—® https://tushare.pro/ æŸ¥çœ‹ç§¯åˆ†å’Œæƒé™è¯´æ˜")
    
    finally:
        stats['end_time'] = datetime.now()
        stats['duration'] = stats['end_time'] - stats['start_time']
    
    return stats


def query_and_display_sample_data(db: StockDatabase) -> None:
    """
    æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„æˆåˆ†è‚¡æ•°æ®æ ·ä¾‹
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
    """
    logger.info("ğŸ” æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æˆåˆ†è‚¡æ•°æ®æ ·ä¾‹...")
    
    try:
        # æŸ¥è¯¢æ ·ä¾‹æ•°æ®
        df = db.query_ths_member(limit=20)
        
        if df is None or df.empty:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰æˆåˆ†è‚¡æ•°æ®")
            return
        
        logger.info(f"ğŸ“‹ æ•°æ®åº“ä¸­å…±æœ‰æˆåˆ†è‚¡è®°å½•ï¼ˆæ˜¾ç¤ºå‰20æ¡ï¼‰ï¼š")
        
        for i, (_, row) in enumerate(df.head(20).iterrows(), 1):
            index_name = row.get('index_name', 'N/A')
            con_name = row.get('con_name', 'N/A')
            con_code = row.get('con_code', 'N/A')
            logger.info(f"   {i:2d}. {index_name} - {con_name}({con_code})")
        
        # ç»Ÿè®¡ä¿¡æ¯
        logger.info("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ï¼š")
        
        # æŸ¥è¯¢æ€»è®°å½•æ•°
        all_data = db.query_ths_member()
        if all_data is not None and not all_data.empty:
            total_records = len(all_data)
            unique_indexes = all_data['ts_code'].nunique()
            unique_stocks = all_data['con_code'].nunique()
            
            logger.info(f"   æ€»æˆåˆ†è‚¡è®°å½•: {total_records:,} æ¡")
            logger.info(f"   æ¶‰åŠæŒ‡æ•°æ•°é‡: {unique_indexes} ä¸ª")
            logger.info(f"   ä¸é‡å¤è‚¡ç¥¨æ•°: {unique_stocks} åª")
            
            # æ˜¾ç¤ºæˆåˆ†è‚¡æ•°é‡æœ€å¤šçš„æŒ‡æ•°
            if 'index_name' in all_data.columns:
                top_indexes = all_data.groupby(['ts_code', 'index_name']).size().reset_index(name='member_count')
                top_indexes = top_indexes.sort_values('member_count', ascending=False).head(5)
                
                logger.info("\nğŸ† æˆåˆ†è‚¡æ•°é‡æœ€å¤šçš„æŒ‡æ•°TOP5ï¼š")
                for i, (_, row) in enumerate(top_indexes.iterrows(), 1):
                    logger.info(f"   {i}. {row['index_name']} ({row['ts_code']}): {row['member_count']} åªæˆåˆ†è‚¡")
        
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®åˆå§‹åŒ–')
    parser.add_argument('--limit', type=int, help='ä»…å¤„ç†å‰Nä¸ªæ¦‚å¿µæŒ‡æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--batch-size', type=int, default=20, help='æ¯æ‰¹æ’å…¥çš„æŒ‡æ•°æ•°é‡ï¼ˆé»˜è®¤20ï¼‰')
    parser.add_argument('--delay', type=float, default=0.3, help='APIè°ƒç”¨å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤0.3ï¼‰')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ åŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®åˆå§‹åŒ–å¼€å§‹...")
    logger.info("=" * 70)
    
    if args.limit:
        logger.info(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šä»…å¤„ç†å‰ {args.limit} ä¸ªæ¦‚å¿µæŒ‡æ•°")
    
    logger.info(f"âš™ï¸ é…ç½®å‚æ•°ï¼šæ‰¹æ¬¡å¤§å°={args.batch_size}, APIå»¶è¿Ÿ={args.delay}ç§’")
    
    start_time = datetime.now()
    
    try:
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®è·å–å™¨...")
        fetcher = StockDataFetcher()
        logger.info("âœ… æ•°æ®è·å–å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        with StockDatabase() as db:
            
            # åˆ›å»ºæ•°æ®åº“è¡¨
            if not create_database_tables(db):
                logger.error("âŒ æ•°æ®åº“è¡¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
                return False
            
            # è·å–å¹¶å­˜å‚¨æˆåˆ†è‚¡æ•°æ®
            stats = fetch_and_store_concept_members(
                fetcher, db, 
                limit=args.limit,
                batch_size=args.batch_size,
                batch_delay=args.delay
            )
            
            # æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®ï¼ˆéªŒè¯æ’å…¥ç»“æœï¼‰
            if stats['successful_insert']:
                query_and_display_sample_data(db)
            
            # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
            logger.info("\n" + "=" * 70)
            logger.info("ğŸ“Š åˆå§‹åŒ–å®Œæˆç»Ÿè®¡ï¼š")
            logger.info(f"   ğŸ“ˆ å¤„ç†æ¦‚å¿µæŒ‡æ•°: {stats['processed_indexes']} ä¸ª")
            logger.info(f"   âœ… æˆåŠŸè·å–æŒ‡æ•°: {stats['successful_indexes']} ä¸ª")
            logger.info(f"   ğŸ“Š æ€»æˆåˆ†è‚¡è®°å½•: {stats['total_members']:,} æ¡")
            logger.info(f"   ğŸ’¾ æ•°æ®æ’å…¥çŠ¶æ€: {'æˆåŠŸ' if stats['successful_insert'] else 'å¤±è´¥'}")
            logger.info(f"   â±ï¸  æ€»è€—æ—¶: {stats['duration']}")
            
            if stats['successful_insert']:
                logger.info("ğŸ‰ åŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®åˆå§‹åŒ–æˆåŠŸï¼")
                logger.info("\nğŸ’¡ ä½¿ç”¨æç¤ºï¼š")
                logger.info("   - å¯ä»¥ä½¿ç”¨ database.py ä¸­çš„ query_ths_member() æ–¹æ³•æŸ¥è¯¢æ•°æ®")
                logger.info("   - æ”¯æŒæŒ‰æŒ‡æ•°ä»£ç ã€è‚¡ç¥¨ä»£ç ã€è‚¡ç¥¨åç§°ç­‰æ¡ä»¶ç­›é€‰")
                logger.info("   - æ•°æ®è¡¨å: ths_member")
                logger.info("   - å¯ä½¿ç”¨å¤–é”®å…³è”æŸ¥è¯¢æŒ‡æ•°å’Œæˆåˆ†è‚¡ä¿¡æ¯")
                return True
            else:
                logger.error("âŒ åŒèŠ±é¡ºæ¦‚å¿µæŒ‡æ•°æˆåˆ†è‚¡æ•°æ®åˆå§‹åŒ–å¤±è´¥")
                return False
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        return False
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}")
        return False
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° ç¨‹åºæ€»æ‰§è¡Œæ—¶é—´: {total_duration}")


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
