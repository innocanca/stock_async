#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®åˆå§‹åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. è·å–TushareæŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®(index_basicæ¥å£)
2. åˆ›å»ºæŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®åº“è¡¨ç»“æ„
3. å°†æ•°æ®åˆå§‹åŒ–åˆ°æ•°æ®åº“ä¸­
4. æä¾›æ•°æ®æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
python init_index_basic.py

å¯¹åº”Tushareæ–‡æ¡£ï¼š
https://tushare.pro/document/2?doc_id=94
"""

import logging
import sys
import os
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥databaseå’Œfetcheræ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import StockDatabase
from fetcher import StockDataFetcher

# é…ç½®æ—¥å¿—
from log_config import get_logger
logger = get_logger(__name__)


def create_database_tables(db: StockDatabase) -> bool:
    """
    åˆ›å»ºå¿…è¦çš„æ•°æ®åº“è¡¨
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
        
    Returns:
        bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
    """
    logger.info("ğŸ”§ å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
    
    try:
        # åˆ›å»ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not db.create_database():
            logger.error("âŒ åˆ›å»ºæ•°æ®åº“å¤±è´¥")
            return False
        
        # è¿æ¥æ•°æ®åº“
        if not db.connect():
            logger.error("âŒ è¿æ¥æ•°æ®åº“å¤±è´¥")
            return False
            
        # åˆ›å»ºæŒ‡æ•°åŸºæœ¬ä¿¡æ¯è¡¨
        if not db.create_index_basic_table():
            logger.error("âŒ åˆ›å»ºæŒ‡æ•°åŸºæœ¬ä¿¡æ¯è¡¨å¤±è´¥")
            return False
            
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def fetch_and_store_index_basic_data(fetcher: StockDataFetcher, db: StockDatabase) -> dict:
    """
    è·å–å¹¶å­˜å‚¨æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®
    
    Args:
        fetcher: æ•°æ®è·å–å™¨å®ä¾‹
        db: æ•°æ®åº“å®ä¾‹
        
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_indexes': 0,
        'successful_insert': False,
        'market_distribution': {},
        'start_time': datetime.now(),
        'end_time': None,
        'duration': None
    }
    
    logger.info("ğŸ“Š å¼€å§‹è·å–æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®...")
    
    try:
        # è·å–æ‰€æœ‰æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®
        df = fetcher.get_all_index_basic_data()
        
        if df is None or df.empty:
            logger.error("âŒ æœªè·å–åˆ°ä»»ä½•æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®")
            return stats
        
        stats['total_indexes'] = len(df)
        
        # ç»Ÿè®¡å„å¸‚åœºæ•°é‡
        if 'market' in df.columns:
            stats['market_distribution'] = df['market'].value_counts().to_dict()
        
        logger.info(f"ğŸ“ˆ æˆåŠŸè·å– {len(df)} ä¸ªæŒ‡æ•°çš„åŸºæœ¬ä¿¡æ¯")
        
        # æ’å…¥æ•°æ®åº“
        logger.info("ğŸ’¾ å¼€å§‹æ’å…¥æ•°æ®åˆ°æ•°æ®åº“...")
        
        if db.insert_index_basic(df):
            stats['successful_insert'] = True
            logger.info("âœ… æ•°æ®æ’å…¥æˆåŠŸï¼")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            logger.info("ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š")
            logger.info(f"   æ€»æŒ‡æ•°æ•°é‡: {stats['total_indexes']} ä¸ª")
            
            if stats['market_distribution']:
                logger.info("   å¸‚åœºåˆ†å¸ƒï¼š")
                for market, count in stats['market_distribution'].items():
                    market_name = _get_market_name(market)
                    logger.info(f"     {market_name}({market}): {count} ä¸ª")
        else:
            logger.error("âŒ æ•°æ®æ’å…¥å¤±è´¥")
            
    except Exception as e:
        logger.error(f"âŒ è·å–å’Œå­˜å‚¨æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    finally:
        stats['end_time'] = datetime.now()
        stats['duration'] = stats['end_time'] - stats['start_time']
    
    return stats


def _get_market_name(market: str) -> str:
    """
    è·å–å¸‚åœºä¸­æ–‡åç§°
    
    Args:
        market: å¸‚åœºä»£ç 
        
    Returns:
        str: ä¸­æ–‡åç§°
    """
    market_mapping = {
        'SSE': 'ä¸Šäº¤æ‰€æŒ‡æ•°',
        'SZSE': 'æ·±äº¤æ‰€æŒ‡æ•°',
        'MSCI': 'MSCIæŒ‡æ•°',
        'CSI': 'ä¸­è¯æŒ‡æ•°',
        'CICC': 'ä¸­é‡‘æŒ‡æ•°',
        'SW': 'ç”³ä¸‡æŒ‡æ•°',
        'OTH': 'å…¶ä»–æŒ‡æ•°'
    }
    return market_mapping.get(market, 'æœªçŸ¥å¸‚åœº')


def query_and_display_data(db: StockDatabase) -> None:
    """
    æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
    """
    logger.info("ğŸ” æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®...")
    
    try:
        # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
        df = db.query_index_basic(limit=10)
        
        if df is None or df.empty:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®")
            return
        
        logger.info(f"ğŸ“‹ æ•°æ®åº“ä¸­å…±æœ‰ {len(df)} æ¡æŒ‡æ•°åŸºæœ¬ä¿¡æ¯è®°å½•")
        logger.info("ğŸ“– å‰10æ¡è®°å½•ç¤ºä¾‹ï¼š")
        
        for i, (_, row) in enumerate(df.head(10).iterrows(), 1):
            logger.info(f"   {i:2d}. {row.get('name', 'N/A')} ({row.get('ts_code', 'N/A')}) "
                       f"- å¸‚åœº:{row.get('market', 'N/A')} - å‘å¸ƒæ–¹:{row.get('publisher', 'N/A')}")
        
        # æŒ‰å¸‚åœºç»Ÿè®¡
        logger.info("\nğŸ“ˆ æŒ‰å¸‚åœºç»Ÿè®¡ï¼š")
        market_counts = df['market'].value_counts() if 'market' in df.columns else {}
        for market, count in market_counts.items():
            market_name = _get_market_name(market)
            logger.info(f"   {market_name}({market}): {count} ä¸ª")
        
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®åˆå§‹åŒ–å¼€å§‹...")
    logger.info("=" * 60)
    
    start_time = datetime.now()
    
    try:
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®è·å–å™¨...")
        fetcher = StockDataFetcher()
        logger.info("âœ… æ•°æ®è·å–å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        with StockDatabase() as db:
            
            # åˆ›å»ºæ•°æ®åº“è¡¨
            if not create_database_tables(db):
                logger.error("âŒ æ•°æ®åº“è¡¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
                return False
            
            # è·å–å¹¶å­˜å‚¨æ•°æ®
            stats = fetch_and_store_index_basic_data(fetcher, db)
            
            # æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®ï¼ˆéªŒè¯æ’å…¥ç»“æœï¼‰
            if stats['successful_insert']:
                query_and_display_data(db)
            
            # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“Š åˆå§‹åŒ–å®Œæˆç»Ÿè®¡ï¼š")
            logger.info(f"   ğŸ“ˆ è·å–æŒ‡æ•°æ€»æ•°: {stats['total_indexes']} ä¸ª")
            logger.info(f"   ğŸ’¾ æ•°æ®æ’å…¥çŠ¶æ€: {'æˆåŠŸ' if stats['successful_insert'] else 'å¤±è´¥'}")
            logger.info(f"   â±ï¸  æ€»è€—æ—¶: {stats['duration']}")
            
            if stats['successful_insert']:
                logger.info("ğŸ‰ æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®åˆå§‹åŒ–æˆåŠŸï¼")
                logger.info("\nğŸ’¡ ä½¿ç”¨æç¤ºï¼š")
                logger.info("   - å¯ä»¥ä½¿ç”¨ database.py ä¸­çš„ query_index_basic() æ–¹æ³•æŸ¥è¯¢æ•°æ®")
                logger.info("   - æ”¯æŒæŒ‰å¸‚åœºç±»å‹ã€å‘å¸ƒå•†ç­‰æ¡ä»¶ç­›é€‰")
                logger.info("   - æ•°æ®è¡¨å: index_basic")
                return True
            else:
                logger.error("âŒ æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®åˆå§‹åŒ–å¤±è´¥")
                return False
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        return False
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}")
        return False
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° ç¨‹åºæ€»æ‰§è¡Œæ—¶é—´: {total_duration}")


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
