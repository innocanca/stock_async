#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. è·å–TushareæŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®(index_dailyæ¥å£)
2. åˆ›å»ºæŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®åº“è¡¨ç»“æ„
3. å°†æ•°æ®åˆå§‹åŒ–åˆ°æ•°æ®åº“ä¸­
4. æä¾›æ•°æ®æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
python init_index_daily.py

å¯¹åº”Tushareæ–‡æ¡£ï¼š
https://tushare.pro/document/2?doc_id=96
"""

import logging
import sys
import os
from datetime import datetime, timedelta

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥databaseå’Œfetcheræ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import StockDatabase
from fetcher import StockDataFetcher

# é…ç½®æ—¥å¿—
from log_config import get_logger
logger = get_logger(__name__)


def create_database_tables(db: StockDatabase) -> bool:
    """
    åˆ›å»ºå¿…è¦çš„æ•°æ®åº“è¡¨
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
        
    Returns:
        bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
    """
    logger.info("ğŸ”§ å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
    
    try:
        # åˆ›å»ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not db.create_database():
            logger.error("âŒ åˆ›å»ºæ•°æ®åº“å¤±è´¥")
            return False
        
        # è¿æ¥æ•°æ®åº“
        if not db.connect():
            logger.error("âŒ è¿æ¥æ•°æ®åº“å¤±è´¥")
            return False
            
        # åˆ›å»ºæŒ‡æ•°æ—¥çº¿è¡Œæƒ…è¡¨
        if not db.create_index_daily_table():
            logger.error("âŒ åˆ›å»ºæŒ‡æ•°æ—¥çº¿è¡Œæƒ…è¡¨å¤±è´¥")
            return False
            
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def fetch_and_store_index_daily_data(fetcher: StockDataFetcher, db: StockDatabase, 
                                    start_date: str = None, end_date: str = None) -> dict:
    """
    è·å–å¹¶å­˜å‚¨æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®
    
    Args:
        fetcher: æ•°æ®è·å–å™¨å®ä¾‹
        db: æ•°æ®åº“å®ä¾‹
        start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDDæ ¼å¼)
        end_date: ç»“æŸæ—¥æœŸ (YYYYMMDDæ ¼å¼)
        
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_records': 0,
        'total_indexes': 0,
        'successful_insert': False,
        'date_range': {},
        'start_time': datetime.now(),
        'end_time': None,
        'duration': None
    }
    
    # é»˜è®¤è·å–æœ€è¿‘3ä¸ªæœˆçš„æ•°æ®
    if not start_date or not end_date:
        end_dt = datetime.now()
        start_dt = end_dt - timedelta(days=90)
        start_date = start_dt.strftime('%Y%m%d')
        end_date = end_dt.strftime('%Y%m%d')
    
    logger.info(f"ğŸ“Š å¼€å§‹è·å–æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ® ({start_date} åˆ° {end_date})...")
    
    try:
        # è·å–ä¸»è¦æŒ‡æ•°çš„æ—¥çº¿è¡Œæƒ…æ•°æ®
        df = fetcher.get_major_index_daily_data(start_date, end_date)
        
        if df is None or df.empty:
            logger.error("âŒ æœªè·å–åˆ°ä»»ä½•æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®")
            return stats
        
        stats['total_records'] = len(df)
        stats['total_indexes'] = df['ts_code'].nunique() if 'ts_code' in df.columns else 0
        
        # ç»Ÿè®¡æ—¥æœŸèŒƒå›´
        if 'trade_date' in df.columns:
            stats['date_range'] = {
                'start_date': df['trade_date'].min(),
                'end_date': df['trade_date'].max()
            }
        
        logger.info(f"ğŸ“ˆ æˆåŠŸè·å– {stats['total_records']} æ¡æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®")
        logger.info(f"ğŸ“ˆ æ¶‰åŠæŒ‡æ•°: {stats['total_indexes']} ä¸ª")
        
        # æ’å…¥æ•°æ®åº“
        logger.info("ğŸ’¾ å¼€å§‹æ’å…¥æ•°æ®åˆ°æ•°æ®åº“...")
        
        if db.insert_index_daily(df):
            stats['successful_insert'] = True
            logger.info("âœ… æ•°æ®æ’å…¥æˆåŠŸï¼")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            logger.info("ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š")
            logger.info(f"   æ€»è®°å½•æ•°: {stats['total_records']} æ¡")
            logger.info(f"   æ¶‰åŠæŒ‡æ•°: {stats['total_indexes']} ä¸ª")
            if stats['date_range']:
                logger.info(f"   æ—¥æœŸèŒƒå›´: {stats['date_range']['start_date']} åˆ° {stats['date_range']['end_date']}")
            
            # æ˜¾ç¤ºå„æŒ‡æ•°æ•°æ®é‡ç»Ÿè®¡
            if 'ts_code' in df.columns:
                index_counts = df['ts_code'].value_counts()
                logger.info("   å„æŒ‡æ•°æ•°æ®é‡ï¼š")
                for ts_code, count in index_counts.head(5).items():
                    index_name = _get_index_name(ts_code)
                    logger.info(f"     {index_name}({ts_code}): {count} æ¡")
        else:
            logger.error("âŒ æ•°æ®æ’å…¥å¤±è´¥")
            
    except Exception as e:
        logger.error(f"âŒ è·å–å’Œå­˜å‚¨æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    finally:
        stats['end_time'] = datetime.now()
        stats['duration'] = stats['end_time'] - stats['start_time']
    
    return stats


def _get_index_name(ts_code: str) -> str:
    """
    è·å–æŒ‡æ•°ä¸­æ–‡åç§°
    
    Args:
        ts_code: æŒ‡æ•°ä»£ç 
        
    Returns:
        str: ä¸­æ–‡åç§°
    """
    index_mapping = {
        '000001.SH': 'ä¸Šè¯ç»¼æŒ‡',
        '000300.SH': 'æ²ªæ·±300',
        '000905.SH': 'ä¸­è¯500',
        '000016.SH': 'ä¸Šè¯50',
        '399001.SZ': 'æ·±è¯æˆæŒ‡',
        '399006.SZ': 'åˆ›ä¸šæ¿æŒ‡',
        '399303.SZ': 'å›½è¯2000',
        '000852.SH': 'ä¸­è¯1000',
        '000688.SH': 'ç§‘åˆ›50',
    }
    return index_mapping.get(ts_code, 'æœªçŸ¥æŒ‡æ•°')


def query_and_display_data(db: StockDatabase) -> None:
    """
    æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
    """
    logger.info("ğŸ” æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®...")
    
    try:
        # æŸ¥è¯¢æœ€æ–°10æ¡æ•°æ®
        df = db.query_index_daily(limit=10)
        
        if df is None or df.empty:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®")
            return
        
        logger.info(f"ğŸ“‹ æ•°æ®åº“ä¸­å…±æœ‰ {len(df)} æ¡æŒ‡æ•°æ—¥çº¿è¡Œæƒ…è®°å½•")
        logger.info("ğŸ“– æœ€æ–°10æ¡è®°å½•ç¤ºä¾‹ï¼š")
        
        for i, (_, row) in enumerate(df.head(10).iterrows(), 1):
            index_name = _get_index_name(row.get('ts_code', 'N/A'))
            logger.info(f"   {i:2d}. {index_name}({row.get('ts_code', 'N/A')}) "
                       f"{row.get('trade_date', 'N/A')} - æ”¶ç›˜:{row.get('close', 'N/A')} "
                       f"æ¶¨è·Œ:{row.get('change_pct', 'N/A')}%")
        
        # æŒ‰æŒ‡æ•°ç»Ÿè®¡
        logger.info("\nğŸ“ˆ æŒ‰æŒ‡æ•°ç»Ÿè®¡æœ€æ–°æ•°æ®ï¼š")
        if 'ts_code' in df.columns:
            index_counts = df['ts_code'].value_counts()
            for ts_code, count in index_counts.head(10).items():
                index_name = _get_index_name(ts_code)
                logger.info(f"   {index_name}({ts_code}): {count} æ¡")
        
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–å¼€å§‹...")
    logger.info("=" * 60)
    
    start_time = datetime.now()
    
    try:
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®è·å–å™¨...")
        fetcher = StockDataFetcher()
        logger.info("âœ… æ•°æ®è·å–å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        with StockDatabase() as db:
            
            # åˆ›å»ºæ•°æ®åº“è¡¨
            if not create_database_tables(db):
                logger.error("âŒ æ•°æ®åº“è¡¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
                return False
            
            # è·å–å¹¶å­˜å‚¨æ•°æ®ï¼ˆé»˜è®¤æœ€è¿‘3ä¸ªæœˆï¼‰
            stats = fetch_and_store_index_daily_data(fetcher, db)
            
            # æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®ï¼ˆéªŒè¯æ’å…¥ç»“æœï¼‰
            if stats['successful_insert']:
                query_and_display_data(db)
            
            # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“Š åˆå§‹åŒ–å®Œæˆç»Ÿè®¡ï¼š")
            logger.info(f"   ğŸ“ˆ è·å–è®°å½•æ€»æ•°: {stats['total_records']} æ¡")
            logger.info(f"   ğŸ“Š æ¶‰åŠæŒ‡æ•°: {stats['total_indexes']} ä¸ª")
            logger.info(f"   ğŸ’¾ æ•°æ®æ’å…¥çŠ¶æ€: {'æˆåŠŸ' if stats['successful_insert'] else 'å¤±è´¥'}")
            logger.info(f"   â±ï¸  æ€»è€—æ—¶: {stats['duration']}")
            
            if stats['successful_insert']:
                logger.info("ğŸ‰ æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–æˆåŠŸï¼")
                logger.info("\nğŸ’¡ ä½¿ç”¨æç¤ºï¼š")
                logger.info("   - å¯ä»¥ä½¿ç”¨ database.py ä¸­çš„ query_index_daily() æ–¹æ³•æŸ¥è¯¢æ•°æ®")
                logger.info("   - æ”¯æŒæŒ‰æŒ‡æ•°ä»£ç ã€æ—¥æœŸèŒƒå›´ç­‰æ¡ä»¶ç­›é€‰")
                logger.info("   - æ•°æ®è¡¨å: index_daily")
                logger.info("   - é»˜è®¤è·å–æœ€è¿‘3ä¸ªæœˆçš„ä¸»è¦æŒ‡æ•°æ•°æ®")
                return True
            else:
                logger.error("âŒ æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®åˆå§‹åŒ–å¤±è´¥")
                return False
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        return False
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}")
        return False
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° ç¨‹åºæ€»æ‰§è¡Œæ—¶é—´: {total_duration}")


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
