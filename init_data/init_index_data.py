#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒ‡æ•°æ•°æ®åˆå§‹åŒ–è„šæœ¬ï¼ˆæ•´åˆç‰ˆï¼‰

åŠŸèƒ½ï¼š
1. è·å–TushareæŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®(index_basicæ¥å£ - doc_id=94)
2. è·å–TushareæŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®(index_dailyæ¥å£ - doc_id=96)
3. åˆ›å»ºç›¸å…³æ•°æ®åº“è¡¨ç»“æ„
4. å°†æ•°æ®åˆå§‹åŒ–åˆ°æ•°æ®åº“ä¸­
5. æä¾›æ•°æ®æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
python init_index_data.py

å¯¹åº”Tushareæ–‡æ¡£ï¼š
- æŒ‡æ•°åŸºæœ¬ä¿¡æ¯: https://tushare.pro/document/2?doc_id=94
- æŒ‡æ•°æ—¥çº¿è¡Œæƒ…: https://tushare.pro/document/2?doc_id=96
"""

import logging
import sys
import os
from datetime import datetime, timedelta
import argparse

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥databaseå’Œfetcheræ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import StockDatabase
from fetcher import StockDataFetcher

# é…ç½®æ—¥å¿—
from log_config import get_logger
logger = get_logger(__name__)


def create_database_tables(db: StockDatabase) -> bool:
    """
    åˆ›å»ºå¿…è¦çš„æ•°æ®åº“è¡¨
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
        
    Returns:
        bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
    """
    logger.info("ğŸ”§ å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
    
    try:
        # åˆ›å»ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not db.create_database():
            logger.error("âŒ åˆ›å»ºæ•°æ®åº“å¤±è´¥")
            return False
        
        # è¿æ¥æ•°æ®åº“
        if not db.connect():
            logger.error("âŒ è¿æ¥æ•°æ®åº“å¤±è´¥")
            return False
            
        # åˆ›å»ºæŒ‡æ•°åŸºæœ¬ä¿¡æ¯è¡¨
        if not db.create_index_basic_table():
            logger.error("âŒ åˆ›å»ºæŒ‡æ•°åŸºæœ¬ä¿¡æ¯è¡¨å¤±è´¥")
            return False
            
        # åˆ›å»ºæŒ‡æ•°æ—¥çº¿è¡Œæƒ…è¡¨
        if not db.create_index_daily_table():
            logger.error("âŒ åˆ›å»ºæŒ‡æ•°æ—¥çº¿è¡Œæƒ…è¡¨å¤±è´¥")
            return False
            
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def fetch_and_store_index_basic_data(fetcher: StockDataFetcher, db: StockDatabase) -> dict:
    """
    è·å–å¹¶å­˜å‚¨æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®
    
    Args:
        fetcher: æ•°æ®è·å–å™¨å®ä¾‹
        db: æ•°æ®åº“å®ä¾‹
        
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_indexes': 0,
        'successful_insert': False,
        'market_distribution': {},
        'start_time': datetime.now(),
        'end_time': None,
        'duration': None
    }
    
    logger.info("ğŸ“Š å¼€å§‹è·å–æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®...")
    
    try:
        # è·å–æ‰€æœ‰æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®
        df = fetcher.get_all_index_basic_data()
        
        if df is None or df.empty:
            logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®")
            return stats
        
        stats['total_indexes'] = len(df)
        
        # ç»Ÿè®¡å„å¸‚åœºæ•°é‡
        if 'market' in df.columns:
            stats['market_distribution'] = df['market'].value_counts().to_dict()
        
        logger.info(f"ğŸ“ˆ æˆåŠŸè·å– {len(df)} ä¸ªæŒ‡æ•°çš„åŸºæœ¬ä¿¡æ¯")
        
        # æ’å…¥æ•°æ®åº“
        logger.info("ğŸ’¾ å¼€å§‹æ’å…¥æŒ‡æ•°åŸºæœ¬ä¿¡æ¯åˆ°æ•°æ®åº“...")
        
        if db.insert_index_basic(df):
            stats['successful_insert'] = True
            logger.info("âœ… æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®æ’å…¥æˆåŠŸï¼")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            logger.info("ğŸ“Š æŒ‡æ•°åŸºæœ¬ä¿¡æ¯ç»Ÿè®¡ï¼š")
            logger.info(f"   æ€»æŒ‡æ•°æ•°é‡: {stats['total_indexes']} ä¸ª")
            
            if stats['market_distribution']:
                logger.info("   å¸‚åœºåˆ†å¸ƒï¼š")
                for market, count in stats['market_distribution'].items():
                    market_name = _get_market_name(market)
                    logger.info(f"     {market_name}({market}): {count} ä¸ª")
        else:
            logger.error("âŒ æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®æ’å…¥å¤±è´¥")
            
    except Exception as e:
        logger.error(f"âŒ è·å–å’Œå­˜å‚¨æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    finally:
        stats['end_time'] = datetime.now()
        stats['duration'] = stats['end_time'] - stats['start_time']
    
    return stats


def fetch_and_store_index_daily_data(fetcher: StockDataFetcher, db: StockDatabase, 
                                    start_date: str = None, end_date: str = None) -> dict:
    """
    è·å–å¹¶å­˜å‚¨â€œå…¨éƒ¨æŒ‡æ•°â€çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼ˆæŒ‰äº¤æ˜“æ—¥å…¨å¸‚åœºæŠ“å–ï¼‰
    
    Args:
        fetcher: æ•°æ®è·å–å™¨å®ä¾‹
        db: æ•°æ®åº“å®ä¾‹
        start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDDæ ¼å¼)
        end_date: ç»“æŸæ—¥æœŸ (YYYYMMDDæ ¼å¼)
        
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_records': 0,
        'total_indexes': 0,
        'successful_insert': False,
        'date_range': {},
        'start_time': datetime.now(),
        'end_time': None,
        'duration': None
    }
    
    # é»˜è®¤è·å–æœ€è¿‘3ä¸ªæœˆçš„æ•°æ®
    if not start_date or not end_date:
        end_dt = datetime.now()
        start_dt = end_dt - timedelta(days=90)
        start_date = start_dt.strftime('%Y%m%d')
        end_date = end_dt.strftime('%Y%m%d')
    
    logger.info(f"ğŸ“Š å¼€å§‹è·å–ã€å…¨éƒ¨æŒ‡æ•°ã€‘æ—¥çº¿è¡Œæƒ…æ•°æ® ({start_date} åˆ° {end_date})...")
    
    try:
        # æŒ‰äº¤æ˜“æ—¥å¾ªç¯è·å–æ‰€æœ‰æŒ‡æ•°æ—¥çº¿å¹¶åˆ†æ‰¹æ’åº“
        index_stats = fetcher.get_all_index_daily_by_dates_with_batch_insert(
            start_date=start_date,
            end_date=end_date,
            delay=0.5,
            exchange='SSE',
            db_instance=db,
            batch_days=10,
        )
        
        if not index_stats:
            logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®")
            return stats
        
        stats['total_records'] = index_stats.get('total_records', 0)
        stats['successful_insert'] = stats['total_records'] > 0
        # total_indexes æ— æ³•ç›´æ¥ä»æ‰¹é‡ç»Ÿè®¡æ‹¿åˆ°ï¼Œè¿™é‡Œç•™ç©ºæˆ–åç»­æŒ‰éœ€æŸ¥è¯¢
        
    except Exception as e:
        logger.error(f"âŒ è·å–å’Œå­˜å‚¨æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    finally:
        stats['end_time'] = datetime.now()
        stats['duration'] = stats['end_time'] - stats['start_time']
    
    return stats


def _get_market_name(market: str) -> str:
    """
    è·å–å¸‚åœºä¸­æ–‡åç§°
    
    Args:
        market: å¸‚åœºä»£ç 
        
    Returns:
        str: ä¸­æ–‡åç§°
    """
    market_mapping = {
        'SSE': 'ä¸Šäº¤æ‰€æŒ‡æ•°',
        'SZSE': 'æ·±äº¤æ‰€æŒ‡æ•°',
        'MSCI': 'MSCIæŒ‡æ•°',
        'CSI': 'ä¸­è¯æŒ‡æ•°',
        'CICC': 'ä¸­é‡‘æŒ‡æ•°',
        'SW': 'ç”³ä¸‡æŒ‡æ•°',
        'OTH': 'å…¶ä»–æŒ‡æ•°'
    }
    return market_mapping.get(market, 'æœªçŸ¥å¸‚åœº')


def _get_index_name(ts_code: str) -> str:
    """
    è·å–æŒ‡æ•°ä¸­æ–‡åç§°
    
    Args:
        ts_code: æŒ‡æ•°ä»£ç 
        
    Returns:
        str: ä¸­æ–‡åç§°
    """
    index_mapping = {
        '000001.SH': 'ä¸Šè¯ç»¼æŒ‡',
        '000300.SH': 'æ²ªæ·±300',
        '000905.SH': 'ä¸­è¯500',
        '000016.SH': 'ä¸Šè¯50',
        '399001.SZ': 'æ·±è¯æˆæŒ‡',
        '399006.SZ': 'åˆ›ä¸šæ¿æŒ‡',
        '399303.SZ': 'å›½è¯2000',
        '000852.SH': 'ä¸­è¯1000',
        '000688.SH': 'ç§‘åˆ›50',
    }
    return index_mapping.get(ts_code, 'æœªçŸ¥æŒ‡æ•°')


def query_and_display_data(db: StockDatabase) -> None:
    """
    æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„æŒ‡æ•°æ•°æ®
    
    Args:
        db: æ•°æ®åº“å®ä¾‹
    """
    logger.info("ğŸ” æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æŒ‡æ•°æ•°æ®...")
    
    try:
        # æŸ¥è¯¢æŒ‡æ•°åŸºæœ¬ä¿¡æ¯
        basic_df = db.query_index_basic(limit=5)
        if basic_df is not None and not basic_df.empty:
            logger.info(f"ğŸ“‹ æŒ‡æ•°åŸºæœ¬ä¿¡æ¯: å…± {len(basic_df)} æ¡è®°å½•")
            logger.info("ğŸ“– å‰5æ¡æŒ‡æ•°åŸºæœ¬ä¿¡æ¯ç¤ºä¾‹ï¼š")
            for i, (_, row) in enumerate(basic_df.head(5).iterrows(), 1):
                logger.info(f"   {i}. {row.get('name', 'N/A')} ({row.get('ts_code', 'N/A')}) "
                           f"- å¸‚åœº:{row.get('market', 'N/A')}")
        
        # æŸ¥è¯¢æŒ‡æ•°æ—¥çº¿è¡Œæƒ…
        daily_df = db.query_index_daily(limit=5)
        if daily_df is not None and not daily_df.empty:
            logger.info(f"\nğŸ“‹ æŒ‡æ•°æ—¥çº¿è¡Œæƒ…: å…± {len(daily_df)} æ¡è®°å½•")
            logger.info("ğŸ“– æœ€æ–°5æ¡æ—¥çº¿è¡Œæƒ…ç¤ºä¾‹ï¼š")
            for i, (_, row) in enumerate(daily_df.head(5).iterrows(), 1):
                index_name = _get_index_name(row.get('ts_code', 'N/A'))
                logger.info(f"   {i}. {index_name}({row.get('ts_code', 'N/A')}) "
                           f"{row.get('trade_date', 'N/A')} - æ”¶ç›˜:{row.get('close', 'N/A')}")
        
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='æŒ‡æ•°æ•°æ®åˆå§‹åŒ–è„šæœ¬')
    parser.add_argument('--basic-only', action='store_true', help='åªåˆå§‹åŒ–æŒ‡æ•°åŸºæœ¬ä¿¡æ¯')
    parser.add_argument('--daily-only', action='store_true', help='åªåˆå§‹åŒ–æŒ‡æ•°æ—¥çº¿è¡Œæƒ…')
    parser.add_argument('--start-date', type=str, help='å¼€å§‹æ—¥æœŸ (YYYYMMDDæ ¼å¼)')
    parser.add_argument('--end-date', type=str, help='ç»“æŸæ—¥æœŸ (YYYYMMDDæ ¼å¼)')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ æŒ‡æ•°æ•°æ®åˆå§‹åŒ–å¼€å§‹...")
    logger.info("=" * 60)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    start_time = datetime.now()
    
    try:
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®è·å–å™¨...")
        fetcher = StockDataFetcher()
        logger.info("âœ… æ•°æ®è·å–å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        with StockDatabase() as db:
            
            # åˆ›å»ºæ•°æ®åº“è¡¨
            if not create_database_tables(db):
                logger.error("âŒ æ•°æ®åº“è¡¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
                return False
            
            # ç»Ÿè®¡ä¿¡æ¯
            overall_stats = {
                'basic_success': False,
                'daily_success': False,
                'basic_stats': None,
                'daily_stats': None
            }
            
            # è·å–å¹¶å­˜å‚¨æŒ‡æ•°åŸºæœ¬ä¿¡æ¯æ•°æ®
            if not args.daily_only:
                basic_stats = fetch_and_store_index_basic_data(fetcher, db)
                overall_stats['basic_stats'] = basic_stats
                overall_stats['basic_success'] = basic_stats['successful_insert']
            
            # è·å–å¹¶å­˜å‚¨æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®
            if not args.basic_only:
                daily_stats = fetch_and_store_index_daily_data(
                    fetcher, db, args.start_date, args.end_date
                )
                overall_stats['daily_stats'] = daily_stats
                overall_stats['daily_success'] = daily_stats['successful_insert']
            
            # æŸ¥è¯¢å¹¶æ˜¾ç¤ºæ•°æ®ï¼ˆéªŒè¯æ’å…¥ç»“æœï¼‰
            if overall_stats['basic_success'] or overall_stats['daily_success']:
                query_and_display_data(db)
            
            # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“Š åˆå§‹åŒ–å®Œæˆæ€»ä½“ç»Ÿè®¡ï¼š")
            
            if overall_stats['basic_stats']:
                logger.info(f"   ğŸ“ˆ æŒ‡æ•°åŸºæœ¬ä¿¡æ¯: {overall_stats['basic_stats']['total_indexes']} ä¸ªæŒ‡æ•°")
                logger.info(f"   ğŸ’¾ åŸºæœ¬ä¿¡æ¯æ’å…¥: {'æˆåŠŸ' if overall_stats['basic_success'] else 'å¤±è´¥'}")
            
            if overall_stats['daily_stats']:
                logger.info(f"   ğŸ“Š æŒ‡æ•°æ—¥çº¿è¡Œæƒ…: {overall_stats['daily_stats']['total_records']} æ¡è®°å½•")
                logger.info(f"   ğŸ’¾ è¡Œæƒ…æ•°æ®æ’å…¥: {'æˆåŠŸ' if overall_stats['daily_success'] else 'å¤±è´¥'}")
            
            success = overall_stats['basic_success'] or overall_stats['daily_success']
            
            if success:
                logger.info("ğŸ‰ æŒ‡æ•°æ•°æ®åˆå§‹åŒ–æˆåŠŸï¼")
                logger.info("\nğŸ’¡ ä½¿ç”¨æç¤ºï¼š")
                logger.info("   - å¯ä»¥ä½¿ç”¨ database.py ä¸­çš„ query_index_basic() æŸ¥è¯¢æŒ‡æ•°åŸºæœ¬ä¿¡æ¯")
                logger.info("   - å¯ä»¥ä½¿ç”¨ database.py ä¸­çš„ query_index_daily() æŸ¥è¯¢æŒ‡æ•°æ—¥çº¿è¡Œæƒ…")
                logger.info("   - æ•°æ®è¡¨å: index_basic, index_daily")
                logger.info("   - æ”¯æŒå¤šç§ç­›é€‰æ¡ä»¶å’Œç»Ÿè®¡åˆ†æ")
                return True
            else:
                logger.error("âŒ æŒ‡æ•°æ•°æ®åˆå§‹åŒ–å¤±è´¥")
                return False
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        return False
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}")
        return False
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° ç¨‹åºæ€»æ‰§è¡Œæ—¶é—´: {total_duration}")


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
