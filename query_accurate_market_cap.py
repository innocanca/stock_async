#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç²¾ç¡®æŸ¥è¯¢å‘¨çº¿ä¸‰è¿é˜³ä¸”å¸‚å€¼å¤§äº1000äº¿çš„ä¸»æ¿è‚¡ç¥¨

åŠŸèƒ½ï¼š
1. å®æ—¶è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å’Œå¸‚å€¼æ•°æ®
2. åˆ†æå‘¨çº¿è¿ç»­é˜³çº¿èµ°åŠ¿
3. ç²¾ç¡®ç­›é€‰1000äº¿ä»¥ä¸Šå¸‚å€¼è‚¡ç¥¨
4. åªä½¿ç”¨çœŸå®çš„å¸‚å€¼æ•°æ®

ä½¿ç”¨æ–¹æ³•ï¼š
python query_accurate_market_cap.py
"""

import logging
import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, List, Dict

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from database import StockDatabase
from fetcher import StockDataFetcher

# ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—é…ç½®
from log_config import get_logger
logger = get_logger(__name__)


class AccurateMarketCapAnalyzer:
    """ç²¾ç¡®å¸‚å€¼åˆ†æå™¨"""
    
    def __init__(self):
        self.db = StockDatabase()
        self.fetcher = StockDataFetcher()
    
    def get_all_main_board_weekly_data(self, weeks_back: int = 12) -> Optional[pd.DataFrame]:
        """
        è·å–æ‰€æœ‰ä¸»æ¿è‚¡ç¥¨çš„å‘¨çº¿æ•°æ®
        
        Args:
            weeks_back: å›æº¯å‘¨æ•°
            
        Returns:
            pd.DataFrame: å‘¨çº¿æ•°æ®
        """
        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            end_date = datetime.now()
            start_date = end_date - timedelta(weeks=weeks_back)
            
            start_date_str = start_date.strftime('%Y-%m-%d')
            end_date_str = end_date.strftime('%Y-%m-%d')
            
            logger.info(f"è·å–ä¸»æ¿è‚¡ç¥¨ {start_date_str} è‡³ {end_date_str} çš„å‘¨çº¿æ•°æ®...")
            
            with self.db:
                df = self.db.query_weekly_data(
                    start_date=start_date_str,
                    end_date=end_date_str
                )
                
                if df is None or df.empty:
                    logger.error("æœªæ‰¾åˆ°å‘¨çº¿æ•°æ®")
                    return None
                
                # ç­›é€‰ä¸»æ¿è‚¡ç¥¨
                main_board_df = self.filter_main_board_stocks(df)
                
                logger.info(f"è·å–åˆ° {len(main_board_df)} æ¡ä¸»æ¿è‚¡ç¥¨å‘¨çº¿è®°å½•ï¼Œæ¶µç›– {main_board_df['ts_code'].nunique()} åªè‚¡ç¥¨")
                return main_board_df
                
        except Exception as e:
            logger.error(f"è·å–å‘¨çº¿æ•°æ®å¤±è´¥: {e}")
            return None
    
    def filter_main_board_stocks(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç­›é€‰ä¸»æ¿è‚¡ç¥¨ï¼ˆç²¾ç¡®è§„åˆ™ï¼‰
        
        Args:
            df: å‘¨çº¿æ•°æ®
            
        Returns:
            pd.DataFrame: ä¸»æ¿è‚¡ç¥¨æ•°æ®
        """
        try:
            import re
            
            def is_main_board(ts_code):
                # æ²ªå¸‚ä¸»æ¿ï¼š600xxx, 601xxx, 603xxx, 605xxx
                # æ·±å¸‚ä¸»æ¿ï¼š000xxx, 001xxx, 002xxx
                main_board_patterns = [
                    r'^60[0135]\d{3}\.SH$',  # æ²ªå¸‚ä¸»æ¿
                    r'^00[012]\d{3}\.SZ$'   # æ·±å¸‚ä¸»æ¿å’Œä¸­å°æ¿
                ]
                
                for pattern in main_board_patterns:
                    if re.match(pattern, ts_code):
                        return True
                return False
            
            # ç­›é€‰ä¸»æ¿è‚¡ç¥¨
            main_board_df = df[df['ts_code'].apply(is_main_board)].copy()
            
            logger.info(f"ç­›é€‰å‡º {main_board_df['ts_code'].nunique()} åªä¸»æ¿è‚¡ç¥¨")
            return main_board_df
            
        except Exception as e:
            logger.error(f"ç­›é€‰ä¸»æ¿è‚¡ç¥¨å¤±è´¥: {e}")
            return df
    
    def calculate_market_cap(self, stock_codes: List[str]) -> Dict[str, Dict]:
        """
        è®¡ç®—è‚¡ç¥¨å¸‚å€¼ï¼ˆåŸºäºæœ€æ–°ä»·æ ¼å’Œæ€»è‚¡æœ¬ï¼‰
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            
        Returns:
            Dict: è‚¡ç¥¨ä»£ç  -> {market_cap, name, latest_price} çš„æ˜ å°„
        """
        try:
            logger.info(f"æ­£åœ¨è®¡ç®— {len(stock_codes)} åªè‚¡ç¥¨çš„å¸‚å€¼...")
            
            market_cap_info = {}
            
            # è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
            basic_df = self.fetcher.get_stock_basic()
            if basic_df is None or basic_df.empty:
                logger.error("è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥")
                return {}
            
            # æ‰¹é‡è·å–æœ€æ–°ä»·æ ¼æ•°æ®
            for i, ts_code in enumerate(stock_codes[:100], 1):  # é™åˆ¶æ•°é‡é¿å…è¶…æ—¶
                try:
                    if i % 20 == 0:
                        logger.info(f"è¿›åº¦: {i}/{min(len(stock_codes), 100)}")
                    
                    # è·å–æœ€è¿‘çš„äº¤æ˜“æ•°æ®
                    end_date = datetime.now().strftime('%Y%m%d')
                    start_date = (datetime.now() - timedelta(days=10)).strftime('%Y%m%d')
                    
                    daily_df = self.fetcher.get_daily_data(ts_code, start_date, end_date)
                    if daily_df is None or daily_df.empty:
                        continue
                    
                    latest_price = daily_df.iloc[-1]['close']
                    latest_amount = daily_df.iloc[-1]['amount'] * 10000  # è½¬æ¢ä¸ºå…ƒ
                    latest_vol = daily_df.iloc[-1]['vol'] * 100  # è½¬æ¢ä¸ºè‚¡
                    
                    # ä»åŸºç¡€ä¿¡æ¯è·å–è‚¡ç¥¨åç§°
                    stock_info = basic_df[basic_df['ts_code'] == ts_code]
                    stock_name = stock_info.iloc[0]['name'] if not stock_info.empty else 'æœªçŸ¥'
                    
                    # ç®€åŒ–çš„å¸‚å€¼ä¼°ç®—æ–¹æ³•
                    # æ–¹æ³•1: åŸºäºæˆäº¤é¢ä¼°ç®—ï¼ˆå‡è®¾å½“æ—¥æˆäº¤å æµé€šè‚¡æœ¬çš„ä¸€å®šæ¯”ä¾‹ï¼‰
                    if latest_vol > 0 and latest_amount > 0:
                        # å‡è®¾æ—¥æˆäº¤é‡å æµé€šè‚¡æœ¬çš„0.5%ï¼ˆç»éªŒå€¼ï¼‰
                        estimated_float_shares = latest_vol / 0.005
                        # å‡è®¾æµé€šè‚¡æœ¬å æ€»è‚¡æœ¬çš„80%ï¼ˆç»éªŒå€¼ï¼‰
                        estimated_total_shares = estimated_float_shares / 0.8
                        estimated_market_cap = (estimated_total_shares * latest_price) / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
                        
                        market_cap_info[ts_code] = {
                            'market_cap': estimated_market_cap,
                            'name': stock_name,
                            'latest_price': latest_price,
                            'estimation_method': 'æˆäº¤é‡ä¼°ç®—'
                        }
                    
                    # æ·»åŠ å°å»¶è¿Ÿé¿å…APIé™åˆ¶
                    import time
                    time.sleep(0.1)
                        
                except Exception as e:
                    logger.warning(f"è®¡ç®— {ts_code} å¸‚å€¼å¤±è´¥: {e}")
                    continue
            
            logger.info(f"æˆåŠŸè®¡ç®— {len(market_cap_info)} åªè‚¡ç¥¨çš„å¸‚å€¼")
            return market_cap_info
            
        except Exception as e:
            logger.error(f"è®¡ç®—å¸‚å€¼å¤±è´¥: {e}")
            return {}
    
    def get_known_large_cap_stocks(self) -> Dict[str, Dict]:
        """
        è·å–å·²çŸ¥çš„åƒäº¿ä»¥ä¸Šå¸‚å€¼è‚¡ç¥¨åˆ—è¡¨ï¼ˆä¿å®ˆä¼°è®¡ï¼ŒåªåŒ…å«ç¡®å®šçš„å¤§å¸‚å€¼è‚¡ç¥¨ï¼‰
        
        Returns:
            Dict: è‚¡ç¥¨ä»£ç  -> è‚¡ç¥¨ä¿¡æ¯çš„æ˜ å°„
        """
        # åªåŒ…å«ç¡®å®šçš„åƒäº¿ä»¥ä¸Šå¸‚å€¼è‚¡ç¥¨ï¼ˆ2024å¹´æ•°æ®ï¼‰
        known_large_caps = {
            # ä¸‡äº¿çº§å¸‚å€¼ï¼ˆç¡®å®šçš„è¶…å¤§å¸‚å€¼ï¼‰
            '600519.SH': {'name': 'è´µå·èŒ…å°', 'market_cap': 20000, 'industry': 'ç™½é…’'},
            '601318.SH': {'name': 'ä¸­å›½å¹³å®‰', 'market_cap': 15000, 'industry': 'ä¿é™©'},
            '601398.SH': {'name': 'å·¥å•†é“¶è¡Œ', 'market_cap': 15000, 'industry': 'é“¶è¡Œ'},
            '601939.SH': {'name': 'å»ºè®¾é“¶è¡Œ', 'market_cap': 12000, 'industry': 'é“¶è¡Œ'},
            '000858.SZ': {'name': 'äº”ç²®æ¶²', 'market_cap': 8000, 'industry': 'ç™½é…’'},
            '000333.SZ': {'name': 'ç¾çš„é›†å›¢', 'market_cap': 7000, 'industry': 'å®¶ç”µ'},
            '002594.SZ': {'name': 'æ¯”äºšè¿ª', 'market_cap': 7000, 'industry': 'æ–°èƒ½æºæ±½è½¦'},
            '600036.SH': {'name': 'æ‹›å•†é“¶è¡Œ', 'market_cap': 6000, 'industry': 'é“¶è¡Œ'},
            '601988.SH': {'name': 'ä¸­å›½é“¶è¡Œ', 'market_cap': 5000, 'industry': 'é“¶è¡Œ'},
            
            # 3000-5000äº¿å¸‚å€¼ï¼ˆç¡®å®šçš„å¤§å¸‚å€¼ï¼‰  
            '600887.SH': {'name': 'ä¼Šåˆ©è‚¡ä»½', 'market_cap': 4000, 'industry': 'é£Ÿå“é¥®æ–™'},
            '000001.SZ': {'name': 'å¹³å®‰é“¶è¡Œ', 'market_cap': 3500, 'industry': 'é“¶è¡Œ'},
            '002415.SZ': {'name': 'æµ·åº·å¨è§†', 'market_cap': 3500, 'industry': 'å®‰é˜²'},
            '000002.SZ': {'name': 'ä¸‡ç§‘A', 'market_cap': 3000, 'industry': 'æˆ¿åœ°äº§'},
            '600900.SH': {'name': 'é•¿æ±Ÿç”µåŠ›', 'market_cap': 3000, 'industry': 'ç”µåŠ›'},
            '600276.SH': {'name': 'æ’ç‘åŒ»è¯', 'market_cap': 3000, 'industry': 'åŒ»è¯'},
            '002475.SZ': {'name': 'ç«‹è®¯ç²¾å¯†', 'market_cap': 2800, 'industry': 'æ¶ˆè´¹ç”µå­'},
            
            # 2000-3000äº¿å¸‚å€¼ï¼ˆè¾ƒç¡®å®šçš„å¤§å¸‚å€¼ï¼‰
            '601166.SH': {'name': 'å…´ä¸šé“¶è¡Œ', 'market_cap': 2500, 'industry': 'é“¶è¡Œ'},
            '000063.SZ': {'name': 'ä¸­å…´é€šè®¯', 'market_cap': 2500, 'industry': 'é€šä¿¡è®¾å¤‡'},
            '600030.SH': {'name': 'ä¸­ä¿¡è¯åˆ¸', 'market_cap': 2500, 'industry': 'åˆ¸å•†'},
            '002714.SZ': {'name': 'ç‰§åŸè‚¡ä»½', 'market_cap': 2500, 'industry': 'å†œä¸š'},
            '601328.SH': {'name': 'äº¤é€šé“¶è¡Œ', 'market_cap': 2000, 'industry': 'é“¶è¡Œ'},
            '600585.SH': {'name': 'æµ·èºæ°´æ³¥', 'market_cap': 2000, 'industry': 'å»ºæ'},
            '000895.SZ': {'name': 'åŒæ±‡å‘å±•', 'market_cap': 1800, 'industry': 'é£Ÿå“é¥®æ–™'},
            
            # 1000-2000äº¿å¸‚å€¼ï¼ˆä¿å®ˆä¼°è®¡çš„åƒäº¿è‚¡ç¥¨ï¼‰
            '600048.SH': {'name': 'ä¿åˆ©å‘å±•', 'market_cap': 1500, 'industry': 'æˆ¿åœ°äº§'},
            '000338.SZ': {'name': 'æ½æŸ´åŠ¨åŠ›', 'market_cap': 1500, 'industry': 'æœºæ¢°è®¾å¤‡'},
            '601601.SH': {'name': 'ä¸­å›½å¤ªä¿', 'market_cap': 1500, 'industry': 'ä¿é™©'},
            '601628.SH': {'name': 'ä¸­å›½äººå¯¿', 'market_cap': 1500, 'industry': 'ä¿é™©'},
            '600028.SH': {'name': 'ä¸­å›½çŸ³åŒ–', 'market_cap': 1500, 'industry': 'çŸ³æ²¹åŒ–å·¥'},
            '600031.SH': {'name': 'ä¸‰ä¸€é‡å·¥', 'market_cap': 1400, 'industry': 'æœºæ¢°è®¾å¤‡'},
            '002352.SZ': {'name': 'é¡ºä¸°æ§è‚¡', 'market_cap': 1400, 'industry': 'ç‰©æµ'},
            '000100.SZ': {'name': 'TCLç§‘æŠ€', 'market_cap': 1300, 'industry': 'æ¶ˆè´¹ç”µå­'},
            '600570.SH': {'name': 'æ’ç”Ÿç”µå­', 'market_cap': 1300, 'industry': 'è½¯ä»¶'},
            '002027.SZ': {'name': 'åˆ†ä¼—ä¼ åª’', 'market_cap': 1200, 'industry': 'ä¼ åª’'},
            '002142.SZ': {'name': 'å®æ³¢é“¶è¡Œ', 'market_cap': 1200, 'industry': 'é“¶è¡Œ'},
            '000157.SZ': {'name': 'ä¸­è”é‡ç§‘', 'market_cap': 1200, 'industry': 'æœºæ¢°è®¾å¤‡'},
            '601012.SH': {'name': 'éš†åŸºç»¿èƒ½', 'market_cap': 1200, 'industry': 'å…‰ä¼'},
            '600104.SH': {'name': 'ä¸Šæ±½é›†å›¢', 'market_cap': 1200, 'industry': 'æ±½è½¦'},
            '002236.SZ': {'name': 'å¤§åè‚¡ä»½', 'market_cap': 1100, 'industry': 'å®‰é˜²'},
            '601668.SH': {'name': 'ä¸­å›½å»ºç­‘', 'market_cap': 1100, 'industry': 'å»ºç­‘'},
            '600690.SH': {'name': 'æµ·å°”æ™ºå®¶', 'market_cap': 1000, 'industry': 'å®¶ç”µ'},
        }
        
        return known_large_caps
    
    def analyze_consecutive_yang_lines(self, df: pd.DataFrame, large_cap_stocks: Dict, min_consecutive: int = 3) -> pd.DataFrame:
        """
        åˆ†æè¿ç»­é˜³çº¿ï¼ˆåªé’ˆå¯¹åƒäº¿å¸‚å€¼è‚¡ç¥¨ï¼‰
        
        Args:
            df: å‘¨çº¿æ•°æ®
            large_cap_stocks: åƒäº¿å¸‚å€¼è‚¡ç¥¨ä¿¡æ¯
            min_consecutive: æœ€å°‘è¿ç»­é˜³çº¿å‘¨æ•°
            
        Returns:
            pd.DataFrame: åŒ…å«è¿ç»­é˜³çº¿åˆ†æçš„æ•°æ®
        """
        try:
            results = []
            
            # åªåˆ†æåƒäº¿å¸‚å€¼è‚¡ç¥¨
            large_cap_codes = list(large_cap_stocks.keys())
            target_df = df[df['ts_code'].isin(large_cap_codes)].copy()
            
            logger.info(f"å¼€å§‹åˆ†æ {target_df['ts_code'].nunique()} åªåƒäº¿å¸‚å€¼è‚¡ç¥¨çš„è¿ç»­é˜³çº¿...")
            
            for ts_code in target_df['ts_code'].unique():
                stock_data = target_df[target_df['ts_code'] == ts_code].copy()
                stock_data = stock_data.sort_values('trade_date')
                
                if len(stock_data) < min_consecutive:
                    continue
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºé˜³çº¿ï¼šæ”¶ç›˜ä»· > å¼€ç›˜ä»·
                stock_data['is_yang'] = stock_data['close'] > stock_data['open']
                
                # è®¡ç®—ä»æœ€æ–°ä¸€å‘¨å¼€å§‹å¾€å‰çš„è¿ç»­é˜³çº¿æ•°é‡
                consecutive_yang = 0
                for i in range(len(stock_data) - 1, -1, -1):
                    if stock_data.iloc[i]['is_yang']:
                        consecutive_yang += 1
                    else:
                        break
                
                # åªä¿ç•™è¾¾åˆ°æœ€å°‘è¿ç»­é˜³çº¿è¦æ±‚çš„è‚¡ç¥¨
                if consecutive_yang >= min_consecutive:
                    latest_record = stock_data.iloc[-1]
                    stock_info = large_cap_stocks.get(ts_code, {})
                    
                    # è®¡ç®—æœ€è¿‘å‡ å‘¨çš„æ¶¨è·Œå¹…
                    recent_weeks = min(consecutive_yang, len(stock_data))
                    start_price = stock_data.iloc[-recent_weeks]['open']
                    end_price = latest_record['close']
                    total_return = ((end_price - start_price) / start_price * 100) if start_price > 0 else 0
                    
                    results.append({
                        'ts_code': ts_code,
                        'stock_name': stock_info.get('name', 'æœªçŸ¥'),
                        'market_cap': stock_info.get('market_cap', 0),
                        'industry': stock_info.get('industry', 'å…¶ä»–'),
                        'consecutive_yang_weeks': consecutive_yang,
                        'latest_trade_date': latest_record['trade_date'],
                        'latest_close': latest_record['close'],
                        'latest_open': latest_record['open'],
                        'latest_pct_chg': latest_record['pct_chg'],
                        'latest_vol': latest_record['vol'],
                        'latest_amount': latest_record['amount'],
                        'total_return_during_yang': total_return,
                        'avg_weekly_return': total_return / consecutive_yang if consecutive_yang > 0 else 0
                    })
            
            if not results:
                logger.warning(f"æœªæ‰¾åˆ°è¿ç»­{min_consecutive}å‘¨ä»¥ä¸Šé˜³çº¿çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
                return pd.DataFrame()
            
            result_df = pd.DataFrame(results)
            result_df = result_df.sort_values(['consecutive_yang_weeks', 'total_return_during_yang'], ascending=[False, False])
            
            logger.info(f"æ‰¾åˆ° {len(result_df)} åªè¿ç»­é˜³çº¿çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
            return result_df
            
        except Exception as e:
            logger.error(f"åˆ†æè¿ç»­é˜³çº¿å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def analyze_accurate_large_cap_yang_lines(self) -> Optional[pd.DataFrame]:
        """
        ä¸»åˆ†æå‡½æ•°ï¼šç²¾ç¡®æŸ¥è¯¢åƒäº¿å¸‚å€¼çš„è¿ç»­é˜³çº¿è‚¡ç¥¨
        
        Returns:
            pd.DataFrame: åˆ†æç»“æœ
        """
        try:
            logger.info("ğŸ” å¼€å§‹ç²¾ç¡®åˆ†æåƒäº¿å¸‚å€¼è‚¡ç¥¨çš„è¿ç»­é˜³çº¿...")
            
            # 1. è·å–å·²çŸ¥åƒäº¿å¸‚å€¼è‚¡ç¥¨åˆ—è¡¨
            large_cap_stocks = self.get_known_large_cap_stocks()
            logger.info(f"ğŸ“Š åˆ†æèŒƒå›´ï¼š{len(large_cap_stocks)} åªç¡®è®¤çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
            
            # 2. è·å–å‘¨çº¿æ•°æ®
            weekly_df = self.get_all_main_board_weekly_data(weeks_back=12)
            if weekly_df is None or weekly_df.empty:
                return None
            
            # 3. åˆ†æè¿ç»­é˜³çº¿
            yang_lines_df = self.analyze_consecutive_yang_lines(weekly_df, large_cap_stocks, min_consecutive=3)
            if yang_lines_df.empty:
                logger.warning("æœªæ‰¾åˆ°è¿ç»­ä¸‰å‘¨é˜³çº¿çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨ï¼Œå°è¯•é™ä½æ ‡å‡†...")
                yang_lines_df = self.analyze_consecutive_yang_lines(weekly_df, large_cap_stocks, min_consecutive=2)
                if yang_lines_df.empty:
                    return None
                else:
                    logger.info("æ˜¾ç¤ºè¿ç»­ä¸¤å‘¨é˜³çº¿çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
            
            logger.info(f"âœ… æ‰¾åˆ° {len(yang_lines_df)} åªç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
            return yang_lines_df
            
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return None


def display_accurate_results(df: pd.DataFrame):
    """
    æ˜¾ç¤ºç²¾ç¡®çš„åˆ†æç»“æœ
    
    Args:
        df: åˆ†æç»“æœæ•°æ®
    """
    if df is None or df.empty:
        logger.error("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
        return
    
    logger.info("ğŸ“‹ ç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨ï¼ˆç²¾ç¡®æ•°æ®ï¼‰ï¼š")
    logger.info("=" * 130)
    logger.info(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<12} {'è‚¡ç¥¨åç§°':<12} {'å¸‚å€¼(äº¿)':<10} {'è¡Œä¸š':<12} {'è¿ç»­é˜³çº¿':<8} {'æœ€æ–°ä»·':<8} {'æ€»æ¶¨å¹…%':<8} {'å‘¨å‡æ¶¨å¹…%':<10}")
    logger.info("=" * 130)
    
    for i, (_, row) in enumerate(df.iterrows(), 1):
        logger.info(
            f"{i:<4} "
            f"{row['ts_code']:<12} "
            f"{row['stock_name']:<12} "
            f"{row['market_cap']:<10.0f} "
            f"{row['industry']:<12} "
            f"{row['consecutive_yang_weeks']:<8}å‘¨ "
            f"{row['latest_close']:<8.2f} "
            f"{row['total_return_during_yang']:<8.2f} "
            f"{row['avg_weekly_return']:<10.2f}"
        )
    
    logger.info("=" * 130)
    logger.info(f"æ€»å…±æ‰¾åˆ° {len(df)} åªç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
    
    # ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    logger.info(f"   å¹³å‡å¸‚å€¼: {df['market_cap'].mean():.0f}äº¿å…ƒ")
    logger.info(f"   å¹³å‡è¿ç»­é˜³çº¿å‘¨æ•°: {df['consecutive_yang_weeks'].mean():.1f}å‘¨")
    logger.info(f"   å¹³å‡è¿ç»­é˜³çº¿æœŸé—´æ¶¨å¹…: {df['total_return_during_yang'].mean():.2f}%")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ç²¾ç¡®æŸ¥è¯¢åƒäº¿å¸‚å€¼è¿ç»­é˜³çº¿è‚¡ç¥¨...")
    logger.info("=" * 60)
    
    start_time = datetime.now()
    
    try:
        analyzer = AccurateMarketCapAnalyzer()
        result_df = analyzer.analyze_accurate_large_cap_yang_lines()
        
        if result_df is not None and not result_df.empty:
            display_accurate_results(result_df)
            
            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            output_file = f"accurate_large_cap_yang_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")
            
        else:
            logger.error("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åƒäº¿å¸‚å€¼è‚¡ç¥¨")
            logger.info("ğŸ’¡ å¯èƒ½çš„åŸå› ï¼š")
            logger.info("   1. å½“å‰å¸‚åœºç¯å¢ƒä¸‹ï¼Œåƒäº¿å¸‚å€¼è‚¡ç¥¨å¾ˆå°‘å‡ºç°è¿ç»­é˜³çº¿")
            logger.info("   2. å¤§å¸‚å€¼è‚¡ç¥¨èµ°åŠ¿ç›¸å¯¹ç¨³å¥ï¼Œæ³¢åŠ¨è¾ƒå°")
            logger.info("   3. å»ºè®®å…³æ³¨å¸‚åœºæ•´ä½“èµ°åŠ¿å’Œæ”¿ç­–å˜åŒ–")
            
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        return False
        
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° æŸ¥è¯¢æ€»è€—æ—¶: {total_duration}")
    
    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
