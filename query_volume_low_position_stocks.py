#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸ¥è¯¢å‘¨çº¿æ”¾é‡ä¸”å¤„äºç›¸å¯¹ä½ä½çš„600äº¿+å¸‚å€¼ä¸»æ¿è‚¡ç¥¨

åŠŸèƒ½ï¼š
1. åˆ†æå‘¨çº¿æˆäº¤é‡æ”¾å¤§æƒ…å†µ
2. è¯†åˆ«å¤„äºç›¸å¯¹ä½ä½çš„è‚¡ç¥¨
3. ç­›é€‰600äº¿ä»¥ä¸Šå¸‚å€¼è‚¡ç¥¨
4. åªåŒ…å«ä¸»æ¿è‚¡ç¥¨

ä½¿ç”¨æ–¹æ³•ï¼š
python query_volume_low_position_stocks.py
"""

import logging
import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, List, Dict

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from database import StockDatabase
from fetcher import StockDataFetcher
from log_config import get_logger

logger = get_logger(__name__)


class VolumeLowPositionAnalyzer:
    """å‘¨çº¿æ”¾é‡ä½ä½è‚¡ç¥¨åˆ†æå™¨"""
    
    def __init__(self):
        self.db = StockDatabase()
        self.fetcher = StockDataFetcher()
        
        # 600äº¿ä»¥ä¸Šå¸‚å€¼çš„ä¸»æ¿è‚¡ç¥¨åˆ—è¡¨ï¼ˆ2024å¹´æ•°æ®ï¼‰
        self.large_cap_stocks = {
            # ä¸‡äº¿çº§å¸‚å€¼ï¼ˆ5000äº¿+ï¼‰
            '600519.SH': {'name': 'è´µå·èŒ…å°', 'market_cap': 20000, 'industry': 'ç™½é…’'},
            '601318.SH': {'name': 'ä¸­å›½å¹³å®‰', 'market_cap': 15000, 'industry': 'ä¿é™©'},
            '601398.SH': {'name': 'å·¥å•†é“¶è¡Œ', 'market_cap': 15000, 'industry': 'é“¶è¡Œ'},
            '601939.SH': {'name': 'å»ºè®¾é“¶è¡Œ', 'market_cap': 12000, 'industry': 'é“¶è¡Œ'},
            '000858.SZ': {'name': 'äº”ç²®æ¶²', 'market_cap': 8000, 'industry': 'ç™½é…’'},
            '000333.SZ': {'name': 'ç¾çš„é›†å›¢', 'market_cap': 7000, 'industry': 'å®¶ç”µ'},
            '002594.SZ': {'name': 'æ¯”äºšè¿ª', 'market_cap': 7000, 'industry': 'æ–°èƒ½æºæ±½è½¦'},
            '600036.SH': {'name': 'æ‹›å•†é“¶è¡Œ', 'market_cap': 6000, 'industry': 'é“¶è¡Œ'},
            '601988.SH': {'name': 'ä¸­å›½é“¶è¡Œ', 'market_cap': 5000, 'industry': 'é“¶è¡Œ'},
            
            # 3000-5000äº¿å¸‚å€¼
            '600887.SH': {'name': 'ä¼Šåˆ©è‚¡ä»½', 'market_cap': 4000, 'industry': 'é£Ÿå“é¥®æ–™'},
            '000001.SZ': {'name': 'å¹³å®‰é“¶è¡Œ', 'market_cap': 3500, 'industry': 'é“¶è¡Œ'},
            '002415.SZ': {'name': 'æµ·åº·å¨è§†', 'market_cap': 3500, 'industry': 'å®‰é˜²'},
            '000002.SZ': {'name': 'ä¸‡ç§‘A', 'market_cap': 3000, 'industry': 'æˆ¿åœ°äº§'},
            '600900.SH': {'name': 'é•¿æ±Ÿç”µåŠ›', 'market_cap': 3000, 'industry': 'ç”µåŠ›'},
            '600276.SH': {'name': 'æ’ç‘åŒ»è¯', 'market_cap': 3000, 'industry': 'åŒ»è¯'},
            '002475.SZ': {'name': 'ç«‹è®¯ç²¾å¯†', 'market_cap': 2800, 'industry': 'æ¶ˆè´¹ç”µå­'},
            
            # 2000-3000äº¿å¸‚å€¼
            '601166.SH': {'name': 'å…´ä¸šé“¶è¡Œ', 'market_cap': 2500, 'industry': 'é“¶è¡Œ'},
            '000063.SZ': {'name': 'ä¸­å…´é€šè®¯', 'market_cap': 2500, 'industry': 'é€šä¿¡è®¾å¤‡'},
            '600030.SH': {'name': 'ä¸­ä¿¡è¯åˆ¸', 'market_cap': 2500, 'industry': 'åˆ¸å•†'},
            '002714.SZ': {'name': 'ç‰§åŸè‚¡ä»½', 'market_cap': 2500, 'industry': 'å†œä¸š'},
            '601328.SH': {'name': 'äº¤é€šé“¶è¡Œ', 'market_cap': 2000, 'industry': 'é“¶è¡Œ'},
            '600585.SH': {'name': 'æµ·èºæ°´æ³¥', 'market_cap': 2000, 'industry': 'å»ºæ'},
            '000895.SZ': {'name': 'åŒæ±‡å‘å±•', 'market_cap': 1800, 'industry': 'é£Ÿå“é¥®æ–™'},
            '600809.SH': {'name': 'å±±è¥¿æ±¾é…’', 'market_cap': 1800, 'industry': 'ç™½é…’'},
            '002304.SZ': {'name': 'æ´‹æ²³è‚¡ä»½', 'market_cap': 2000, 'industry': 'ç™½é…’'},
            
            # 1000-2000äº¿å¸‚å€¼
            '600048.SH': {'name': 'ä¿åˆ©å‘å±•', 'market_cap': 1500, 'industry': 'æˆ¿åœ°äº§'},
            '000338.SZ': {'name': 'æ½æŸ´åŠ¨åŠ›', 'market_cap': 1500, 'industry': 'æœºæ¢°è®¾å¤‡'},
            '601601.SH': {'name': 'ä¸­å›½å¤ªä¿', 'market_cap': 1500, 'industry': 'ä¿é™©'},
            '601628.SH': {'name': 'ä¸­å›½äººå¯¿', 'market_cap': 1500, 'industry': 'ä¿é™©'},
            '600028.SH': {'name': 'ä¸­å›½çŸ³åŒ–', 'market_cap': 1500, 'industry': 'çŸ³æ²¹åŒ–å·¥'},
            '601857.SH': {'name': 'ä¸­å›½çŸ³æ²¹', 'market_cap': 1500, 'industry': 'çŸ³æ²¹åŒ–å·¥'},
            '600031.SH': {'name': 'ä¸‰ä¸€é‡å·¥', 'market_cap': 1400, 'industry': 'æœºæ¢°è®¾å¤‡'},
            '002352.SZ': {'name': 'é¡ºä¸°æ§è‚¡', 'market_cap': 1400, 'industry': 'ç‰©æµ'},
            '000100.SZ': {'name': 'TCLç§‘æŠ€', 'market_cap': 1300, 'industry': 'æ¶ˆè´¹ç”µå­'},
            '600570.SH': {'name': 'æ’ç”Ÿç”µå­', 'market_cap': 1300, 'industry': 'è½¯ä»¶'},
            '002027.SZ': {'name': 'åˆ†ä¼—ä¼ åª’', 'market_cap': 1200, 'industry': 'ä¼ åª’'},
            '002142.SZ': {'name': 'å®æ³¢é“¶è¡Œ', 'market_cap': 1200, 'industry': 'é“¶è¡Œ'},
            '000157.SZ': {'name': 'ä¸­è”é‡ç§‘', 'market_cap': 1200, 'industry': 'æœºæ¢°è®¾å¤‡'},
            '002202.SZ': {'name': 'é‡‘é£ç§‘æŠ€', 'market_cap': 1200, 'industry': 'é£ç”µ'},
            '601012.SH': {'name': 'éš†åŸºç»¿èƒ½', 'market_cap': 1200, 'industry': 'å…‰ä¼'},
            '600104.SH': {'name': 'ä¸Šæ±½é›†å›¢', 'market_cap': 1200, 'industry': 'æ±½è½¦'},
            '000166.SZ': {'name': 'ç”³ä¸‡å®æº', 'market_cap': 1100, 'industry': 'åˆ¸å•†'},
            '002236.SZ': {'name': 'å¤§åè‚¡ä»½', 'market_cap': 1100, 'industry': 'å®‰é˜²'},
            '601668.SH': {'name': 'ä¸­å›½å»ºç­‘', 'market_cap': 1100, 'industry': 'å»ºç­‘'},
            '600690.SH': {'name': 'æµ·å°”æ™ºå®¶', 'market_cap': 1000, 'industry': 'å®¶ç”µ'},
            
            # 600-1000äº¿å¸‚å€¼
            '000876.SZ': {'name': 'æ–°å¸Œæœ›', 'market_cap': 800, 'industry': 'å†œä¸š'},
            '000858.SZ': {'name': 'äº”ç²®æ¶²', 'market_cap': 8000, 'industry': 'ç™½é…’'},  # é‡å¤äº†ï¼Œä¿®æ­£
            '600132.SH': {'name': 'é‡åº†å•¤é…’', 'market_cap': 900, 'industry': 'é£Ÿå“é¥®æ–™'},
            '000596.SZ': {'name': 'å¤äº•è´¡é…’', 'market_cap': 800, 'industry': 'ç™½é…’'},
            '600600.SH': {'name': 'é’å²›å•¤é…’', 'market_cap': 900, 'industry': 'é£Ÿå“é¥®æ–™'},
            '000568.SZ': {'name': 'æ³¸å·è€çª–', 'market_cap': 900, 'industry': 'ç™½é…’'},
            '600519.SH': {'name': 'è´µå·èŒ…å°', 'market_cap': 20000, 'industry': 'ç™½é…’'},  # é‡å¤äº†
            '000999.SZ': {'name': 'åæ¶¦ä¸‰ä¹', 'market_cap': 700, 'industry': 'åŒ»è¯'},
            '000661.SZ': {'name': 'é•¿æ˜¥é«˜æ–°', 'market_cap': 800, 'industry': 'åŒ»è¯'},
            '600660.SH': {'name': 'ç¦è€€ç»ç’ƒ', 'market_cap': 700, 'industry': 'æ±½è½¦é›¶éƒ¨ä»¶'},
            '002008.SZ': {'name': 'å¤§æ—æ¿€å…‰', 'market_cap': 600, 'industry': 'æœºæ¢°è®¾å¤‡'},
            '002129.SZ': {'name': 'ä¸­ç¯è‚¡ä»½', 'market_cap': 600, 'industry': 'åŠå¯¼ä½“'},
        }
        
        # å»é™¤é‡å¤ï¼Œåªä¿ç•™600äº¿ä»¥ä¸Šçš„
        self.filtered_stocks = {k: v for k, v in self.large_cap_stocks.items() 
                               if v['market_cap'] >= 600}
    
    def get_weekly_data(self, weeks_back: int = 20) -> Optional[pd.DataFrame]:
        """
        è·å–å¤§å¸‚å€¼è‚¡ç¥¨çš„å‘¨çº¿æ•°æ®
        
        Args:
            weeks_back: å›æº¯å‘¨æ•°
            
        Returns:
            pd.DataFrame: å‘¨çº¿æ•°æ®
        """
        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            end_date = datetime.now()
            start_date = end_date - timedelta(weeks=weeks_back)
            
            start_date_str = start_date.strftime('%Y-%m-%d')
            end_date_str = end_date.strftime('%Y-%m-%d')
            
            logger.info(f"è·å–600äº¿+å¸‚å€¼è‚¡ç¥¨ {start_date_str} è‡³ {end_date_str} çš„å‘¨çº¿æ•°æ®...")
            
            with self.db:
                df = self.db.query_weekly_data(
                    start_date=start_date_str,
                    end_date=end_date_str
                )
                
                if df is None or df.empty:
                    logger.error("æœªæ‰¾åˆ°å‘¨çº¿æ•°æ®")
                    return None
                
                # ç­›é€‰ä¸»æ¿è‚¡ç¥¨
                main_board_df = self.filter_main_board_stocks(df)
                
                # åªä¿ç•™600äº¿ä»¥ä¸Šå¸‚å€¼è‚¡ç¥¨
                large_cap_df = main_board_df[main_board_df['ts_code'].isin(self.filtered_stocks.keys())].copy()
                
                if large_cap_df.empty:
                    logger.error("æœªæ‰¾åˆ°600äº¿+å¸‚å€¼è‚¡ç¥¨çš„å‘¨çº¿æ•°æ®")
                    return None
                
                logger.info(f"è·å–åˆ° {len(large_cap_df)} æ¡600äº¿+å¸‚å€¼è‚¡ç¥¨å‘¨çº¿è®°å½•ï¼Œæ¶µç›– {large_cap_df['ts_code'].nunique()} åªè‚¡ç¥¨")
                return large_cap_df
                
        except Exception as e:
            logger.error(f"è·å–å‘¨çº¿æ•°æ®å¤±è´¥: {e}")
            return None
    
    def filter_main_board_stocks(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç­›é€‰ä¸»æ¿è‚¡ç¥¨
        
        Args:
            df: å‘¨çº¿æ•°æ®
            
        Returns:
            pd.DataFrame: ä¸»æ¿è‚¡ç¥¨æ•°æ®
        """
        try:
            import re
            
            def is_main_board(ts_code):
                # æ²ªå¸‚ä¸»æ¿ï¼š600xxx, 601xxx, 603xxx, 605xxx
                # æ·±å¸‚ä¸»æ¿ï¼š000xxx, 001xxx, 002xxx
                main_board_patterns = [
                    r'^60[0135]\d{3}\.SH$',  # æ²ªå¸‚ä¸»æ¿
                    r'^00[012]\d{3}\.SZ$'   # æ·±å¸‚ä¸»æ¿å’Œä¸­å°æ¿
                ]
                
                for pattern in main_board_patterns:
                    if re.match(pattern, ts_code):
                        return True
                return False
            
            # ç­›é€‰ä¸»æ¿è‚¡ç¥¨
            main_board_df = df[df['ts_code'].apply(is_main_board)].copy()
            
            logger.info(f"ç­›é€‰å‡º {main_board_df['ts_code'].nunique()} åªä¸»æ¿è‚¡ç¥¨")
            return main_board_df
            
        except Exception as e:
            logger.error(f"ç­›é€‰ä¸»æ¿è‚¡ç¥¨å¤±è´¥: {e}")
            return df
    
    def analyze_volume_surge(self, df: pd.DataFrame, min_volume_ratio: float = 1.5) -> pd.DataFrame:
        """
        åˆ†ææˆäº¤é‡æ”¾å¤§æƒ…å†µ
        
        Args:
            df: å‘¨çº¿æ•°æ®
            min_volume_ratio: æœ€å°æˆäº¤é‡æ”¾å¤§å€æ•°
            
        Returns:
            pd.DataFrame: åŒ…å«æˆäº¤é‡åˆ†æçš„æ•°æ®
        """
        try:
            results = []
            
            for ts_code in df['ts_code'].unique():
                stock_data = df[df['ts_code'] == ts_code].copy()
                stock_data = stock_data.sort_values('trade_date')
                
                if len(stock_data) < 8:  # è‡³å°‘éœ€è¦8å‘¨æ•°æ®
                    continue
                
                # æœ€è¿‘2å‘¨çš„å¹³å‡æˆäº¤é‡
                recent_2weeks = stock_data.tail(2)['vol'].mean()
                
                # ä¹‹å‰10å‘¨çš„å¹³å‡æˆäº¤é‡ï¼ˆä½œä¸ºåŸºå‡†ï¼‰
                if len(stock_data) >= 12:
                    baseline_weeks = stock_data.iloc[-12:-2]['vol'].mean()
                else:
                    baseline_weeks = stock_data.iloc[:-2]['vol'].mean()
                
                if baseline_weeks > 0:
                    volume_ratio = recent_2weeks / baseline_weeks
                    
                    # åªä¿ç•™æˆäº¤é‡æ”¾å¤§çš„è‚¡ç¥¨
                    if volume_ratio >= min_volume_ratio:
                        latest_record = stock_data.iloc[-1]
                        stock_info = self.filtered_stocks.get(ts_code, {})
                        
                        results.append({
                            'ts_code': ts_code,
                            'stock_name': stock_info.get('name', 'æœªçŸ¥'),
                            'market_cap': stock_info.get('market_cap', 0),
                            'industry': stock_info.get('industry', 'å…¶ä»–'),
                            'latest_trade_date': latest_record['trade_date'],
                            'latest_close': latest_record['close'],
                            'latest_vol': latest_record['vol'],
                            'recent_2weeks_avg_vol': recent_2weeks,
                            'baseline_avg_vol': baseline_weeks,
                            'volume_surge_ratio': volume_ratio,
                            'latest_pct_chg': latest_record['pct_chg'],
                            'latest_amount': latest_record['amount'],
                            'stock_data': stock_data  # ä¿ç•™å®Œæ•´æ•°æ®ç”¨äºåç»­åˆ†æ
                        })
            
            if not results:
                logger.warning(f"æœªæ‰¾åˆ°æˆäº¤é‡æ”¾å¤§{min_volume_ratio}å€ä»¥ä¸Šçš„è‚¡ç¥¨")
                return pd.DataFrame()
            
            result_df = pd.DataFrame(results)
            result_df = result_df.sort_values('volume_surge_ratio', ascending=False)
            
            logger.info(f"æ‰¾åˆ° {len(result_df)} åªæˆäº¤é‡æ”¾å¤§çš„600äº¿+å¸‚å€¼è‚¡ç¥¨")
            return result_df
            
        except Exception as e:
            logger.error(f"åˆ†ææˆäº¤é‡æ”¾å¤§å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def analyze_low_position(self, df: pd.DataFrame, lookback_weeks: int = 16) -> pd.DataFrame:
        """
        åˆ†ææ˜¯å¦å¤„äºç›¸å¯¹ä½ä½
        
        Args:
            df: åŒ…å«æˆäº¤é‡åˆ†æçš„æ•°æ®
            lookback_weeks: å›æœ›å‘¨æ•°æ¥åˆ¤æ–­ç›¸å¯¹ä½ä½
            
        Returns:
            pd.DataFrame: åŒ…å«ä½ä½åˆ†æçš„æ•°æ®
        """
        try:
            low_position_results = []
            
            for _, row in df.iterrows():
                stock_data = row['stock_data']
                
                if len(stock_data) < lookback_weeks:
                    continue
                
                # åˆ†ææœ€è¿‘16å‘¨çš„ä»·æ ¼åˆ†å¸ƒ
                recent_data = stock_data.tail(lookback_weeks)
                
                highest_price = recent_data['high'].max()
                lowest_price = recent_data['low'].min()
                current_price = row['latest_close']
                
                # è®¡ç®—å½“å‰ä»·æ ¼åœ¨åŒºé—´ä¸­çš„ä½ç½®ï¼ˆ0è¡¨ç¤ºæœ€ä½ç‚¹ï¼Œ1è¡¨ç¤ºæœ€é«˜ç‚¹ï¼‰
                if highest_price > lowest_price:
                    price_position = (current_price - lowest_price) / (highest_price - lowest_price)
                else:
                    price_position = 0.5  # å¦‚æœæ²¡æœ‰æ³¢åŠ¨ï¼Œè®¾ä¸ºä¸­ä½
                
                # è®¡ç®—è·ç¦»æœ€é«˜ç‚¹çš„è·Œå¹…
                decline_from_high = (highest_price - current_price) / highest_price * 100
                
                # åˆ¤æ–­æ˜¯å¦å¤„äºç›¸å¯¹ä½ä½ï¼ˆä»·æ ¼ä½ç½®åœ¨30%ä»¥ä¸‹ï¼Œæˆ–è€…ä»é«˜ç‚¹ä¸‹è·Œè¶…è¿‡20%ï¼‰
                is_low_position = price_position <= 0.3 or decline_from_high >= 20
                
                if is_low_position:
                    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    ma_short = recent_data.tail(4)['close'].mean()  # 4å‘¨å‡çº¿
                    ma_long = recent_data.tail(8)['close'].mean()   # 8å‘¨å‡çº¿
                    
                    low_position_results.append({
                        'ts_code': row['ts_code'],
                        'stock_name': row['stock_name'],
                        'market_cap': row['market_cap'],
                        'industry': row['industry'],
                        'latest_close': row['latest_close'],
                        'volume_surge_ratio': row['volume_surge_ratio'],
                        'latest_pct_chg': row['latest_pct_chg'],
                        'latest_amount': row['latest_amount'],
                        'price_position': price_position,
                        'decline_from_high': decline_from_high,
                        'highest_price_16w': highest_price,
                        'lowest_price_16w': lowest_price,
                        'ma_4w': ma_short,
                        'ma_8w': ma_long,
                        'relative_to_ma4w': (current_price - ma_short) / ma_short * 100,
                        'relative_to_ma8w': (current_price - ma_long) / ma_long * 100
                    })
            
            if not low_position_results:
                logger.warning("æœªæ‰¾åˆ°å¤„äºç›¸å¯¹ä½ä½çš„è‚¡ç¥¨")
                return pd.DataFrame()
            
            result_df = pd.DataFrame(low_position_results)
            # æŒ‰ä»·æ ¼ä½ç½®æ’åºï¼ˆè¶Šä½è¶Šæ’å‰é¢ï¼‰
            result_df = result_df.sort_values(['price_position', 'volume_surge_ratio'], ascending=[True, False])
            
            logger.info(f"æ‰¾åˆ° {len(result_df)} åªå¤„äºç›¸å¯¹ä½ä½çš„è‚¡ç¥¨")
            return result_df
            
        except Exception as e:
            logger.error(f"åˆ†æç›¸å¯¹ä½ä½å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def analyze_volume_low_position(self) -> Optional[pd.DataFrame]:
        """
        ä¸»åˆ†æå‡½æ•°ï¼šæ‰¾åˆ°å‘¨çº¿æ”¾é‡ä¸”å¤„äºç›¸å¯¹ä½ä½çš„600äº¿+å¸‚å€¼è‚¡ç¥¨
        
        Returns:
            pd.DataFrame: åˆ†æç»“æœ
        """
        try:
            logger.info("ğŸ” å¼€å§‹åˆ†æå‘¨çº¿æ”¾é‡ä¸”å¤„äºç›¸å¯¹ä½ä½çš„600äº¿+å¸‚å€¼è‚¡ç¥¨...")
            logger.info(f"ğŸ“Š åˆ†æèŒƒå›´ï¼š{len(self.filtered_stocks)} åª600äº¿+å¸‚å€¼è‚¡ç¥¨")
            
            # 1. è·å–å‘¨çº¿æ•°æ®
            weekly_df = self.get_weekly_data(weeks_back=20)
            if weekly_df is None or weekly_df.empty:
                return None
            
            # 2. åˆ†ææˆäº¤é‡æ”¾å¤§
            volume_surge_df = self.analyze_volume_surge(weekly_df, min_volume_ratio=1.5)
            if volume_surge_df.empty:
                logger.error("æœªæ‰¾åˆ°æˆäº¤é‡æ”¾å¤§çš„è‚¡ç¥¨")
                return None
            
            # 3. åˆ†æç›¸å¯¹ä½ä½
            low_position_df = self.analyze_low_position(volume_surge_df, lookback_weeks=16)
            if low_position_df.empty:
                logger.error("æœªæ‰¾åˆ°å¤„äºç›¸å¯¹ä½ä½çš„è‚¡ç¥¨")
                return None
            
            logger.info(f"âœ… æ‰¾åˆ° {len(low_position_df)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return low_position_df
            
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return None


def display_results(df: pd.DataFrame):
    """
    æ˜¾ç¤ºåˆ†æç»“æœ
    
    Args:
        df: åˆ†æç»“æœæ•°æ®
    """
    if df is None or df.empty:
        logger.error("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        return
    
    logger.info("ğŸ“‹ ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆå‘¨çº¿æ”¾é‡+ç›¸å¯¹ä½ä½+600äº¿+å¸‚å€¼ï¼‰ï¼š")
    logger.info("=" * 140)
    logger.info(f"{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<12} {'è‚¡ç¥¨åç§°':<12} {'å¸‚å€¼(äº¿)':<8} {'è¡Œä¸š':<12} {'æœ€æ–°ä»·':<8} "
               f"{'æˆäº¤é‡å€æ•°':<10} {'ä»·æ ¼ä½ç½®':<8} {'è·é«˜ç‚¹è·Œå¹…%':<12} {'ç›¸å¯¹4å‘¨å‡çº¿%':<12}")
    logger.info("=" * 140)
    
    for i, (_, row) in enumerate(df.iterrows(), 1):
        logger.info(
            f"{i:<4} "
            f"{row['ts_code']:<12} "
            f"{row['stock_name']:<12} "
            f"{row['market_cap']:<8.0f} "
            f"{row['industry']:<12} "
            f"{row['latest_close']:<8.2f} "
            f"{row['volume_surge_ratio']:<10.2f} "
            f"{row['price_position']:<8.1%} "
            f"{row['decline_from_high']:<12.1f} "
            f"{row['relative_to_ma4w']:<12.1f}"
        )
    
    logger.info("=" * 140)
    logger.info(f"æ€»å…±æ‰¾åˆ° {len(df)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
    
    # ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    logger.info(f"   å¹³å‡å¸‚å€¼: {df['market_cap'].mean():.0f}äº¿å…ƒ")
    logger.info(f"   å¹³å‡æˆäº¤é‡æ”¾å¤§å€æ•°: {df['volume_surge_ratio'].mean():.2f}")
    logger.info(f"   å¹³å‡ä»·æ ¼ä½ç½®: {df['price_position'].mean():.1%}")
    logger.info(f"   å¹³å‡è·é«˜ç‚¹è·Œå¹…: {df['decline_from_high'].mean():.1f}%")
    
    # è¡Œä¸šåˆ†å¸ƒ
    if 'industry' in df.columns:
        industry_counts = df['industry'].value_counts()
        logger.info(f"\nğŸ“ˆ è¡Œä¸šåˆ†å¸ƒï¼š")
        for industry, count in industry_counts.items():
            logger.info(f"   {industry}: {count} åª")
    
    # æŠ•èµ„æç¤º
    logger.info(f"\nğŸ’¡ æŠ•èµ„æç¤ºï¼š")
    logger.info("   ğŸ” ä»·æ ¼ä½ç½®ï¼šæ•°å€¼è¶Šå°è¡¨ç¤ºè¶Šæ¥è¿‘ä½ç‚¹")
    logger.info("   ğŸ“Š æˆäº¤é‡å€æ•°ï¼šè¡¨ç¤ºæœ€è¿‘2å‘¨ç›¸å¯¹å‰æœŸçš„æ”¾å¤§å€æ•°")
    logger.info("   ğŸ“‰ è·é«˜ç‚¹è·Œå¹…ï¼šæ­£å€¼è¡¨ç¤ºä»é«˜ç‚¹å›è°ƒçš„å¹…åº¦")
    logger.info("   âš ï¸  å»ºè®®ç»“åˆåŸºæœ¬é¢å’ŒæŠ€æœ¯é¢è¿›ä¸€æ­¥åˆ†æ")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æŸ¥è¯¢å‘¨çº¿æ”¾é‡ä¸”å¤„äºç›¸å¯¹ä½ä½çš„600äº¿+å¸‚å€¼è‚¡ç¥¨...")
    logger.info("=" * 60)
    
    start_time = datetime.now()
    
    try:
        analyzer = VolumeLowPositionAnalyzer()
        result_df = analyzer.analyze_volume_low_position()
        
        if result_df is not None and not result_df.empty:
            display_results(result_df)
            
            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            output_file = f"volume_low_position_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")
            
            logger.info("\nğŸ’¡ æŠ•èµ„ç­–ç•¥è§£è¯»ï¼š")
            logger.info("   âœ… å‘¨çº¿æ”¾é‡ï¼šè¡¨æ˜æœ‰èµ„é‡‘å…³æ³¨ï¼Œå¯èƒ½æœ‰é‡è¦å˜åŒ–")
            logger.info("   âœ… ç›¸å¯¹ä½ä½ï¼šä»·æ ¼å¤„äºè¿‘æœŸåŒºé—´ä½ä½ï¼Œå®‰å…¨è¾¹é™…è¾ƒé«˜")
            logger.info("   âœ… 600äº¿+å¸‚å€¼ï¼šæµåŠ¨æ€§å¥½ï¼ŒåŸºæœ¬é¢ç›¸å¯¹ç¨³å¥")
            logger.info("   âœ… ä¸»æ¿è‚¡ç¥¨ï¼šè§„èŒƒæ€§å¥½ï¼Œä¿¡æ¯é€æ˜åº¦é«˜")
            logger.info("   âš ï¸  å»ºè®®å…³æ³¨æ”¾é‡åŸå› å’ŒåŸºæœ¬é¢å˜åŒ–")
            
        else:
            logger.error("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œå¯èƒ½åŸå› ï¼š")
            logger.error("   1. è¿‘æœŸå¤§å¸‚å€¼è‚¡ç¥¨æˆäº¤é‡ç›¸å¯¹ç¨³å®š")
            logger.error("   2. å¤§éƒ¨åˆ†è‚¡ç¥¨ä¸åœ¨ç›¸å¯¹ä½ä½")
            logger.error("   3. å¯ä»¥é€‚å½“é™ä½ç­›é€‰æ ‡å‡†")
            
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        return False
        
    finally:
        end_time = datetime.now()
        total_duration = end_time - start_time
        logger.info(f"\nâ° æŸ¥è¯¢æ€»è€—æ—¶: {total_duration}")
    
    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)

